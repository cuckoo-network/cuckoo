---
title: "प्रमुख LLM चैट टूल्स पर Reddit उपयोगकर्ता प्रतिक्रिया"
tags: [AI, ChatGPT, Claude, Google Gemini, Open-Source LLMs]
keywords: [AI चैट टूल्स, उपयोगकर्ता प्रतिक्रिया, ChatGPT, Claude, Google Gemini, ओपन-सोर्स LLMs, Reddit विश्लेषण]
authors: [lark]
description: यह लेख ChatGPT, Claude, Google Gemini और ओपन-सोर्स LLMs सहित लोकप्रिय AI चैट टूल्स पर Reddit चर्चाओं का गहन विश्लेषण प्रदान करता है। यह उपयोगकर्ता-रिपोर्टेड समस्याओं, अक्सर अनुरोधित सुविधाओं और उपेक्षित आवश्यकताओं को उजागर करता है, प्रत्येक टूल की ताकत और कमजोरियों में अंतर्दृष्टि प्रदान करता है।
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=प्रमुख%20LLM%20चैट%20टूल्स%20पर%20Reddit%20उपयोगकर्ता%20प्रतिक्रिया"
---

# प्रमुख LLM चैट टूल्स पर Reddit उपयोगकर्ता प्रतिक्रिया

**सारांश:** यह रिपोर्ट चार लोकप्रिय AI चैट टूल्स – **OpenAI का ChatGPT**, **Anthropic का Claude**, **Google का Gemini (Bard)**, और **ओपन-सोर्स LLMs** (जैसे LLaMA-आधारित मॉडल) पर Reddit चर्चाओं का विश्लेषण करती है। यह प्रत्येक के लिए उपयोगकर्ताओं द्वारा रिपोर्ट की गई सामान्य समस्याओं का सारांश प्रस्तुत करती है, वे सुविधाएँ जो वे सबसे अधिक बार अनुरोध करते हैं, अपूर्ण आवश्यकताएँ या उपयोगकर्ता खंड जो उपेक्षित महसूस करते हैं, और डेवलपर्स, आकस्मिक उपयोगकर्ताओं और व्यावसायिक उपयोगकर्ताओं के बीच धारणा में अंतर। इन बिंदुओं को स्पष्ट करने के लिए Reddit थ्रेड्स से विशिष्ट उदाहरण और उद्धरण शामिल हैं।

![प्रमुख LLM चैट टूल्स पर Reddit उपयोगकर्ता प्रतिक्रिया](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=प्रमुख%20LLM%20चैट%20टूल्स%20पर%20Reddit%20उपयोगकर्ता%20प्रतिक्रिया)

## ChatGPT (OpenAI)

### सामान्य समस्याएँ और सीमाएँ

- **सीमित संदर्भ स्मृति:** एक शीर्ष शिकायत है कि ChatGPT लंबी बातचीत या बड़े दस्तावेज़ों को बिना पहले के विवरण भूलने के संभालने में असमर्थ है। उपयोगकर्ता अक्सर संदर्भ लंबाई सीमा (कुछ हजार टोकन) तक पहुँचते हैं और उन्हें जानकारी को संक्षिप्त या सारांशित करना पड़ता है। एक उपयोगकर्ता ने उल्लेख किया *“संदर्भ विंडो का आकार बढ़ाना सबसे बड़ा सुधार होगा... यही वह सीमा है जिसका मैं सबसे अधिक सामना करता हूँ”*। जब संदर्भ पार हो जाता है, तो ChatGPT प्रारंभिक निर्देशों या सामग्री को भूल जाता है, जिससे सत्र के मध्य में गुणवत्ता में निराशाजनक गिरावट आती है।

- **GPT-4 के लिए संदेश कैप्स:** ChatGPT Plus उपयोगकर्ता GPT-4 उपयोग के 25-संदेश/3-घंटे की सीमा (2023 में मौजूद सीमा) की शिकायत करते हैं। इस सीमा को पार करने से उन्हें प्रतीक्षा करनी पड़ती है, जिससे काम में बाधा आती है। भारी उपयोगकर्ता इस थ्रॉटलिंग को एक प्रमुख समस्या मानते हैं।

- **कठोर सामग्री फ़िल्टर ("नरफ्स"):** कई Reddit उपयोगकर्ता महसूस करते हैं कि ChatGPT अत्यधिक प्रतिबंधात्मक हो गया है, अक्सर उन अनुरोधों को अस्वीकार कर देता है जिन्हें पहले के संस्करणों ने संभाला था। एक अत्यधिक अपवोटेड पोस्ट ने शिकायत की कि *“आजकल आप जो कुछ भी पूछते हैं, वह 'माफ़ करें, मदद नहीं कर सकता' लौटाता है... यह सबसे उपयोगी टूल से Google सहायक के समकक्ष कैसे हो गया?”*। उपयोगकर्ता उदाहरण देते हैं जैसे कि ChatGPT उनके *अपने* टेक्स्ट (जैसे लॉगिन क्रेडेंशियल्स) को पुनः स्वरूपित करने से इंकार कर देता है क्योंकि इसका दुरुपयोग हो सकता है। भुगतान करने वाले ग्राहक तर्क देते हैं कि *“कुछ अस्पष्ट धारणा कि उपयोगकर्ता 'बुरा' काम कर सकता है... परिणाम प्रदर्शित न करने का आधार नहीं होना चाहिए”*, क्योंकि वे मॉडल के आउटपुट चाहते हैं और इसे जिम्मेदारी से उपयोग करेंगे।

- **भ्रम और त्रुटियाँ:** अपनी उन्नत क्षमता के बावजूद, ChatGPT आत्मविश्वास के साथ गलत या गढ़ी हुई जानकारी उत्पन्न कर सकता है। कुछ उपयोगकर्ताओं ने देखा है कि समय के साथ यह बदतर हो गया है, संदेह है कि मॉडल को "मूर्ख" बनाया गया था। उदाहरण के लिए, वित्त में एक उपयोगकर्ता ने कहा कि ChatGPT पहले NPV या IRR जैसे मेट्रिक्स को सही ढंग से गणना करता था, लेकिन अपडेट के बाद *“मुझे इतने सारे गलत उत्तर मिल रहे हैं... यह अभी भी गलत उत्तर उत्पन्न करता है [सुधार के बाद भी]। मुझे वास्तव में विश्वास है कि परिवर्तनों के बाद यह बहुत मूर्ख हो गया है।”*। इस तरह की अप्रत्याशित गलतियाँ उन कार्यों के लिए विश्वास को कम करती हैं जिनके लिए तथ्यात्मक सटीकता की आवश्यकता होती है।

- **अपूर्ण कोड आउटपुट:** डेवलपर्स अक्सर कोडिंग सहायता के लिए ChatGPT का उपयोग करते हैं, लेकिन वे रिपोर्ट करते हैं कि यह कभी-कभी समाधान के कुछ हिस्सों को छोड़ देता है या लंबे कोड को काट देता है। एक उपयोगकर्ता ने साझा किया कि ChatGPT अब *“कोड छोड़ देता है, अनुपयोगी कोड उत्पन्न करता है, और जिस चीज़ की मुझे आवश्यकता है उसमें बस बेकार है... यह अक्सर इतना कोड छोड़ देता है कि मैं यह भी नहीं जानता कि इसके समाधान को कैसे एकीकृत किया जाए।”* यह उपयोगकर्ताओं को शेष को बाहर निकालने के लिए अनुवर्ती संकेत देने के लिए मजबूर करता है, या उत्तरों को मैन्युअल रूप से जोड़ने के लिए मजबूर करता है - एक थकाऊ प्रक्रिया।

- **प्रदर्शन और अपटाइम चिंताएँ:** यह धारणा है कि जैसे-जैसे एंटरप्राइज़ उपयोग बढ़ा, व्यक्तिगत उपयोगकर्ताओं के लिए ChatGPT का प्रदर्शन घट गया। *“मुझे लगता है कि वे बैंडविड्थ और प्रोसेसिंग पावर को व्यवसायों को आवंटित कर रहे हैं और इसे उपयोगकर्ताओं से दूर कर रहे हैं, जो कि सदस्यता की लागत को देखते हुए असहनीय है!”* एक निराश प्लस ग्राहक ने कहा। चरम समय के दौरान आउटेज या मंदी का उल्लेख किया गया है, जो वर्कफ़्लो को बाधित कर सकता है।

### अक्सर अनुरोधित सुविधाएँ या सुधार

- **लंबा संदर्भ विंडो / मेमोरी:** अब तक का सबसे अनुरोधित सुधार बड़ा संदर्भ लंबाई है। उपयोगकर्ता बहुत लंबी बातचीत करना चाहते हैं या बिना रीसेट के बड़े दस्तावेज़ फ़ीड करना चाहते हैं। कई लोग सुझाव देते हैं कि ChatGPT के संदर्भ को GPT-4 की 32K टोकन क्षमता (वर्तमान में API के माध्यम से उपलब्ध) या उससे आगे तक विस्तारित किया जाए। जैसा कि एक उपयोगकर्ता ने कहा, *“GPT संदर्भ के साथ सबसे अच्छा है, और जब यह उस प्रारंभिक संदर्भ को याद नहीं रखता है, तो मुझे निराशा होती है... अगर अफवाहें सच हैं कि संदर्भ पीडीएफ, तो यह मूल रूप से मेरी सभी समस्याओं का समाधान करेगा।”* दस्तावेज़ अपलोड करने या व्यक्तिगत डेटा लिंक करने की सुविधाओं की उच्च मांग है ताकि ChatGPT सत्र के दौरान उन्हें याद रख सके और संदर्भित कर सके।

- **फाइल-हैंडलिंग और एकीकरण:** उपयोगकर्ता अक्सर ChatGPT में फ़ाइलें या डेटा फ़ीड करने के आसान तरीकों के लिए कहते हैं। चर्चाओं में, लोग *“मेरे Google ड्राइव को कॉपी और पेस्ट करना और इसे काम करना”* या ऐसे प्लगइन्स चाहते हैं जो ChatGPT को सीधे व्यक्तिगत फ़ाइलों से संदर्भ प्राप्त करने दें। कुछ ने वर्कअराउंड आज़माए हैं (जैसे पीडीएफ रीडर प्लगइन्स या Google डॉक्स लिंक करना), लेकिन त्रुटियों और सीमाओं के बारे में शिकायत की। एक उपयोगकर्ता ने अपने आदर्श प्लगइन का वर्णन किया जो *“लिंक रीडर की तरह काम करता है लेकिन व्यक्तिगत फ़ाइलों के लिए... बातचीत में मेरे ड्राइव के किन हिस्सों का उपयोग करना है चुनना... यह मूल रूप से मेरी GPT-4 के साथ वर्तमान में सभी समस्याओं का समाधान करेगा।”*। संक्षेप में, बाहरी ज्ञान के लिए बेहतर देशी समर्थन (प्रशिक्षण डेटा से परे) एक लोकप्रिय अनुरोध है।

- **भुगतान किए गए उपयोगकर्ताओं के लिए कम थ्रॉटलिंग:** चूंकि कई प्लस उपयोगकर्ता GPT-4 संदेश सीमा तक पहुँचते हैं, वे उच्च सीमाओं या असीमित पहुंच के लिए अधिक भुगतान करने के विकल्प के लिए कहते हैं। 25-संदेश सीमा को मनमाना और गहन उपयोग में बाधा डालने वाला माना जाता है। लोग उपयोग-आधारित मॉडल या उच्च सीमा पसंद करेंगे ताकि लंबे समस्या-समाधान सत्रों को बीच में न काटा जाए।

- **"अनसेंसर्ड" या कस्टम मॉडरेशन मोड:** उपयोगकर्ताओं का एक खंड सामग्री फ़िल्टर की कठोरता को टॉगल करने की क्षमता चाहता है, विशेष रूप से जब वे ChatGPT का उपयोग स्वयं के लिए कर रहे हों (सार्वजनिक-सामना करने वाली सामग्री नहीं)। वे महसूस करते हैं कि एक "अनुसंधान" या "अनसेंसर्ड" मोड - चेतावनियों के साथ लेकिन कठिन अस्वीकृति के बिना - उन्हें अधिक स्वतंत्र रूप से अन्वेषण करने देगा। जैसा कि एक उपयोगकर्ता ने कहा, भुगतान करने वाले ग्राहक इसे एक उपकरण के रूप में देखते हैं और विश्वास करते हैं *“मैं इसके लिए पैसे देता हूं।”* वे चाहते हैं कि उन्हें सीमा रेखा प्रश्नों पर भी उत्तर मिलें। जबकि OpenAI को सुरक्षा का संतुलन बनाना है, ये उपयोगकर्ता निजी चैट में नीतियों को शिथिल करने के लिए एक फ्लैग या सेटिंग का सुझाव देते हैं।

- **बेहतर तथ्यात्मक सटीकता और अपडेट:** उपयोगकर्ता आमतौर पर अधिक अद्यतन ज्ञान और कम भ्रम के लिए कहते हैं। ChatGPT का ज्ञान कटऑफ (पहले के संस्करणों में सितंबर 2021) Reddit पर अक्सर उठाई गई एक सीमा थी। OpenAI ने तब से ब्राउज़िंग और प्लगइन्स पेश किए हैं, जिन्हें कुछ उपयोगकर्ता लाभ उठाते हैं, लेकिन अन्य केवल अनुरोध करते हैं कि आधार मॉडल को अधिक बार नए डेटा के साथ अपडेट किया जाए। स्पष्ट त्रुटियों को कम करना - विशेष रूप से गणित और कोडिंग जैसे डोमेन में - एक चल रही इच्छा है। कुछ डेवलपर्स ChatGPT के गलत होने पर फीडबैक प्रदान करते हैं ताकि मॉडल में सुधार हो सके।

- **बेहतर कोड आउटपुट और टूल्स:** डेवलपर्स के पास एक बेहतर कोड इंटरप्रेटर जैसी फीचर अनुरोध हैं जो सामग्री को नहीं छोड़ता है, और आईडीई या संस्करण नियंत्रण के साथ एकीकरण। (OpenAI का कोड इंटरप्रेटर प्लगइन - अब "उन्नत डेटा विश्लेषण" का हिस्सा - इस दिशा में एक कदम था और प्रशंसा प्राप्त की।) फिर भी, उपयोगकर्ता अक्सर कोड जनरेशन में अधिक नियंत्रण का अनुरोध करते हैं: उदाहरण के लिए, एक विकल्प जो पूर्ण, बिना फ़िल्टर किए कोड को आउटपुट करता है, भले ही यह लंबा हो, या ऐसे तंत्र जो आसानी से कोड को ठीक करते हैं यदि एआई ने गलती की। मूल रूप से, वे चाहते हैं कि ChatGPT एक विश्वसनीय कोडिंग सहायक की तरह व्यवहार करे बिना उत्तर को परिष्कृत करने के लिए कई संकेतों की आवश्यकता के।

- **स्थायी उपयोगकर्ता प्रोफाइल या मेमोरी:** कुछ लोग जिस सुधार का उल्लेख करते हैं, वह है ChatGPT को सत्रों के दौरान उपयोगकर्ता के बारे में चीजें याद रखने देना (सहमति के साथ)। उदाहरण के लिए, किसी की लेखन शैली को याद रखना, या कि वे एक सॉफ्टवेयर इंजीनियर हैं, बिना इसे हर नई चैट में दोहराए। यह एपीआई फाइन-ट्यूनिंग या "प्रोफाइल" फीचर में टाई कर सकता है। उपयोगकर्ता अब महत्वपूर्ण संदर्भ को नई चैट में मैन्युअल रूप से कॉपी करते हैं, इसलिए व्यक्तिगत प्राथमिकताओं के लिए एक अंतर्निहित मेमोरी समय बचाएगा।

### उपेक्षित आवश्यकताएँ या उपयोगकर्ता खंड

- **लंबे दस्तावेज़ों वाले शोधकर्ता और छात्र:** जो लोग ChatGPT से लंबे शोध पत्र, किताबें, या बड़े डेटासेट का विश्लेषण करने की उम्मीद करते हैं, वे उपेक्षित महसूस करते हैं। वर्तमान सीमाएँ उन्हें पाठ को काटने या सारांश के लिए मजबूर करती हैं। यह खंड बड़े संदर्भ विंडो या लंबे दस्तावेज़ों को संभालने की सुविधाओं से बहुत लाभान्वित होगा (जैसा कि टोकन सीमाओं के आसपास जाने की कोशिश के बारे में कई पोस्टों से प्रमाणित होता है)।

- **सीमाओं से परे रचनात्मक कहानी कहने या भूमिका निभाने की तलाश करने वाले उपयोगकर्ता:** जबकि ChatGPT का अक्सर रचनात्मक लेखन के लिए उपयोग किया जाता है, कुछ कहानीकार लंबे समय तक कहानी में प्रारंभिक प्लॉट पॉइंट्स को भूलने या वयस्क/हॉरर सामग्री से इनकार करने के मॉडल से बाधित महसूस करते हैं। वे अपनी कथाओं को जारी रखने के लिए वैकल्पिक मॉडलों या हैक्स की ओर रुख करते हैं। इन रचनात्मक उपयोगकर्ताओं को ChatGPT के एक ऐसे संस्करण से बेहतर सेवा मिलेगी जिसमें लंबी मेमोरी और काल्पनिक हिंसा या परिपक्व विषयों पर थोड़ी अधिक लचीलापन हो (कारण के भीतर)। जैसा कि एक फिक्शन लेखक ने कहा, जब एआई कहानी का ट्रैक खो देता है, *“मुझे इसे सटीक प्रारूप या संदर्भ की याद दिलानी पड़ती है... मुझे निराशा होती है कि यह दो संकेत पहले महान था, लेकिन अब मुझे एआई को पकड़ना है।”*।

- **पावर उपयोगकर्ता और डोमेन विशेषज्ञ:** विशेष क्षेत्रों में पेशेवर (जैसे **वित्त**, **इंजीनियरिंग**, **चिकित्सा**) कभी-कभी अपने डोमेन में गहराई या सटीकता की कमी वाले ChatGPT के उत्तर पाते हैं, विशेष रूप से यदि प्रश्न हालिया विकास शामिल करते हैं। ये उपयोगकर्ता अधिक विश्वसनीय विशेषज्ञ ज्ञान की इच्छा रखते हैं। कुछ ने एपीआई या कस्टम GPTs के माध्यम से फाइन-ट्यूनिंग की कोशिश की है। जो फाइन-ट्यून नहीं कर सकते वे ChatGPT के डोमेन-विशिष्ट संस्करणों या विश्वसनीय डेटाबेस को एम्बेड करने वाले प्लगइन्स की सराहना करेंगे। अपने डिफ़ॉल्ट रूप में, ChatGPT उन उपयोगकर्ताओं की सेवा नहीं कर सकता जिन्हें अत्यधिक सटीक, क्षेत्र-विशिष्ट जानकारी की आवश्यकता होती है (उन्हें अक्सर इसके काम की दोबारा जांच करनी पड़ती है)।

- **असेंसर्ड या एज-केस सामग्री की आवश्यकता वाले उपयोगकर्ता:** उपयोगकर्ताओं का एक अल्पसंख्यक (सुरक्षा परिदृश्यों का परीक्षण करने वाले हैकर्स, चरम फिक्शन के लेखक, आदि) ChatGPT की सामग्री प्रतिबंधों को अपनी आवश्यकताओं के लिए बहुत सीमित पाते हैं। वे वर्तमान में आधिकारिक उत्पाद द्वारा उपेक्षित हैं (क्योंकि यह स्पष्ट रूप से कुछ सामग्री से बचता है)। ये उपयोगकर्ता अक्सर जेलब्रेकिंग संकेतों के साथ प्रयोग करते हैं या वे जो प्रतिक्रियाएँ चाहते हैं उन्हें प्राप्त करने के लिए ओपन-सोर्स मॉडल का उपयोग करते हैं। यह OpenAI के लिए एक जानबूझकर अंतर है (सुरक्षा बनाए रखने के लिए), लेकिन इसका मतलब है कि ऐसे उपयोगकर्ता कहीं और देखते हैं।

- **गोपनीयता-सचेत व्यक्ति और उद्यम:** कुछ उपयोगकर्ता (विशेष रूप से कॉर्पोरेट सेटिंग्स में) संवेदनशील डेटा को गोपनीयता चिंताओं के कारण ChatGPT को भेजने में असहज होते हैं। OpenAI के पास एपीआई डेटा का प्रशिक्षण के लिए उपयोग न करने की नीतियाँ हैं, लेकिन ChatGPT वेब यूआई ने ऐतिहासिक रूप से ऐसी गारंटी नहीं दी जब तक कि एक ऑप्ट-आउट सुविधा नहीं जोड़ी गई। जो कंपनियाँ गोपनीय डेटा (कानूनी, स्वास्थ्य देखभाल, आदि) को संभालती हैं, वे अक्सर महसूस करती हैं कि वे ChatGPT का पूरी तरह से उपयोग नहीं कर सकतीं, जब तक कि वे स्व-होस्टेड समाधान नहीं बनातीं। उदाहरण के लिए, एक Redditor ने उल्लेख किया कि उनकी कंपनी गोपनीयता कारणों से स्थानीय LLM में स्थानांतरित हो गई। जब तक ऑन-प्रेम या निजी ChatGPT के उदाहरण उपलब्ध नहीं होते, यह खंड सतर्क रहता है या छोटे विशेषज्ञ विक्रेताओं का उपयोग करता है।

### उपयोगकर्ता प्रकार द्वारा धारणा में अंतर

- **डेवलपर्स/तकनीकी उपयोगकर्ता:** डेवलपर्स ChatGPT के सबसे बड़े समर्थकों और सबसे कठोर आलोचकों में से कुछ होते हैं। वे इसके कोड की व्याख्या करने, बोइलरप्लेट उत्पन्न करने, और डिबगिंग में सहायता करने की क्षमता को पसंद करते हैं। हालांकि, वे लंबे संदर्भ और कोड सटीकता में इसकी सीमाओं को तीव्रता से महसूस करते हैं। जैसा कि एक देव ने शिकायत की, ChatGPT ने *“अनुपयोगी कोड”* उत्पन्न करना शुरू कर दिया और महत्वपूर्ण भागों को छोड़ दिया, जो *“मुझे गुस्सा दिलाता है... मैं इसे 'आलसी मत बनो' नहीं कहना चाहता - मैं बस पूरा परिणाम चाहता हूँ”*। देव अक्सर मॉडल अपडेट के बाद गुणवत्ता में सूक्ष्म परिवर्तनों को भी नोटिस करते हैं और कोडिंग क्षमता में कथित "नरफ्स" या गिरावट के बारे में Reddit पर बहुत मुखर रहे हैं। वे सीमा को भी धकेलते हैं (जटिल संकेत बनाना, उपकरणों को जोड़ना), इसलिए वे विस्तारित संदर्भ, कम संदेश कैप्स, और कोडिंग टूल्स के साथ बेहतर एकीकरण जैसी सुविधाओं की लालसा करते हैं। संक्षेप में, डेवलपर्स ChatGPT को नियमित कार्यों को गति देने के लिए महत्व देते हैं लेकिन तर्क या कोड में त्रुटियों को इंगित करने में तेज होते हैं - वे इसे एक जूनियर सहायक के रूप में देखते हैं जिसे अभी भी निगरानी की आवश्यकता होती है।

- **आकस्मिक/दैनिक उपयोगकर्ता:** अधिक आकस्मिक उपयोगकर्ता - जो सामान्य ज्ञान, सलाह, या मज़े के लिए पूछते हैं - अक्सर ChatGPT की क्षमताओं पर आश्चर्यचकित होते हैं, लेकिन उनकी अपनी शिकायतें होती हैं। एक सामान्य आकस्मिक-उपयोगकर्ता निराशा तब होती है जब ChatGPT एक अनुरोध को अस्वीकार कर देता है जो उन्हें निर्दोष लगता है (संभवतः एक नीति नियम को ट्रिपिंग)। एक थ्रेड में मूल पोस्टर ने इसका उदाहरण दिया, *“इतना गुस्सा आता है जब मैं एक संकेत लिखता हूँ जिसमें इसे कोई समस्या नहीं होनी चाहिए और अब यह मना कर देता है”*। आकस्मिक उपयोगकर्ता भी ज्ञान कटऑफ में आ सकते हैं (यह पाते हुए कि बॉट बहुत वर्तमान घटनाओं को संभाल नहीं सकता जब तक कि स्पष्ट रूप से अपडेट न किया जाए) और कभी-कभी नोटिस करते हैं जब ChatGPT स्पष्ट रूप से गलत उत्तर देता है। डेवलपर्स के विपरीत, वे हमेशा एआई की दोबारा जांच नहीं कर सकते, जिससे निराशा हो सकती है यदि वे गलती पर कार्य करते हैं। सकारात्मक पक्ष पर, कई आकस्मिक उपयोगकर्ता ChatGPT Plus की तेज़ प्रतिक्रियाओं और GPT-4 के बेहतर आउटपुट को $20/माह के लायक पाते हैं - जब तक कि "अस्वीकृति" समस्या या अन्य सीमाएँ अनुभव को खराब न कर दें। वे आम तौर पर एक सहायक, सर्व-उद्देश्यीय सहायक चाहते हैं और जब ChatGPT नीति वक्तव्यों के साथ जवाब देता है या एक सरल उत्तर प्राप्त करने के लिए एक जटिल संकेत की आवश्यकता होती है तो निराश हो सकते हैं।

- **व्यवसाय/पेशेवर उपयोगकर्ता:** व्यावसायिक उपयोगकर्ता अक्सर उत्पादकता और विश्वसनीयता के दृष्टिकोण से ChatGPT से संपर्क करते हैं। वे ईमेल के त्वरित मसौदे तैयार करने, दस्तावेज़ों के सारांश, या विचारों की पीढ़ी की सराहना करते हैं। हालांकि, वे **डेटा सुरक्षा**, स्थिरता, और वर्कफ़्लो में एकीकरण के बारे में चिंतित हैं। Reddit पर, पेशेवरों ने चर्चा की है कि वे ChatGPT को Outlook, Google Docs, या अपने आंतरिक सिस्टम में एक एपीआई के रूप में चाहते हैं। कुछ ने नोट किया है कि जैसे-जैसे OpenAI एंटरप्राइज़ क्लाइंट्स की सेवा करने के लिए आगे बढ़ता है, उत्पाद का ध्यान बदलता हुआ प्रतीत होता है: एक भावना है कि मुफ्त या व्यक्तिगत उपयोगकर्ता अनुभव थोड़ा खराब हो गया (जैसे धीमा या "कम स्मार्ट") जैसा कि कंपनी ने बड़े ग्राहकों की सेवा करने के लिए स्केल किया। चाहे वह सच हो या नहीं, यह एक धारणा को उजागर करता है: व्यावसायिक उपयोगकर्ता विश्वसनीयता और प्राथमिकता सेवा चाहते हैं, और व्यक्तिगत उपयोगकर्ता चिंता करते हैं कि वे अब द्वितीय श्रेणी के हैं। इसके अलावा, पेशेवरों को सही आउटपुट की आवश्यकता होती है - एक आकर्षक लेकिन गलत उत्तर कोई उत्तर न होने से भी बदतर हो सकता है। इसलिए, यह खंड सटीकता के प्रति संवेदनशील है। उनके लिए, लंबे संदर्भ जैसी सुविधाएँ (अनुबंध पढ़ने, कोडबेस का विश्लेषण करने के लिए) और गारंटीकृत अपटाइम महत्वपूर्ण हैं। वे शायद प्रीमियम सेवा स्तरों के लिए अधिक भुगतान करेंगे, बशर्ते उनकी अनुपालन और गोपनीयता आवश्यकताओं को पूरा किया जाए। कुछ उद्यम यहां तक कि ऑन-प्रेमिस परिनियोजन का पता लगाते हैं या अपने आईटी नीतियों को संतुष्ट करने के लिए सख्त डेटा हैंडलिंग नियमों के साथ OpenAI के एपीआई का उपयोग करते हैं।

---

## Claude (Anthropic)

### सामान्य समस्याएँ और सीमाएँ

- **उपयोग सीमा और पहुंच प्रतिबंध:** Claude को एक शक्तिशाली मॉडल (Claude 2) मुफ्त में पेश करने के लिए प्रशंसा मिली, लेकिन उपयोगकर्ता जल्दी ही उपयोग सीमा (विशेष रूप से मुफ्त स्तर पर) का सामना करते हैं। एक निश्चित संख्या में संकेतों या बड़ी मात्रा में पाठ के बाद, Claude रुक सकता है और कुछ ऐसा कह सकता है *“मुझे खेद है, मुझे अभी के लिए इस बातचीत को समाप्त करना होगा। कृपया बाद में वापस आएं।”* यह थ्रॉटलिंग उन उपयोगकर्ताओं को निराश करता है जो Claude को एक विस्तारित कोडिंग या लेखन साथी के रूप में मानते हैं। यहां तक कि Claude Pro (भुगतान किया गया) उपयोगकर्ताओं को भी *“असीमित समय की गारंटी नहीं है”*, जैसा कि एक उपयोगकर्ता ने कहा; कोटा तक पहुंचने पर भी "बाद में वापस आएं" संदेश उत्पन्न होता है। इसके अलावा, लंबे समय तक Claude आधिकारिक तौर पर भू-प्रतिबंधित था (शुरुआत में केवल यूएस/यूके में उपलब्ध)। Reddit पर अंतरराष्ट्रीय उपयोगकर्ताओं को इसे एक्सेस करने के लिए वीपीएन या तृतीय-पक्ष प्लेटफार्मों का उपयोग करना पड़ा, जो असुविधाजनक था। इससे कई गैर-अमेरिकी उपयोगकर्ता तब तक उपेक्षित महसूस करते थे जब तक कि पहुंच का विस्तार नहीं हुआ।

- **बहुत बड़े इनपुट के साथ ट्रैक से बाहर जाने की प्रवृत्ति:** Claude की प्रमुख विशेषता इसका *100k-टोकन संदर्भ विंडो* है, जो अत्यधिक लंबे संकेतों की अनुमति देता है। हालांकि, कुछ उपयोगकर्ताओं ने देखा है कि जब आप Claude में दसियों हजार टोकन भरते हैं, तो इसकी प्रतिक्रियाएं कम केंद्रित हो सकती हैं। *“100k सुपर उपयोगी है लेकिन अगर यह निर्देशों का सही ढंग से पालन नहीं करता है और ट्रैक से बाहर चला जाता है, तो यह इतना उपयोगी नहीं है,”* एक उपयोगकर्ता ने देखा। यह सुझाव देता है कि विशाल संदर्भों के साथ, Claude भटक सकता है या बकवास करना शुरू कर सकता है, इसे कार्य पर रखने के लिए सावधानीपूर्वक संकेत की आवश्यकता होती है। यह संदर्भ को चरम पर धकेलने की एक अंतर्निहित सीमा है - मॉडल बहुत कुछ बनाए रखता है लेकिन कभी-कभी "भूल जाता है" कि कौन सा विवरण सबसे प्रासंगिक है, जिससे मामूली भ्रम या ऑफ-टॉपिक टैंगेंट्स हो सकते हैं।

- **अनुपालन या निर्देशों का पालन करने में असंगतता:** साइड-बाय-साइड तुलना में, कुछ उपयोगकर्ताओं ने पाया कि Claude कुछ निर्देशों का पालन करने में कम अनुमानित है। उदाहरण के लिए, Claude को *“इंटरैक्शन में अधिक मानव-समान के रूप में वर्णित किया गया है। लेकिन यह सिस्टम संदेशों का कम सख्ती से पालन करता है।”*। इसका मतलब है कि यदि आप इसे पालन करने के लिए एक निश्चित प्रारूप या एक बहुत सख्त व्यक्तित्व देते हैं, तो Claude ChatGPT की तुलना में अधिक विचलित हो सकता है। डेवलपर्स जो निर्धारक आउटपुट (जैसे JSON प्रारूप या विशिष्ट शैलियाँ) पर निर्भर करते हैं, कभी-कभी निराश हो जाते हैं यदि Claude अतिरिक्त टिप्पणी पेश करता है या टेम्पलेट का सख्ती से पालन नहीं करता है।

- **सामग्री प्रतिबंध और अस्वीकृति:** जबकि ChatGPT की तुलना में उतनी बार आलोचना नहीं की जाती है, Claude के सुरक्षा फ़िल्टर सामने आते हैं। Anthropic ने नैतिक दिशानिर्देशों का पालन करने के लिए एआई के साथ भारी जोर देकर Claude को डिज़ाइन किया। उपयोगकर्ता आमतौर पर पाते हैं कि Claude विषयों की एक विस्तृत श्रृंखला पर चर्चा करने के लिए तैयार है, लेकिन ऐसे उदाहरण हैं जहां Claude उन अनुरोधों को अस्वीकार करता है जिन्हें ChatGPT अनुमति दे सकता है। उदाहरण के लिए, एक Redditor ने नोट किया *“ChatGPT के पास कम नैतिक प्रतिबंध हैं... यह बताएगा कि कौन से गैस मास्क किन परिस्थितियों के लिए बेहतर हैं जबकि Claude मना कर देगा”*। यह सुझाव देता है कि Claude कुछ "संवेदनशील" सलाह के बारे में सख्त हो सकता है (शायद इसे संभावित खतरनाक मार्गदर्शन के रूप में मानता है)। एक अन्य उपयोगकर्ता ने एक मजेदार भूमिका-खेल परिदृश्य ("कल्पना करें कि आपको एलियंस द्वारा अपहरण कर लिया गया था") आज़माया जिसे Claude ने अस्वीकार कर दिया, जबकि Gemini और ChatGPT लगे रहते। इसलिए, Claude के पास फ़िल्टर हैं जो कभी-कभी उपयोगकर्ताओं को आश्चर्यचकित कर सकते हैं जो इसे अधिक अनुमति देने की उम्मीद करते हैं।

- **मल्टीमॉडल क्षमताओं की कमी:** ChatGPT के विपरीत (जो, 2023 के अंत तक, GPT-4 विज़न के साथ छवि समझ प्राप्त कर चुका था), Claude वर्तमान में केवल पाठ है। Reddit उपयोगकर्ता ध्यान देते हैं कि Claude चित्रों का विश्लेषण नहीं कर सकता या अपने आप वेब ब्राउज़ नहीं कर सकता। यह वास्तव में एक "समस्या" नहीं है (Anthropic ने उन सुविधाओं का विज्ञापन कभी नहीं किया), लेकिन यह प्रतिस्पर्धियों के सापेक्ष एक सीमा है। जो उपयोगकर्ता एक एआई चाहते हैं जो आरेख या स्क्रीनशॉट की व्याख्या कर सके, वे इसके लिए Claude का उपयोग नहीं कर सकते, जबकि ChatGPT या Gemini इसे संभाल सकते हैं। इसी तरह, किसी भी मौजूदा जानकारी की पुनर्प्राप्ति के लिए Claude का उपयोग तृतीय-पक्ष टूल (जैसे, Poe या सर्च इंजन एकीकरण) के माध्यम से करना आवश्यक है, क्योंकि Claude के पास इस समय कोई आधिकारिक ब्राउज़िंग मोड नहीं है।

- **मामूली स्थिरता समस्याएँ:** कुछ उपयोगकर्ताओं ने बताया है कि Claude कभी-कभी दोहरावदार होता है या कुछ संकेतों के लिए लूप में फंस जाता है (हालांकि यह कुछ छोटे मॉडलों की तुलना में कम आम है)। इसके अलावा, Claude के पहले के संस्करण कभी-कभी प्रतिक्रियाओं को समय से पहले समाप्त कर देते थे या बड़े आउटपुट के साथ लंबा समय लेते थे, जिसे मामूली परेशानियों के रूप में देखा जा सकता है, हालांकि Claude 2 ने गति में सुधार किया।

### अक्सर अनुरोधित सुविधाएँ या सुधार

- **उच्च या समायोज्य उपयोग सीमा:** Reddit पर Claude के प्रशंसक अक्सर Anthropic से बातचीत की सीमा बढ़ाने के लिए कहते हैं। वे 100k संदर्भ का पूरा उपयोग करना चाहते हैं बिना कृत्रिम रोक के। कुछ सुझाव देते हैं कि यहां तक कि भुगतान किए गए Claude Pro को *काफी* अधिक टोकन प्रति दिन की अनुमति देनी चाहिए। अन्य लोगों ने एक वैकल्पिक "100k विस्तारित मोड" का विचार प्रस्तुत किया - उदाहरण के लिए, *“Claude के पास दोगुनी उपयोग सीमा के साथ 100k संदर्भ मोड होना चाहिए”* - जहां शायद एक सदस्यता भारी उपयोगकर्ताओं के लिए विस्तारित पहुंच की पेशकश कर सकती है। सारांश में, एक योजना की मांग है जो ग्राहकों के लिए ChatGPT के असीमित (या उच्च-कैप) उपयोग के साथ प्रतिस्पर्धा करती है।

- **बेहतर लंबे संदर्भ नेविगेशन:** 100k टोकन होने के बावजूद, उपयोगकर्ता चाहते हैं कि Claude उस संदर्भ का बेहतर *उपयोग* करे। एक सुधार यह होगा कि Claude कैसे जानकारी को प्राथमिकता देता है ताकि वह ट्रैक पर रहे। जब संकेत बहुत बड़ा होता है तो मॉडल की संकेत पालन क्षमता पर Anthropic काम कर सकता है। Reddit चर्चाएँ ऐसी तकनीकों का सुझाव देती हैं जैसे उपयोगकर्ता को कुछ निर्देशों को "पिन" करने की अनुमति देना ताकि वे बड़े संदर्भ में पतला न हो जाएं। इनपुट के भागों को खंडित या सारांशित करने में मदद करने वाले किसी भी उपकरण से Claude को बड़े इनपुट को अधिक सुसंगत रूप से संभालने में मदद मिल सकती है। संक्षेप में, उपयोगकर्ता Claude को एक पूरी किताब खिलाने की संभावना पसंद करते हैं - वे बस चाहते हैं कि यह पूरे समय तेज रहे।

- **प्लगइन्स या वेब ब्राउज़िंग:** कई ChatGPT उपयोगकर्ता प्लगइन्स के आदी हो गए हैं (उदाहरण के लिए, ब्राउज़िंग, कोड निष्पादन, आदि) और वे Claude में समान विस्तारशीलता में रुचि व्यक्त करते हैं। एक सामान्य अनुरोध है कि Claude के पास एक आधिकारिक वेब खोज/ब्राउज़िंग फ़ंक्शन हो, ताकि यह मांग पर अद्यतन जानकारी प्राप्त कर सके। वर्तमान में, Claude का ज्ञान ज्यादातर स्थिर है (प्रारंभिक 2023 तक का प्रशिक्षण डेटा, कुछ अपडेट के साथ)। यदि Claude वेब को क्वेरी कर सकता है, तो यह उस सीमा को दूर करेगा। इसी तरह, एक प्लगइन सिस्टम जहां Claude तृतीय-पक्ष टूल्स (जैसे कैलकुलेटर या डेटाबेस कनेक्टर) का उपयोग कर सकता है, पावर उपयोगकर्ताओं के लिए इसकी उपयोगिता का विस्तार कर सकता है। यह एक विशेषता है जो Claude की कमी है, और Reddit उपयोगकर्ता अक्सर उल्लेख करते हैं कि ChatGPT का प्लगइन्स का पारिस्थितिकी तंत्र कुछ कार्यों में इसे बढ़त देता है।

- **मल्टीमॉडल इनपुट (छवियाँ या ऑडियो):** कुछ उपयोगकर्ताओं ने यह भी सोचा है कि क्या Claude छवि इनपुट का समर्थन करेगा या छवियों का उत्पादन करेगा। Google के Gemini और OpenAI के GPT-4 में मल्टीमॉडल क्षमताएँ हैं, इसलिए प्रतिस्पर्धी बने रहने के लिए उपयोगकर्ता Anthropic से इस पर विचार करने की उम्मीद करते हैं। एक बार-बार अनुरोधित सुविधा है: *“क्या मैं Claude के विश्लेषण के लिए एक पीडीएफ या छवि अपलोड कर सकता हूँ?”* वर्तमान में उत्तर नहीं है (छवियों को कहीं और पाठ में परिवर्तित करने जैसे वर्कअराउंड के अलावा)। यहां तक कि छवि-से-पाठ (ओसीआर और विवरण) की अनुमति देना भी उन लोगों को संतुष्ट करेगा जो एक-स्टॉप सहायक चाहते हैं। यह इच्छा सूची में है, हालांकि Anthropic ने 2025 की शुरुआत तक कुछ भी समान घोषित नहीं किया है।

- **फाइन-ट्यूनिंग या अनुकूलन:** उन्नत उपयोगकर्ता और व्यवसाय कभी-कभी पूछते हैं कि क्या वे Claude को अपने डेटा पर फाइन-ट्यून कर सकते हैं या कस्टम संस्करण प्राप्त कर सकते हैं। OpenAI कुछ मॉडलों के लिए फाइन-ट्यूनिंग प्रदान करता है (अभी तक GPT-4 के लिए नहीं, लेकिन GPT-3.5 के लिए)। Anthropic ने पहले Claude 1.3 के लिए एक फाइन-ट्यूनिंग इंटरफ़ेस जारी किया, लेकिन यह Claude 2 के लिए व्यापक रूप से विज्ञापित नहीं है। Reddit उपयोगकर्ताओं ने Claude को कंपनी के ज्ञान या व्यक्तिगत लेखन शैली पर प्रशिक्षित करने में सक्षम होने के बारे में पूछा है। ऐसा करने का एक आसान तरीका (प्रत्येक बार संकेत इंजेक्शन के अलावा) बहुत स्वागत योग्य होगा, क्योंकि यह Claude को एक व्यक्तिगत सहायक में बदल सकता है जो एक विशिष्ट ज्ञान आधार या व्यक्तित्व को याद रखता है।

- **विस्तृत उपलब्धता:** गैर-अमेरिकी उपयोगकर्ता अक्सर अनुरोध करते हैं कि Claude को आधिकारिक तौर पर उनके देशों में लॉन्च किया जाए। कनाडा, यूरोप, भारत आदि से पोस्ट पूछते हैं कि वे कब Claude की वेबसाइट का उपयोग बिना वीपीएन के कर सकते हैं या Claude एपीआई कब व्यापक रूप से खुला होगा। Anthropic सतर्क रहा है, लेकिन मांग वैश्विक है - कई लोगों की नजर में एक सुधार बस "हमें इसका उपयोग करने दें" होगा। कंपनी की पहुंच का क्रमिक विस्तार ने इसे आंशिक रूप से संबोधित किया है।

### उपेक्षित आवश्यकताएँ या उपयोगकर्ता खंड

- **अंतरराष्ट्रीय उपयोगकर्ता आधार:** जैसा कि उल्लेख किया गया है, लंबे समय तक Claude का प्राथमिक उपयोगकर्ता आधार भूगोल द्वारा सीमित था। इसने कई *संभावित* उपयोगकर्ताओं को उपेक्षित छोड़ दिया। उदाहरण के लिए, जर्मनी में एक डेवलपर जो Claude के 100k संदर्भ में रुचि रखता था, उसके पास इसका उपयोग करने का कोई आधिकारिक तरीका नहीं था। जबकि वर्कअराउंड मौजूद हैं (तृतीय-पक्ष प्लेटफार्म, या वीपीएन + समर्थित देश में फोन सत्यापन), ये बाधाएं आकस्मिक अंतरराष्ट्रीय उपयोगकर्ताओं को प्रभावी रूप से बंद कर देती हैं। इसके विपरीत, ChatGPT अधिकांश देशों में उपलब्ध है। इसलिए, गैर-अमेरिकी अंग्रेजी बोलने वाले और विशेष रूप से गैर-अंग्रेजी बोलने वाले Claude के सीमित रोलआउट द्वारा उपेक्षित रहे हैं। वे केवल पहुंच के मुद्दों के कारण ChatGPT या स्थानीय मॉडलों पर भरोसा कर सकते हैं।

- **सख्त आउटपुट स्वरूपण की आवश्यकता वाले उपयोगकर्ता:** जैसा कि उल्लेख किया गया है, Claude कभी-कभी प्रतिक्रियाओं में स्वतंत्रता लेता है। जिन्हें अत्यधिक संरचित आउटपुट की आवश्यकता होती है (जैसे किसी एप्लिकेशन के लिए JSON, या एक सटीक प्रारूप का पालन करने वाला उत्तर) उन्हें ChatGPT की तुलना में इसके लिए Claude कम विश्वसनीय लग सकता है। ये उपयोगकर्ता - अक्सर एआई को किसी सिस्टम में एकीकृत करने वाले डेवलपर्स - एक खंड है जिसे Claude एक "सख्त मोड" की अनुमति देता है या निर्देशों के पालन में सुधार करता है। वे वर्तमान में Claude को ऐसे कार्यों के लिए टाल सकते हैं, उन मॉडलों के साथ चिपके रहते हैं जो प्रारूपों का अधिक सख्ती से पालन करने के लिए जाने जाते हैं।

- **आकस्मिक प्रश्नोत्तर उपयोगकर्ता (बनाम रचनात्मक उपयोगकर्ता):** Claude को अक्सर रचनात्मक कार्यों के लिए सराहा जाता है - यह प्रवाहमयी, मानव-समान गद्य और विचारशील निबंध उत्पन्न करता है। हालांकि, कुछ उपयोगकर्ताओं ने Reddit पर नोट किया कि सीधे प्रश्न-उत्तर या तथ्यात्मक प्रश्नों के लिए, Claude कभी-कभी लंबी प्रतिक्रियाएँ देता है जहाँ संक्षिप्तता पर्याप्त होती। जिसने ChatGPT और Claude की तुलना की, उसने कहा कि ChatGPT संक्षिप्त और बुलेट-पॉइंटेड होता है, जबकि Claude डिफ़ॉल्ट रूप से अधिक वर्णनात्मक होता है। जो उपयोगकर्ता केवल एक त्वरित तथ्यात्मक उत्तर चाहते हैं (जैसे "X की राजधानी क्या है और इसकी जनसंख्या क्या है?") उन्हें Claude थोड़ा अप्रत्यक्ष लग सकता है। ये उपयोगकर्ता कुछ ऐसा पसंद करते हैं जैसे एक सटीक खोज या एक संक्षिप्त मॉडल। Claude इसे मांगने पर कर सकता है, लेकिन इसकी शैली एक संक्षिप्त प्रश्नोत्तर की अपेक्षा से मेल नहीं खा सकती है, जिसका अर्थ है कि यह खंड अन्य उपकरणों (जैसे Bing Chat या Google) की ओर जा सकता है।

- **सुरक्षा-महत्वपूर्ण उपयोगकर्ता:** इसके विपरीत, कुछ उपयोगकर्ता जिन्हें सुरक्षा के प्रति बहुत सावधानीपूर्वक पालन की आवश्यकता होती है (उदाहरण के लिए, छात्रों के साथ एआई का उपयोग करने वाले शिक्षक, या एंटरप्राइज़ ग्राहक जो दुष्ट आउटपुट का शून्य जोखिम चाहते हैं) Claude के संरेखण को एक प्लस मान सकते हैं, लेकिन चूंकि ChatGPT भी काफी संरेखित है और इसमें अधिक एंटरप्राइज़ सुविधाएँ हैं, वे उपयोगकर्ता विशेष रूप से Claude को नहीं चुन सकते। यह एक छोटा खंड है, लेकिन कोई तर्क दे सकता है कि Claude ने इसे अभी तक स्पष्ट रूप से नहीं पकड़ा है। वे इस मायने में उपेक्षित हैं कि उनके पास Claude के सुरक्षा उपायों को *बढ़ाने* या इसके "विचार की श्रृंखला" देखने का कोई आसान तरीका नहीं है (जो Anthropic के पास आंतरिक रूप से संवैधानिक एआई दृष्टिकोण के माध्यम से है, लेकिन अंतिम उपयोगकर्ता सीधे इसके साथ इंटरफ़ेस नहीं करते हैं, सिवाय इसके कि Claude के आम तौर पर विनम्र स्वर को नोटिस करने के अलावा)।

- **गैर-अंग्रेजी बोलने वाले (आउटपुट की गुणवत्ता):** Claude को मुख्य रूप से अंग्रेजी में प्रशिक्षित किया गया था (जैसे अधिकांश बड़े LLMs)। कुछ उपयोगकर्ताओं ने इसे अन्य भाषाओं में आज़माया है; यह कई भाषाओं में प्रतिक्रिया दे सकता है, लेकिन गुणवत्ता भिन्न हो सकती है। यदि, मान लें, कोई उपयोगकर्ता फ्रेंच या हिंदी में एक बहुत ही बारीक उत्तर चाहता है, तो संभव है कि Claude की क्षमताएँ वहाँ उतनी अच्छी न हों जितनी ChatGPT की (GPT-4 ने मजबूत बहुभाषी प्रदर्शन का प्रदर्शन किया है, कुछ बेंचमार्क में अक्सर अन्य मॉडलों की तुलना में उच्चतर)। जो उपयोगकर्ता मुख्य रूप से अंग्रेजी के अलावा अन्य भाषाओं में बातचीत करते हैं, उन्हें Claude की प्रवाह या सटीकता थोड़ी कमजोर लग सकती है। यह खंड कुछ हद तक उपेक्षित है क्योंकि Anthropic ने सार्वजनिक रूप से बहुभाषी प्रशिक्षण को प्राथमिकता के रूप में उजागर नहीं किया है।

### उपयोगकर्ता प्रकार द्वारा धारणा में अंतर

- **डेवलपर्स/तकनीकी उपयोगकर्ता:** Reddit पर डेवलपर्स ने विशेष रूप से कोडिंग कार्यों के लिए Claude, विशेष रूप से Claude 2 / Claude 3.5 की प्रशंसा की है। 2024 के अंत में धारणा में बदलाव उल्लेखनीय था: कई डेवलपर्स ने प्रोग्रामिंग सहायता के लिए ChatGPT पर Claude को पसंद करना शुरू कर दिया। वे *“कोडिंग में अद्भुत”* प्रदर्शन और एक बार में बड़े कोडबेस को संभालने की क्षमता का हवाला देते हैं। उदाहरण के लिए, एक उपयोगकर्ता ने लिखा *“Claude Sonnet 3.5 कोड के साथ काम करने के लिए बेहतर है (विश्लेषण, उत्पन्न) [ChatGPT की तुलना में]।”* डेवलपर्स सराहना करते हैं कि Claude प्रोजेक्ट कोड या लॉग के एक बड़े हिस्से को ले सकता है और सुसंगत विश्लेषण या सुधार उत्पन्न कर सकता है, इसके विशाल संदर्भ के लिए धन्यवाद। हालांकि, वे इसकी विचित्रताओं को भी नोटिस करते हैं - जैसे कभी-कभी अधिक बातचीतपूर्ण फुलाना इंजेक्ट करना या एक विनिर्देश का अक्षरशः पालन न करना। संतुलन पर, कई देव दोनों ChatGPT और Claude को हाथ में रखते हैं: एक कठोर कदम-दर-चरण तर्क के लिए (ChatGPT) और एक व्यापक संदर्भ और सहानुभूतिपूर्ण समझ के लिए (Claude)। यह बताना महत्वपूर्ण है कि एक टिप्पणीकार ने कहा *“अगर मुझे एक चुनना होता तो मैं Claude को चुनता”* दोनों की दैनिक तुलना के बाद। यह उन्नत उपयोगकर्ताओं के बीच एक बहुत ही सकारात्मक धारणा को इंगित करता है, विशेष रूप से विचार-मंथन, कोड समीक्षा, या वास्तुशिल्प सुझावों जैसे उपयोग के मामलों के लिए। डेवलपर्स की एकमात्र सामान्य शिकायत Claude की उपयोग सीमा को धक्का देने पर होती है (उदाहरण के लिए, एक पूरे रिपॉजिटरी का विश्लेषण करने के लिए 50K-टोकन संकेत खिलाना)। संक्षेप में, डेवलपर्स Claude को एक अत्यधिक शक्तिशाली उपकरण के रूप में देखते हैं - कुछ मामलों में ChatGPT से बेहतर - केवल उपलब्धता और स्वरूपण में कुछ अप्रत्याशितता से बाधित।

- **आकस्मिक/गैर-तकनीकी उपयोगकर्ता:** जिन्होंने Claude को आज़माया, वे अक्सर टिप्पणी करते हैं कि यह *मैत्रीपूर्ण और स्पष्टवादी* है। Claude की शैली बातचीतपूर्ण, विनम्र, और विस्तृत होती है। ChatGPT की तुलना में एक नए उपयोगकर्ता ने देखा कि *“Claude अधिक सहानुभूतिपूर्ण है, और एक बातचीतपूर्ण स्वर का पालन करता है... ChatGPT अक्सर बुलेट पॉइंट्स में डिफ़ॉल्ट होता है”*। यह मानव-समान गर्मजोशी Claude को उन लोगों के लिए आकर्षक बनाती है जो इसे रचनात्मक लेखन, सलाह, या सिर्फ जानकारी के लिए चैटिंग के लिए उपयोग कर रहे हैं। कुछ लोग यहां तक कि Claude को "व्यक्तित्व" के रूप में मानते हैं जो दयालु है। आकस्मिक उपयोगकर्ताओं को यह भी पसंद है कि Claude के मुफ्त संस्करण ने बिना सदस्यता के GPT-4-स्तरीय बुद्धिमत्ता तक पहुंच की अनुमति दी (कम से कम दर सीमा तक)। दूसरी ओर, आकस्मिक उपयोगकर्ता Claude की कुछ विषयों पर अस्वीकृति में भी आ सकते हैं और यह समझ नहीं सकते कि क्यों (क्योंकि Claude इसे माफी के साथ लेकिन दृढ़ता से व्यक्त करेगा)। यदि एक आकस्मिक उपयोगकर्ता ने कुछ सीमा रेखा पूछा और Claude से अस्वीकृति प्राप्त की, तो वे इसे कम सक्षम या बहुत सीमित मान सकते हैं, यह महसूस नहीं करते कि यह एक नीति रुख है। एक और पहलू यह है कि Claude में नाम की पहचान की कमी है - कई आकस्मिक उपयोगकर्ता यह भी नहीं जानते होंगे कि इसे आज़माना है जब तक कि वे एआई समुदायों से जुड़े न हों। जो लोग आज़माते हैं वे आम तौर पर टिप्पणी करते हैं कि यह *“मानव से बात करने जैसा लगता है”* एक अच्छे तरीके से। वे Claude की *आउटपुट गुणवत्ता और स्वर* के बारे में बड़े पैमाने पर संतुष्ट होते हैं, इसकी उपलब्धता (किसी विशेष ऐप या क्षेत्र में इसका उपयोग करना) और कभी-कभी "यह नहीं कर सकता" क्षणों के आसपास कुछ भ्रम या निराशा के साथ।

- **व्यवसाय/पेशेवर उपयोगकर्ता:** Reddit से सार्वजनिक रूप से पेशेवरों की धारणा को मापना थोड़ा कठिन है (क्योंकि कम एंटरप्राइज़ उपयोगकर्ता विस्तार से पोस्ट करते हैं), लेकिन कुछ रुझान उभरते हैं। सबसे पहले, Anthropic ने Claude को अधिक *गोपनीयता-केंद्रित* और एंटरप्राइज़ समझौतों पर हस्ताक्षर करने के इच्छुक के रूप में स्थान दिया है - यह उन कंपनियों से अपील करता है जो OpenAI के साथ डेटा के बारे में चिंतित हैं। वास्तव में, कुछ Reddit चर्चाएँ Claude को Slack या Notion जैसे टूल्स के संदर्भ में उल्लेख करती हैं, जहां इसे सहायक के रूप में एकीकृत किया गया है। जिन्होंने उन एकीकरणों का उपयोग किया है, वे यह भी नहीं जानते होंगे कि Claude इंजन है, लेकिन जब वे करते हैं, तो वे लेखन शैली और बड़े कॉर्पोरेट दस्तावेजों को पचाने की क्षमता के संदर्भ में इसकी तुलना अनुकूल रूप से करते हैं। उदाहरण के लिए, एक टीम Claude को एक लंबी त्रैमासिक रिपोर्ट खिला सकती है और एक अच्छा सारांश प्राप्त कर सकती है - कुछ ऐसा जो ChatGPT का छोटा संदर्भ संघर्ष करेगा। यह कहा जा रहा है, व्यावसायिक उपयोगकर्ता कुछ पारिस्थितिकी तंत्र सुविधाओं की कमी को भी नोटिस करते हैं; उदाहरण के लिए, OpenAI अपने एपीआई में सिस्टम संदेश नियंत्रण, फ़ंक्शन कॉलिंग, आदि प्रदान करता है, जिसका Anthropic में अधिक सीमित समर्थन है। एक व्यवसाय समाधान पर काम कर रहे एक डेवलपर ने टिप्पणी की कि *Claude वार्तालापों में अधिक स्टीरेबल है, जबकि ChatGPT अधिक कठोर होता है... [लेकिन] ChatGPT के पास वेब एक्सेस है जो बहुत सहायक हो सकता है*। निहितार्थ यह है कि एक व्यावसायिक उपयोगकर्ता को जिन शोध या डेटा लुकअप कार्यों की आवश्यकता हो सकती है (जैसे प्रतिस्पर्धी खुफिया), ChatGPT सीधे जानकारी प्राप्त कर सकता है, जबकि Claude को एक अलग कदम की आवश्यकता होगी। कुल मिलाकर, व्यावसायिक उपयोगकर्ता Claude को एक बहुत ही सक्षम एआई के रूप में देखते हैं - कुछ मामलों में आंतरिक विश्लेषणात्मक कार्यों के लिए *बेहतर* - लेकिन शायद अभी तक एकीकरण के लिए उतना फीचर-समृद्ध नहीं है। लागत एक और कारक है: Claude की एपीआई मूल्य निर्धारण और शर्तें OpenAI की तरह सार्वजनिक नहीं हैं, और कुछ स्टार्टअप्स ने Reddit पर Claude की कीमत या स्थिरता के बारे में अनिश्चितता का उल्लेख किया है। संक्षेप में, पेशेवर Claude की क्षमताओं का सम्मान करते हैं (विशेष रूप से उच्च-स्तरीय निर्देशों का पालन करने और बड़े इनपुट का सारांश देने में इसकी विश्वसनीयता), लेकिन वे इसे OpenAI की तुलना में पूरी तरह से प्रतिबद्ध करने से पहले एकीकरण, समर्थन, और वैश्विक उपलब्धता के संदर्भ में कैसे विकसित होता है, इस पर नज़र रखते हैं।

---

## Google Gemini (Bard)

### सामान्य समस्याएँ और सीमाएँ

- **गलत या "मूर्ख" प्रतिक्रियाएँ:** जब Google ने अपने Gemini-संचालित Bard अपग्रेड को लॉन्च किया, तो Reddit प्रतिक्रिया की बाढ़ आ गई, जिनमें से अधिकांश नकारात्मक थी। उपयोगकर्ताओं ने शिकायत की कि Gemini **बुनियादी QA में ChatGPT की तुलना में कम प्रदर्शन करता है**। "Google Gemini पर 100% ईमानदार राय" शीर्षक वाली एक स्पष्ट मूल्यांकन ने कहा: *“यह एक टूटा हुआ, गलत LLM चैटबॉट है”*। एक अन्य निराश उपयोगकर्ता ने पूछा: *“Gemini अभी भी इतना बेकार कैसे है? मैं Gemini से कुछ पूछता हूँ और यह या तो गलत उत्तर देता है या अधूरे उत्तर देता है, यह हास्यास्पद है”*। उन्होंने इसे ChatGPT-4 के साथ साइड-बाय-साइड तुलना की और पाया कि ChatGPT ने *“एक बार में सही, कुशल उत्तर दिया,”* जबकि Gemini ने बकवास किया और सही जानकारी निकालने के लिए कई संकेतों की आवश्यकता थी। सारांश में, शुरुआती उपयोगकर्ताओं ने महसूस किया कि Gemini अक्सर **भ्रमित हो जाता है या प्रश्नों का उद्देश्य चूक जाता है**, सही जानकारी निकालने के लिए अत्यधिक संकेत प्रयास की आवश्यकता होती है। इस गुणवत्ता में असंगति Gemini के आसपास के प्रचार को देखते हुए एक बड़ी निराशा थी।

- **अत्यधिक शब्दाडंबर और फुलाना:** कई उपयोगकर्ताओं ने नोट किया कि Gemini (नए Bard के रूप में) लंबी-लंबी प्रतिक्रियाएँ उत्पन्न करता है जो बिंदु पर नहीं आतीं। जैसा कि एक व्यक्ति ने वर्णन किया, *“यह बकवास करता रहा... 3 पैराग्राफ एआई कचरा... तब भी, यह [केवल] अंततः उत्तर का उल्लेख करता है जो कचरे के पैराग्राफ में दफन है”*। यह ChatGPT के विपरीत है, जो अक्सर अधिक संक्षिप्त उत्तर या बुलेट पॉइंट्स प्रदान करता है जब उपयुक्त हो। जब उपयोगकर्ताओं को एक साधारण तथ्य के लिए बहुत सारे पाठ को छानना पड़ता है तो शब्दाडंबर एक समस्या बन जाता है। कुछ ने अनुमान लगाया कि Google ने इसे बातचीतपूर्ण या "सहायक" बनाने के लिए ट्यून किया हो सकता है, लेकिन बिना पदार्थ के *बहुत अधिक* स्पष्टीकरण में ओवरशूट किया।

- **Google की अपनी सेवाओं के साथ खराब एकीकरण:** Google के एआई सहायक का एक विक्रय बिंदु Google के पारिस्थितिकी तंत्र (Gmail, Docs, Drive, आदि) के साथ एकीकरण माना जाता है। हालांकि, इस मोर्चे पर शुरुआती उपयोगकर्ता अनुभव बहुत निराशाजनक थे। एक उपयोगकर्ता ने वेंट किया: *“Google के अपने उत्पादों के साथ एकीकृत करने में इसकी लगभग पूर्ण अक्षमता पर मुझे शुरू भी न करें जो कि एक 'फीचर' माना जाता है (जिसके बारे में यह स्पष्ट रूप से नहीं जानता कि यह है)।”*। उदाहरण के लिए, लोग Gemini (Bard के माध्यम से) से Google Doc का सारांश देने या कुछ जानकारी के आधार पर एक ईमेल का मसौदा तैयार करने के लिए कहने की कोशिश करेंगे - Google द्वारा विज्ञापित सुविधाएँ - और बॉट जवाब देगा कि यह **उस डेटा तक पहुंच नहीं सकता**। r/GooglePixel पर एक उपयोगकर्ता ने लिखा: *“हर बार जब मैं अपने Google Docs या Drive के साथ Gemini का उपयोग करने की कोशिश करता हूँ, तो यह मुझे बताता है कि यह इसके साथ कुछ नहीं कर सकता। इन एकीकरण सुविधाओं के होने का क्या मतलब है?”*। यह दिखाता है कि वादा की गई क्षमताओं और वास्तविक प्रदर्शन के बीच एक महत्वपूर्ण अंतर है, जिससे उपयोगकर्ताओं को यह महसूस होता है कि "एआई सहायक" Google के अपने पारिस्थितिकी तंत्र के भीतर बहुत अधिक सहायता नहीं कर रहा है।

- **अस्वीकृति और क्षमता भ्रम:** उपयोगकर्ताओं को Gemini से अजीब अस्वीकृति या विरोधाभास भी मिले। उसी Redditor ने नोट किया कि Gemini *“बिना किसी कारण के चीजें करने से इनकार करता है, भूल जाता है कि यह अन्य चीजें कर सकता है... दूसरे दिन इसने मुझे बताया कि इसे इंटरनेट/लाइव डेटा तक पहुंच नहीं है। क्या।”*। यह इंगित करता है कि Gemini कभी-कभी **ऐसे कार्यों को अस्वीकार कर देगा जिन्हें यह करने में सक्षम होना चाहिए** (जैसे लाइव जानकारी पुनः प्राप्त करना, जिसे Bard से जोड़ा गया है) या अपनी क्षमताओं के बारे में गलत बयान देगा। ऐसे अनुभवों ने एक एआई का प्रभाव दिया जो न केवल कम बुद्धिमान है, बल्कि **कम विश्वसनीय या आत्म-जागरूक** भी है। एक अन्य उपयोगकर्ता की रंगीन टिप्पणी: *“Gemini बिल्कुल बेकार है। क्या आपके पास कभी ऐसा क्षण आया है जब आप बस अपने हाथ ऊपर उठाना चाहते हैं और कहना चाहते हैं, 'वे क्या सोच रहे थे?'”* निराशा को समेटता है। अनिवार्य रूप से, Gemini की उत्पाद एकीकरण और स्थिरता के मुद्दों ने इसे कई शुरुआती अपनाने वालों के लिए *अधपका* महसूस कराया।

- **असाधारण कोडिंग क्षमताएँ:** जबकि सामान्य प्रश्नोत्तर के रूप में व्यापक रूप से चर्चा नहीं की गई, कई उपयोगकर्ताओं ने Gemini (Bard) को कोडिंग कार्यों पर परीक्षण किया और इसे कमतर पाया। एआई मंचों में, Gemini की कोडिंग क्षमताओं को आमतौर पर GPT-4 और यहां तक कि Claude से नीचे रेट किया गया था। उदाहरण के लिए, एक उपयोगकर्ता ने स्पष्ट रूप से कहा कि *“Claude 3.5 Sonnet स्पष्ट रूप से ChatGPT 4o की तुलना में कोडिंग के लिए बेहतर है... Gemini उस संदर्भ में बिल्कुल बेकार है”*। आम सहमति थी कि Gemini सरल कोड लिख सकता है या बुनियादी एल्गोरिदम की व्याख्या कर सकता है, लेकिन यह अक्सर अधिक जटिल समस्याओं पर ठोकर खाता है या त्रुटियों के साथ कोड उत्पन्न करता है। इसके पास एक व्यापक डेवलपर टूलसेट की कमी (जैसे, इसका कोड इंटरप्रेटर या मजबूत फ़ंक्शन कॉलिंग के समकक्ष नहीं है) का मतलब यह नहीं था कि यह प्रोग्रामर के लिए पहली पसंद नहीं था। इसलिए, जबकि हर आकस्मिक उपयोगकर्ता को कोड की परवाह नहीं है, यह उस खंड के लिए एक सीमा है।

- **मोबाइल डिवाइस सीमाएँ:** Gemini को Google के सहायक के हिस्से के रूप में Pixel फोन पर रोल आउट किया गया (जिसे "Bard के साथ सहायक" के रूप में ब्रांडेड किया गया)। कुछ Pixel उपयोगकर्ताओं ने नोट किया कि इसे वॉयस असिस्टेंट रिप्लेसमेंट के रूप में उपयोग करने में समस्याएँ थीं। यह कभी-कभी वॉयस संकेतों को सटीक रूप से नहीं उठाता था या पुराने Google सहायक की तुलना में प्रतिक्रिया देने में बहुत लंबा समय लेता था। कुछ क्लासिक सहायक सुविधाओं को चुनने और खोने की आवश्यकता के बारे में भी टिप्पणियाँ थीं। इससे यह धारणा बनी कि *Gemini का डिवाइस पर एकीकरण पूरी तरह से तैयार नहीं था*, जिससे Google के पारिस्थितिकी तंत्र के पावर उपयोगकर्ताओं को यह महसूस हुआ कि उन्हें एक स्मार्ट सहायक और एक कार्यात्मक सहायक के बीच चयन करना होगा।

### अक्सर अनुरोधित सुविधाएँ या सुधार

- **ड्रामेटिक रूप से बेहतर सटीकता और तर्क:** उपयोगकर्ता Gemini के लिए नंबर एक सुधार चाहते हैं कि यह **अधिक स्मार्ट और अधिक विश्वसनीय हो**। Reddit प्रतिक्रिया स्पष्ट करती है कि Google को उत्तर गुणवत्ता में अंतर को बंद करने की आवश्यकता है। उपयोगकर्ता उम्मीद करते हैं कि Gemini Google की विशाल जानकारी का उपयोग करके *तथ्यात्मक, प्रत्यक्ष उत्तर* दे, न कि भटकने वाले या गलत। इसलिए अनुरोध (अक्सर व्यंग्यात्मक रूप से व्यक्त किए गए) इस प्रकार हैं: *इसे सामान्य ज्ञान और तर्क पर GPT-4 के बराबर या बेहतर बनाएं।* इसमें अनुवर्ती प्रश्नों और जटिल संकेतों को बेहतर ढंग से संभालना शामिल है। अनिवार्य रूप से, "Gemini के मस्तिष्क को ठीक करें" - उन कथित मल्टीमॉडल प्रशिक्षण लाभों का लाभ उठाएं ताकि यह स्पष्ट विवरणों को याद करना बंद कर दे। Google ने संभवतः इसे जोर से और स्पष्ट रूप से सुना है: कई पोस्ट विशिष्ट उत्तरों की तुलना करते हैं जहां ChatGPT उत्कृष्ट था और Gemini विफल रहा, जो सुधार के लिए अनौपचारिक बग रिपोर्ट के रूप में कार्य करता है।

- **बेहतर एकीकरण और संदर्भ की जागरूकता:** उपयोगकर्ता चाहते हैं कि Gemini एक निर्बाध Google पारिस्थितिकी तंत्र सहायक के वादे को पूरा करे। इसका मतलब है कि इसे **Gmail, Calendar, Docs, Drive आदि के साथ ठीक से इंटरफेस करना चाहिए**। यदि कोई उपयोगकर्ता पूछता है "मैंने जो दस्तावेज़ खोला है उसका सारांश दें" या "मेरे बॉस से अंतिम ईमेल का उत्तर तैयार करें," एआई को इसे करना चाहिए - और इसे सुरक्षित रूप से करना चाहिए। अभी के लिए, अनुरोध यह है कि Google *उन सुविधाओं को सक्षम करे और वास्तव में पहचान करे कि जब ऐसा कार्य संभव हो*। यह विज्ञापित किया गया था कि Bard उपयोगकर्ता सामग्री (अनुमति के साथ) से जुड़ सकता है, इसलिए उपयोगकर्ता प्रभावी रूप से Google से "इसे चालू" करने या इस एकीकरण को ठीक करने की मांग कर रहे हैं। यह विशेष रूप से व्यावसायिक उपयोगकर्ताओं के लिए एक प्रमुख विशेषता है। इसके अलावा, वेब ब्राउज़िंग फ्रंट पर: Bard (Gemini) वेब खोज सकता है, लेकिन कुछ उपयोगकर्ता चाहते हैं कि यह स्रोतों का अधिक स्पष्ट रूप से हवाला दे या ब्रेकिंग न्यूज़ को शामिल करने में अधिक समय पर हो। इसलिए Gemini की *कनेक्टेड* प्रकृति में सुधार एक बार-बार अनुरोधित सुविधा है।

- **संक्षिप्तता नियंत्रण:** शब्दाडंबर की शिकायतों को देखते हुए, कुछ उपयोगकर्ता प्रतिक्रिया शैली को टॉगल करने की सुविधा का सुझाव देते हैं। उदाहरण के लिए, एक *“संक्षिप्त मोड”* जहां Gemini डिफ़ॉल्ट रूप से एक छोटा, बिंदु-पर उत्तर देता है, जब तक कि विस्तार से पूछने के लिए न कहा जाए। इसके विपरीत, शायद एक "विस्तृत मोड" उन लोगों के लिए जो बहुत विस्तृत उत्तर चाहते हैं। ChatGPT कुछ हद तक उपयोगकर्ता संकेत ("इसे संक्षिप्त रखें") द्वारा इसकी अनुमति देता है; Gemini के साथ, उपयोगकर्ताओं को लगा कि जब उन्होंने विस्तार के लिए नहीं कहा, तब भी इसने अधिक व्याख्या की। इसलिए एक अंतर्निहित सेटिंग या केवल बेहतर ट्यूनिंग जो उपयुक्त होने पर संक्षिप्त उत्तर उत्पन्न करती है, एक स्वागत योग्य सुधार होगा। अनिवार्य रूप से, शब्दाडंबर डायल को समायोजित करें।

- **ChatGPT के साथ फीचर समानता (कोडिंग, प्लगइन्स, आदि):** Reddit पर पावर उपयोगकर्ता स्पष्ट रूप से सुविधाओं की तुलना करते हैं। वे अनुरोध करते हैं कि Google का Gemini/Bard चीजें जैसे *कोड निष्पादन सैंडबॉक्स* (ChatGPT के कोड इंटरप्रेटर के समान), विश्लेषण के लिए छवियों/पीडीएफ को अपलोड करने की क्षमता (चूंकि Gemini मल्टीमॉडल है, उपयोगकर्ता वास्तव में इसे कस्टम छवियों को खिलाना चाहते हैं, न कि केवल प्रदान की गई छवियों का वर्णन करना)। एक अन्य बार-बार उल्लेख की गई सुविधा बेहतर **वार्तालाप के भीतर स्मृति** है - जबकि Bard में पिछले इंटरैक्शन की कुछ स्मृति है, उपयोगकर्ता चाहते हैं कि यह संदर्भ का संदर्भ देने में ChatGPT जितना अच्छा हो, या यहां तक कि ChatGPT के चैट इतिहास की तरह स्थायी बातचीत भंडारण हो जिसे आप स्क्रॉल कर सकते हैं और फिर से देख सकते हैं। अनिवार्य रूप से, Google से उन सभी गुणवत्ता-जीवन सुविधाओं को पकड़ने के लिए कहा जा रहा है जो ChatGPT Plus उपयोगकर्ताओं के पास हैं: चैट इतिहास, प्लगइन पारिस्थितिकी तंत्र (या कम से कम मजबूत तृतीय-पक्ष एकीकरण), कोडिंग सहायता, आदि।

- **मोबाइल ऐप और वॉयस सुधार:** कई आकस्मिक उपयोगकर्ताओं ने Bard/Gemini के लिए एक **समर्पित मोबाइल ऐप** का अनुरोध किया (ChatGPT मोबाइल ऐप के समान)। वेब इंटरफ़ेस पर निर्भर रहना या केवल Pixel सहायक सीमित है। iOS/Android पर एक आधिकारिक ऐप जिसमें वॉयस इनपुट, बोलने वाली प्रतिक्रियाएँ (एक सच्चे सहायक अनुभव के लिए), और तंग एकीकरण उपयोगकर्ता अनुभव को काफी हद तक सुधार सकता है। इसके साथ ही, Pixel मालिक चाहते हैं कि Bard के साथ सहायक तेज़ और अधिक कार्यात्मक हो जाए - मूल रूप से, वे पुराने Google सहायक की सर्वश्रेष्ठता चाहते हैं (त्वरित, सटीक क्रियाएँ) Gemini की बुद्धिमत्ता के साथ संयुक्त। उदाहरण के लिए, "हे Google" स्मार्ट होम वॉयस कमांड को जारी रखने जैसी चीजें और न कि केवल चैट उत्तर। Google Gemini के वॉयस मोड को वास्तव में पुराने सहायक को प्रतिस्थापित करने के लिए सुधार सकता है बिना फीचर रिग्रेशन के।

- **पारदर्शिता और नियंत्रण:** कुछ उपयोगकर्ताओं ने Bard के स्रोतों में अधिक अंतर्दृष्टि या इसकी शैली को ठीक करने का तरीका मांगा है। उदाहरण के लिए, यह दिखाना कि Bard किस Google परिणाम से जानकारी खींच रहा है (सटीकता को सत्यापित करने के लिए) - कुछ ऐसा जो Bing Chat लिंक का हवाला देकर करता है। इसके अलावा, क्योंकि Bard कभी-कभी गलत जानकारी उत्पन्न करता है, उपयोगकर्ता इसे चिह्नित या सुधारने में सक्षम होना चाहते हैं, और आदर्श रूप से Bard को समय के साथ उस फीडबैक से सीखना चाहिए। एक आसान फीडबैक तंत्र ("थंब्स डाउन - यह गलत है क्योंकि...") होना जो तेजी से मॉडल सुधार की ओर ले जाता है, यह विश्वास पैदा करेगा कि Google सुन रहा है। मूल रूप से, एआई को एक सहयोगी सहायक बनाने के लिए सुविधाएँ, न कि एक ब्लैक बॉक्स।

### उपेक्षित आवश्यकताएँ या उपयोगकर्ता खंड

- **एक विश्वसनीय व्यक्तिगत सहायक की तलाश करने वाले उपयोगकर्ता:** विडंबना यह है कि Google ने जिस समूह को *लक्षित* किया - एक शक्तिशाली व्यक्तिगत सहायक चाहने वाले लोग - वर्तमान रूप में Gemini द्वारा सबसे अधिक उपेक्षित महसूस करते हैं। जिन्होंने नए Bard-आधारित सहायक को चालू किया, उन्होंने अपग्रेड की उम्मीद की, लेकिन कई लोगों ने इसे व्यावहारिक रूप से डाउनग्रेड महसूस किया। उदाहरण के लिए, यदि कोई व्यक्ति एक वॉयस सहायक चाहता है जो *सटीक रूप से* उत्तर दे, अनुस्मारक सेट करे, उपकरणों को नियंत्रित करे, और उनके खातों से जानकारी एकीकृत करे, तो Gemini संघर्ष करता है। इससे व्यस्त पेशेवरों या गैजेट उत्साही लोगों के बहुत खंड को यह महसूस होता है कि उनकी आवश्यकताओं को पूरा नहीं किया गया। एक उपयोगकर्ता ने टिप्पणी की कि वे Pixel के "Bard के साथ सहायक" के लिए भुगतान करने पर विचार करेंगे *"यदि [यह] Google सहायक को पार कर जाए,"* यह दर्शाता है कि यह अभी तक नहीं हुआ है। इसलिए वह खंड अभी भी एक विश्वसनीय, वास्तव में सहायक एआई सहायक की प्रतीक्षा कर रहा है - यदि Gemini में सुधार होता है तो वे इस पर कूदेंगे।

- **गैर-देशी अंग्रेजी बोलने वाले / स्थानीयकरण:** Google उत्पादों में आमतौर पर उत्कृष्ट स्थानीयकरण होता है, लेकिन यह स्पष्ट नहीं है कि Bard/Gemini लॉन्च के समय सभी भाषाओं में समान रूप से मजबूत था। कुछ अंतरराष्ट्रीय उपयोगकर्ताओं ने बताया कि उनकी मूल भाषा में Bard के उत्तर कम प्रवाहमयी या उपयोगी थे, उन्हें स्थानीय प्रतिस्पर्धियों की ओर धकेलते हुए। यदि Gemini का प्रशिक्षण डेटा या अनुकूलन अंग्रेजी का पक्षधर था, तो गैर-अंग्रेजी उपयोगकर्ता उपेक्षित हैं। वे ChatGPT या स्थानीय मॉडलों को पसंद कर सकते हैं जिन्होंने स्पष्ट रूप से बहुभाषी क्षमताओं का अनुकूलन किया है। यह एक ऐसा स्थान है जिसमें Google पारंपरिक रूप से उत्कृष्टता प्राप्त कर सकता है (इसके अनुवाद तकनीक को देखते हुए), लेकिन उस पर उपयोगकर्ता प्रतिक्रिया दुर्लभ है - संभवतः यह संकेत दे रहा है कि Gemini ने अभी तक उन समुदायों को प्रभावित नहीं किया है।

- **एंटरप्राइज़ ग्राहक (अब तक):** सार्वजनिक चर्चा के आधार पर बड़े संगठनों ने Bard/Gemini को व्यापक रूप से नहीं अपनाया है, अक्सर विश्वास और क्षमता अंतराल के कारण। उद्यमों को स्थिरता, उद्धरण, और उनके वर्कफ़्लो के साथ एकीकरण की आवश्यकता होती है (Office 365 OpenAI की तकनीक के साथ MS Copilot के माध्यम से गहराई से एकीकृत है, उदाहरण के लिए)। Google का समकक्ष (Duet AI with Gemini) अभी भी विकसित हो रहा है। जब तक Gemini/Bard यह साबित नहीं करता कि यह ईमेल का मसौदा तैयार करने, स्लाइड डेक बनाने, या Google शीट्स में डेटा का विश्लेषण करने में विश्वसनीय रूप से सक्षम है, एंटरप्राइज़ उपयोगकर्ता महसूस करेंगे कि Google का समाधान उनकी आवश्यकताओं को पूरी तरह से संबोधित नहीं कर रहा है। r/Bard पर पेशेवरों से कुछ पोस्ट इस प्रकार हैं "मैंने कार्य कार्यों के लिए Bard की कोशिश की, यह ChatGPT के रूप में अच्छा नहीं था, इसलिए हम देखेंगे और इंतजार करेंगे।" यह इंगित करता है कि एंटरप्राइज़ उपयोगकर्ता अभी के लिए एक उपेक्षित खंड हैं - वे एक एआई चाहते हैं जो Google Workspace में फिट हो और वास्तव में उत्पादकता को बढ़ावा दे बिना आउटपुट की निरंतर सत्यापन की आवश्यकता के।

- **Google पारिस्थितिकी तंत्र में उपयोगकर्ता जो एक-स्टॉप समाधान पसंद करते हैं:** उपयोगकर्ताओं का एक खंड है जो सब कुछ के लिए Google का उपयोग करता है (खोज, ईमेल, दस्तावेज़) और *खुशी से* सभी चैटबॉट आवश्यकताओं के लिए Google एआई का उपयोग करेगा - यदि यह उतना ही अच्छा हो। अभी, उन उपयोगकर्ताओं को कुछ हद तक उपेक्षित किया जाता है क्योंकि वे कुछ चीजों के लिए ChatGPT और अन्य के लिए Bard का उपयोग करते हैं। वे ChatGPT से तथ्यात्मक प्रश्न पूछ सकते हैं क्योंकि वे इसके उत्तर की गुणवत्ता पर अधिक भरोसा करते हैं, लेकिन इसके ब्राउज़िंग या एकीकरण प्रयासों के लिए Bard का उपयोग करते हैं। वह विभाजित अनुभव आदर्श नहीं है। ऐसे उपयोगकर्ता वास्तव में बस एक ऐप/सहायक में रहना चाहते हैं। यदि Gemini में सुधार होता है, तो वे इसके चारों ओर समेकित हो जाएंगे, लेकिन तब तक "सभी को नियंत्रित करने के लिए एक सहायक" का उनका उपयोग मामला पूरा नहीं होता है।

- **Google क्लाउड पर डेवलपर्स/डेटा वैज्ञानिक:** Google ने अपने डेवलपर्स के लिए अपने Vertex AI प्लेटफॉर्म के माध्यम से Gemini मॉडल जारी किए। हालांकि, शुरुआती रिपोर्ट और बेंचमार्क ने सुझाव दिया कि Gemini (विशेष रूप से उपलब्ध "Gemini Pro" मॉडल) GPT-4 को नहीं हरा रहा था। जो डेवलपर्स एआई सेवाओं के लिए Google क्लाउड को पसंद करते हैं, वे मॉडल गुणवत्ता से कुछ हद तक उपेक्षित हैं - उन्हें या तो थोड़ा हीन मॉडल स्वीकार करना होगा या OpenAI के एपीआई को अलग से एकीकृत करना होगा। यह एंटरप्राइज़ डेवलपर खंड एक मजबूत Google मॉडल के लिए भूखा है ताकि वे सब कुछ एक स्टैक में रख सकें। जब तक Gemini का प्रदर्शन स्पष्ट रूप से कुछ क्षेत्रों में उत्कृष्ट नहीं होता या मूल्य निर्धारण एक सम्मोहक कारण प्रदान नहीं करता, यह इस समूह की जरूरतों को प्रतिस्पर्धी रूप से पूरी तरह से सेवा नहीं दे रहा है।

### उपयोगकर्ता प्रकार द्वारा धारणा में अंतर

- **डेवलपर्स/तकनीकी उत्साही:** तकनीकी-प्रेमी उपयोगकर्ताओं ने Gemini से उच्च उम्मीदों के साथ संपर्क किया (आखिरकार यह Google है)। उनके हाथों के परीक्षण के बाद उनकी धारणा जल्दी खराब हो गई। कई डेवलपर्स ने Reddit पर बेंचमार्क चलाए या अपने पसंदीदा पेचीदा प्रश्नों को Gemini के माध्यम से चलाया और इसे पिछड़ता हुआ पाया। एक प्रोग्रामर ने स्पष्ट रूप से कहा, *“Gemini बिल्कुल बेकार है जैसे Llama 3.0 हुआ करता था”*, यह संकेत देते हुए कि वे इसे कुछ ओपन मॉडलों से भी नीचे रैंक करते हैं। डेवलपर्स तार्किक त्रुटियों और शब्दाडंबर के प्रति विशेष रूप से संवेदनशील होते हैं। इसलिए जब Gemini ने शब्दाडंबर लेकिन गलत उत्तर दिए, तो उसने तेजी से विश्वसनीयता खो दी। दूसरी ओर, डेवलपर्स Google की क्षमता को पहचानते हैं; कुछ को उम्मीद है कि *“अधिक फाइन-ट्यूनिंग के साथ, Gemini बेहतर हो जाएगा”* और वे अपडेट के बाद इसे समय-समय पर फिर से परीक्षण करते हैं। वर्तमान में, हालांकि, अधिकांश देव इसे **गंभीर कार्यों में GPT-4 से कमतर** मानते हैं (कोडिंग, जटिल समस्या समाधान)। वे कुछ चीजों की सराहना करते हैं: उदाहरण के लिए, Gemini के पास वास्तविक समय की जानकारी (Google खोज के माध्यम से) तक पहुंच है बिना किसी प्लगइन की आवश्यकता के, जो अद्यतन प्रश्नों के लिए उपयोगी है। एक डेवलपर कुछ ऐसा करने के लिए Bard का उपयोग कर सकता है जैसे "X पर नवीनतम पत्रों को खोजें और सारांशित करें," जहां यह वेब डेटा का हवाला दे सकता है। लेकिन आत्म-निहित तर्क के लिए, वे अन्य मॉडलों की ओर झुकते हैं। संक्षेप में, तकनीकी उत्साही Gemini को एक आशाजनक कार्य-प्रगति के रूप में देखते हैं जो *वर्तमान में* एक पीढ़ी पीछे महसूस करता है। इसने उनकी पूरी विश्वास हासिल नहीं की है, और वे अक्सर Google को इसे सुधारने के लिए प्रेरित करने के लिए इसकी गलतियों को उजागर करने वाली साइड-बाय-साइड तुलना पोस्ट करते हैं।

- **आकस्मिक/दैनिक उपयोगकर्ता:** आकस्मिक उपयोगकर्ता, जिनमें वे लोग शामिल हैं जिन्हें अपने फोन पर या वेब के माध्यम से नया Bard एक्सेस मिला, की मिश्रित भावनाएँ थीं। कई आकस्मिक उपयोगकर्ताओं ने शुरू में Bard (Gemini) से संपर्क किया क्योंकि यह एक Google खाते के साथ मुफ्त और आसानी से सुलभ है, जबकि GPT-4 पेवॉल्ड था। कुछ आकस्मिक उपयोगकर्ता वास्तव में सरल उपयोगों के लिए अच्छे अनुभवों की रिपोर्ट करते हैं: उदाहरण के लिए, r/Bard में एक Redditor ने एक सकारात्मक समीक्षा दी जिसमें बताया गया कि Gemini ने उन्हें कानूनी दस्तावेजों की समीक्षा करने, कॉपीराइटिंग में मदद की, और यहां तक कि एक मजेदार उपयोग-मामले में एक फोटो से कपड़ों के आकार की पहचान की। उन्होंने कहा *“Gemini मेरे प्रश्नों का उत्तर देने के लिए एक मूल्यवान संसाधन रहा है... अद्यतन जानकारी... मैं भुगतान किए गए संस्करण का इतना आदी हो गया हूँ कि मुझे याद नहीं है कि मुफ्त संस्करण कैसे प्रदर्शन करता है।”* - यह दर्शाता है कि कम से कम *कुछ* आकस्मिक उपयोगकर्ता जिन्होंने Bard Advanced में समय (और पैसा) निवेश किया, उन्हें दैनिक जीवन में यह उपयोगी लगा। ये उपयोगकर्ता इसे व्यावहारिक, दैनिक सहायता के लिए उपयोग करते हैं और मॉडल को इसकी सीमाओं तक नहीं धकेल सकते। हालांकि, कई अन्य आकस्मिक उपयोगकर्ता (विशेष रूप से जिन्होंने ChatGPT को भी आज़माया था) निराश थे। यात्रा सलाह, सामान्य ज्ञान, या किसी कार्य में मदद जैसी चीजें पूछने वाले आम लोगों को Bard के उत्तर कम स्पष्ट या उपयोगी लगे। यहां धारणा विभाजित है: **ब्रांड-निष्ठावान Google उपयोगकर्ता** बनाम **जो पहले से ही ChatGPT द्वारा खराब हो चुके हैं**। पूर्व समूह, यदि उन्होंने ChatGPT का अधिक उपयोग नहीं किया है, तो कभी-कभी उनकी आवश्यकताओं के लिए Bard/Gemini को "काफी अच्छा" पाते हैं और इसकी सराहना करते हैं कि यह खोज के साथ एकीकृत है और मुफ्त है। बाद वाला समूह लगभग हमेशा तुलना करता है और Gemini को वांछनीय पाता है। वे कह सकते हैं, *“मैं Bard का उपयोग क्यों करूँ जब ChatGPT 90% समय बेहतर है?”*। इसलिए आकस्मिक उपयोगकर्ता की धारणा वास्तव में उनके पूर्व संदर्भ फ्रेम पर निर्भर करती है। जो एआई सहायकों के लिए नए हैं, वे Gemini को एक सहायक नवीनता के रूप में रेट कर सकते हैं; जो प्रतियोगिता का अनुभव करते हैं, वे इसे एक निराशा के रूप में देखते हैं जो *“अभी भी इतनी बुरी तरह से बेकार है”* और इसे सुधारने की आवश्यकता है।

- **व्यवसाय/पेशेवर उपयोगकर्ता:** जब Bard ने Google Workspace एकीकरण (Duet AI) के साथ लॉन्च किया तो कई पेशेवरों ने इसे आज़माया। इस समूह के बीच धारणा सतर्क संदेह है। एक तरफ, वे डेटा गोपनीयता और एकीकरण के संबंध में Google के एंटरप्राइज़ वादों पर भरोसा करते हैं (जैसे, एआई के माध्यम से डॉक्स का संपादन, कैलेंडर आमंत्रणों से बैठकों का सारांश, आदि)। दूसरी ओर, शुरुआती परीक्षणों ने अक्सर दिखाया कि Gemini तथ्यात्मक गलतियाँ करता है या सामान्य आउटपुट प्रदान करता है, जो व्यावसायिक उपयोग के लिए विश्वास-प्रेरक नहीं है। उदाहरण के लिए, एक पेशेवर Bard से एक ग्राहक रिपोर्ट का मसौदा तैयार करने के लिए कह सकता है - यदि Bard गलत डेटा या कमजोर अंतर्दृष्टि डालता है, तो यह मदद से अधिक परेशानी हो सकती है। इसलिए, पेशेवर उपयोगकर्ता Bard को गैर-महत्वपूर्ण कार्यों पर *पायलट* करते हैं लेकिन महत्वपूर्ण आउटपुट के लिए अभी भी GPT-4 या Claude पर निर्भर रहते हैं। यह धारणा भी है कि Google पकड़ने की कोशिश कर रहा था: कई लोगों ने Bard को "प्राइम टाइम के लिए तैयार नहीं" के रूप में देखा और इंतजार करने का फैसला किया। कुछ सकारात्मक धारणा वास्तविक समय डेटा क्वेरी जैसे क्षेत्रों में मौजूद है - उदाहरण के लिए, Reddit पर एक वित्तीय विश्लेषक ने नोट किया कि Bard Google खोज के लिए धन्यवाद हालिया बाजार जानकारी खींच सकता है, जिसे ChatGPT नहीं कर सकता जब तक कि प्लगइन्स सक्षम न हों। इसलिए जहां वर्तमान डेटा प्रमुख है, वहां कुछ पेशेवरों ने एक लाभ देखा। एक और बारीकियों: Google पारिस्थितिकी तंत्र में लोग (जैसे, जो कंपनियाँ विशेष रूप से Google Workspace का उपयोग करती हैं) के पास थोड़ा अधिक अनुकूल दृष्टिकोण है क्योंकि Bard/Gemini वह विकल्प है जो उनके वातावरण में फिट बैठता है। वे इसे सुधारने के लिए प्रोत्साहित कर रहे हैं बजाय इसके कि वे पूरी तरह से अलग पारिस्थितिकी तंत्र में स्विच करें। संक्षेप में, व्यावसायिक उपयोगकर्ता Gemini को *संभावित रूप से बहुत उपयोगी* (Google के डेटा और टूल एकीकरण को देखते हुए) के रूप में देखते