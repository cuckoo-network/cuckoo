---
title: "Отзывы пользователей Reddit о крупных инструментах LLM-чата"
tags: [ИИ, ChatGPT, Claude, Google Gemini, Open-Source LLMs]
keywords: [инструменты чата ИИ, отзывы пользователей, ChatGPT, Claude, Google Gemini, open-source LLMs, анализ Reddit]
authors: [lark]
description: Эта статья предоставляет подробный анализ обсуждений на Reddit о популярных инструментах чата ИИ, включая ChatGPT, Claude, Google Gemini и open-source LLMs. Она подчеркивает проблемы, о которых сообщают пользователи, часто запрашиваемые функции и неудовлетворенные потребности, предлагая понимание сильных и слабых сторон каждого инструмента.
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=Отзывы%20пользователей%20Reddit%20о%20крупных%20инструментах%20LLM-чата"
---

# Отзывы пользователей Reddit о крупных инструментах LLM-чата

**Обзор:** Этот отчет анализирует обсуждения на Reddit о четырех популярных инструментах чата ИИ – **ChatGPT от OpenAI**, **Claude от Anthropic**, **Gemini (Bard) от Google** и **open-source LLMs** (например, модели на основе LLaMA). Он резюмирует общие проблемы, о которых сообщают пользователи для каждого инструмента, функции, которые они чаще всего запрашивают, неудовлетворенные потребности или сегменты пользователей, которые чувствуют себя недостаточно обслуженными, и различия в восприятии среди разработчиков, обычных пользователей и бизнес-пользователей. Включены конкретные примеры и цитаты из веток Reddit для иллюстрации этих моментов.

![Отзывы пользователей Reddit о крупных инструментах LLM-чата](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=Отзывы%20пользователей%20Reddit%20о%20крупных%20инструментах%20LLM-чата)

## ChatGPT (OpenAI)

### Общие проблемы и ограничения

- **Ограниченная память контекста:** Основная жалоба заключается в неспособности ChatGPT обрабатывать длинные разговоры или большие документы, не забывая предыдущие детали. Пользователи часто сталкиваются с ограничением длины контекста (несколько тысяч токенов) и вынуждены сокращать или резюмировать информацию. Один пользователь отметил: *«увеличение размера окна контекста было бы самым большим улучшением... Это ограничение, с которым я сталкиваюсь чаще всего»*. Когда контекст превышен, ChatGPT забывает начальные инструкции или содержание, что приводит к разочаровывающим падениям качества в середине сессии.

- **Ограничения на сообщения для GPT-4:** Пользователи ChatGPT Plus жалуются на ограничение в 25 сообщений/3 часа на использование GPT-4 (ограничение, существующее в 2023 году). Достигнув этого лимита, они вынуждены ждать, что прерывает работу. Активные пользователи считают это ограничение серьезной проблемой.

- **Строгие фильтры контента («нерфы»):** Многие пользователи Reddit считают, что ChatGPT стал чрезмерно ограничительным, часто отказываясь выполнять запросы, которые предыдущие версии обрабатывали. Один из популярных постов жаловался, что *«практически все, что вы спрашиваете в наши дни, возвращает ‘Извините, не могу помочь’... Как это превратилось из самого полезного инструмента в эквивалент Google Assistant?»*. Пользователи приводят примеры, когда ChatGPT отказывается форматировать *их собственный* текст (например, учетные данные для входа) из-за гипотетического неправильного использования. Платные подписчики утверждают, что *«некое смутное представление о том, что пользователь может сделать 'плохие' вещи... не должно быть основанием для неотображения результатов»*, поскольку они хотят получить вывод модели и будут использовать его ответственно.

- **Галлюцинации и ошибки:** Несмотря на свои продвинутые возможности, ChatGPT может с уверенностью выдавать неверную или вымышленную информацию. Некоторые пользователи заметили, что это ухудшается со временем, подозревая, что модель была «упрощена». Например, пользователь из финансовой сферы сказал, что ChatGPT раньше правильно рассчитывал такие метрики, как NPV или IRR, но после обновлений *«я получаю так много неправильных ответов... он все еще выдает неправильные ответы [даже после исправления]. Я действительно верю, что он стал намного глупее после изменений»*. Такие непредсказуемые неточности подрывают доверие к задачам, требующим фактической точности.

- **Неполные выходные данные кода:** Разработчики часто используют ChatGPT для помощи в кодировании, но сообщают, что он иногда опускает части решения или обрезает длинный код. Один пользователь поделился, что ChatGPT теперь *«опускает код, выдает бесполезный код и просто плохо справляется с тем, что мне нужно... Он часто опускает так много кода, что я даже не знаю, как интегрировать его решение»*. Это заставляет пользователей задавать дополнительные подсказки, чтобы выудить остальное, или вручную объединять ответы – утомительный процесс.

- **Проблемы с производительностью и временем работы:** Существует мнение, что производительность ChatGPT для отдельных пользователей снизилась по мере увеличения использования в корпоративной среде. *«Я думаю, что они выделяют пропускную способность и вычислительную мощность для бизнеса и отбирают их у пользователей, что невыносимо, учитывая, сколько стоит подписка!»* – пожаловался один разочарованный подписчик Plus. Аварии или замедления в периоды пиковых нагрузок отмечались анекдотически, что может нарушать рабочие процессы.

### Часто запрашиваемые функции или улучшения

- **Более длинное окно контекста / память:** Самое запрашиваемое улучшение – это увеличение длины контекста. Пользователи хотят иметь гораздо более длинные разговоры или вводить большие документы без сбросов. Многие предлагают расширить контекст ChatGPT, чтобы он соответствовал возможности GPT-4 в 32K токенов (в настоящее время доступно через API) или даже больше. Как выразился один пользователь, *«GPT лучше всего работает с контекстом, и когда он не помнит этот начальный контекст, я расстраиваюсь... Если слухи о контекстных PDF-файлах правдивы, это решит практически все мои проблемы»*. Существует высокий спрос на функции загрузки документов или привязки личных данных, чтобы ChatGPT мог запомнить и ссылаться на них в течение сессии.

- **Обработка файлов и интеграция:** Пользователи часто просят более простые способы ввода файлов или данных в ChatGPT. В обсуждениях люди упоминают желание *«скопировать и вставить мой Google Drive и чтобы это работало»* или иметь плагины, которые позволяют ChatGPT напрямую получать контекст из личных файлов. Некоторые пробовали обходные пути (например, плагины для чтения PDF или привязку Google Docs), но жаловались на ошибки и ограничения. Один пользователь описал свой идеальный плагин как такой, который *«работает как Link Reader, но для личных файлов... выбирая, какие части моего диска использовать в разговоре... это решило бы практически все мои проблемы с GPT-4 в настоящее время»*. В общем, лучшая нативная поддержка внешних знаний (за пределами обучающих данных) является популярным запросом.

- **Снижение ограничений для платных пользователей:** Поскольку многие пользователи Plus достигают лимита сообщений GPT-4, они требуют более высоких лимитов или возможности платить больше за неограниченный доступ. Лимит в 25 сообщений считается произвольным и мешающим интенсивному использованию. Люди предпочли бы модель, основанную на использовании, или более высокий лимит, чтобы длинные сессии решения проблем не прерывались.

- **«Несцензурированные» или пользовательские режимы модерации:** Сегмент пользователей хотел бы иметь возможность переключать строгость фильтров контента, особенно при использовании ChatGPT для себя (не для публичного контента). Они считают, что режим «исследования» или «несцензурированный» – с предупреждениями, но без жестких отказов – позволил бы им исследовать более свободно. Как отметил один пользователь, платные клиенты видят в этом инструмент и считают, что *«я плачу деньги за [это]»*. Они хотят иметь возможность получать ответы даже на пограничные запросы. Хотя OpenAI должен балансировать безопасность, эти пользователи предлагают флаг или настройку для ослабления политики в частных чатах.

- **Улучшенная фактическая точность и обновления:** Пользователи часто просят более актуальные знания и меньше галлюцинаций. Ограничение знаний ChatGPT (сентябрь 2021 года в более ранних версиях) часто поднималось на Reddit. OpenAI с тех пор представила просмотр и плагины, которые некоторые пользователи используют, но другие просто просят, чтобы базовая модель обновлялась чаще с новыми данными. Снижение очевидных ошибок – особенно в таких областях, как математика и кодирование – является постоянным желанием. Некоторые разработчики предоставляют обратную связь, когда ChatGPT ошибается, в надежде на улучшение модели.

- **Лучшие выходные данные кода и инструменты:** Разработчики имеют запросы на функции, такие как улучшенный интерпретатор кода, который не опускает содержимое, и интеграция с IDE или системой контроля версий. (Плагин Code Interpreter от OpenAI – теперь часть «Advanced Data Analysis» – был шагом в этом направлении и получил похвалу.) Тем не менее, пользователи часто запрашивают более тонкий контроль в генерации кода: например, возможность выводить полный, нефильтрованный код, даже если он длинный, или механизмы для легкого исправления кода, если ИИ допустил ошибку. В основном, они хотят, чтобы ChatGPT вел себя больше как надежный помощник по кодированию, не требуя множества подсказок для уточнения ответа.

- **Постоянные профили пользователей или память:** Еще одно улучшение, которое некоторые упоминают, – это позволить ChatGPT запоминать вещи о пользователе между сессиями (с согласия). Например, запоминать стиль письма или то, что они являются инженером-программистом, без необходимости повторять это в каждом новом чате. Это может быть связано с тонкой настройкой API или функцией «профиля». Пользователи вручную копируют важный контекст в новые чаты сейчас, поэтому встроенная память для личных предпочтений сэкономила бы время.

### Неудовлетворенные потребности или сегменты пользователей

- **Исследователи и студенты с длинными документами:** Люди, которые хотят, чтобы ChatGPT анализировал длинные научные статьи, книги или большие наборы данных, чувствуют себя недостаточно обслуженными. Текущие ограничения заставляют их разбивать текст или довольствоваться резюме. Этот сегмент получил бы большую выгоду от более крупных окон контекста или функций для обработки длинных документов (как свидетельствуют многочисленные посты о попытках обойти лимиты токенов).

- **Пользователи, ищущие креативное повествование или ролевую игру за пределами ограничений:** Хотя ChatGPT часто используется для креативного письма, некоторые рассказчики чувствуют себя ограниченными моделью, забывающей ранние сюжетные моменты в длинной истории или отказывающейся от взрослого/ужасного контента. Они обращаются к альтернативным моделям или хакам, чтобы продолжить свои повествования. Эти креативные пользователи были бы лучше обслужены версией ChatGPT с более длинной памятью и немного большей гибкостью в отношении вымышленного насилия или зрелых тем (в разумных пределах). Как отметил один писатель-фантаст, когда ИИ теряет нить повествования, *«я должен напоминать ему о точном формате или контексте... Я расстраиваюсь, что он был великолепен два запроса назад, но теперь я должен догонять ИИ»*.

- **Энергичные пользователи и эксперты в области:** Профессионалы в специализированных областях (**финансы**, **инженерия**, **медицина**) иногда считают, что ответы ChatGPT недостаточно глубоки или точны в их области, особенно если вопросы касаются недавних разработок. Эти пользователи желают более надежных экспертных знаний. Некоторые пробовали тонкую настройку через API или пользовательские GPT. Те, кто не может настроить, оценили бы версии ChatGPT, специфичные для домена, или плагины, которые встраивают доверенные базы данных. В своей стандартной форме ChatGPT может недостаточно обслуживать пользователей, которым нужна высокоточная, специфичная для области информация (они часто должны перепроверять его работу).

- **Пользователи, нуждающиеся в несцензурированном или пограничном контенте:** Меньшинство пользователей (хакеры, тестирующие сценарии безопасности, писатели экстремальной фантастики и т. д.) считают ограничения контента ChatGPT слишком ограничительными для своих нужд. В настоящее время они недостаточно обслуживаются официальным продуктом (поскольку он явно избегает определенного контента). Эти пользователи часто экспериментируют с взломом подсказок или используют open-source модели, чтобы получить желаемые ответы. Это сознательный пробел для OpenAI (для поддержания безопасности), но это означает, что такие пользователи ищут другие решения.

- **Лица и предприятия, заботящиеся о конфиденциальности:** Некоторые пользователи (особенно в корпоративной среде) неохотно отправляют конфиденциальные данные в ChatGPT из-за проблем с конфиденциальностью. У OpenAI есть политика не использовать данные API для обучения, но веб-интерфейс ChatGPT исторически не предлагал таких гарантий до добавления функции отказа. Компании, которые обрабатывают конфиденциальные данные (юридические, медицинские и т. д.), часто считают, что не могут полностью использовать ChatGPT, оставляя свои потребности неудовлетворенными, если только они не создадут автономные решения. Например, один пользователь Reddit упомянул, что их компания перешла на локальную LLM по причинам конфиденциальности. Пока не будут доступны локальные или частные экземпляры ChatGPT, этот сегмент остается осторожным или использует более мелких специализированных поставщиков.

### Различия в восприятии по типу пользователя

- **Разработчики/технические пользователи:** Разработчики, как правило, являются как одними из самых больших сторонников ChatGPT, так и его самыми строгими критиками. Они любят его способность объяснять код, генерировать шаблоны и помогать в отладке. Однако они остро ощущают его ограничения в более длинном контексте и точности кода. Как пожаловался один разработчик, ChatGPT начал *«выдавать бесполезный код»* и опускать важные части, что *«раздражает меня... Я не хочу говорить ему ‘не ленись’ – я просто хочу полный результат»*. Разработчики часто замечают даже незначительные изменения в качестве после обновлений модели и были очень активны на Reddit по поводу предполагаемых «нерфов» или снижения возможностей кодирования. Они также расширяют границы (создавая сложные подсказки, связывая инструменты), поэтому они жаждут таких функций, как расширенный контекст, меньше ограничений на сообщения и лучшая интеграция с инструментами кодирования. В общем, разработчики ценят ChatGPT за ускорение рутинных задач, но быстро указывают на ошибки в логике или коде – они рассматривают его как младшего помощника, который все еще нуждается в надзоре.

- **Обычные/ежедневные пользователи:** Более обычные пользователи – те, кто спрашивает общие знания, советы или развлечения – часто восхищаются возможностями ChatGPT, но у них есть свои претензии. Обычное разочарование обычного пользователя – когда ChatGPT отказывается от запроса, который кажется им безобидным (вероятно, нарушая правило политики). Автор оригинального поста в одной ветке выразил это, будучи *«так раздражен, когда я пишу подсказку, с которой у него не должно быть проблем, и он отказывается сейчас»*. Обычные пользователи также могут столкнуться с ограничением знаний (обнаружив, что бот не может справиться с очень актуальными событиями, если явно не обновлен) и иногда замечают, когда ChatGPT дает явно неправильный ответ. В отличие от разработчиков, они могут не всегда перепроверять ИИ, что может привести к разочарованию, если они действуют на основе ошибки. С положительной стороны, многие обычные пользователи считают, что более быстрые ответы ChatGPT Plus и улучшенный вывод GPT-4 стоят $20 в месяц – если только проблема «отказов» или другие ограничения не портят опыт. Они обычно хотят полезного, универсального помощника и могут расстраиваться, когда ChatGPT отвечает политическими заявлениями или требует сложной подсказки для получения простого ответа.

- **Бизнес/профессиональные пользователи:** Бизнес-пользователи часто подходят к ChatGPT с точки зрения производительности и надежности. Они ценят быстрое составление писем, резюме документов или генерацию идей. Однако их беспокоит **безопасность данных**, консистентность и интеграция в рабочие процессы. На Reddit профессионалы обсуждали желание иметь ChatGPT в таких инструментах, как Outlook, Google Docs, или в виде API в их внутренних системах. Некоторые отметили, что по мере того, как OpenAI переходит к обслуживанию корпоративных клиентов, фокус продукта, кажется, смещается: существует ощущение, что бесплатный или индивидуальный пользовательский опыт немного ухудшился (например, стал медленнее или «менее умным») по мере того, как компания расширялась, чтобы обслуживать более крупных клиентов. Независимо от того, правда это или нет, это подчеркивает восприятие: бизнес-пользователи хотят надежности и приоритетного обслуживания, а индивидуальные пользователи беспокоятся, что теперь они стали второсортными. Кроме того, профессионалы нуждаются в правильных выводах – эффектный, но неправильный ответ может быть хуже, чем отсутствие ответа. Таким образом, этот сегмент чувствителен к точности. Для них такие функции, как более длинный контекст (для чтения контрактов, анализа кодовых баз) и гарантированное время работы, имеют решающее значение. Они, вероятно, готовы платить больше за премиальные уровни обслуживания, если их требования к соответствию и конфиденциальности будут удовлетворены. Некоторые предприятия даже исследуют развертывание на месте или использование API OpenAI с жесткими правилами обработки данных, чтобы удовлетворить свои ИТ-политики.

---

## Claude (Anthropic)

### Общие проблемы и ограничения

- **Ограничения на использование и доступ:** Claude получил похвалу за предложение мощной модели (Claude 2) бесплатно, но пользователи быстро столкнулись с ограничениями на использование (особенно на бесплатном уровне). После определенного количества подсказок или большого объема текста Claude может остановиться и сказать что-то вроде *«Извините, я должен завершить этот разговор на данный момент. Пожалуйста, возвращайтесь позже»*. Это ограничение разочаровывает пользователей, которые рассматривают Claude как расширенного партнера по кодированию или письму. Даже пользователи Claude Pro (платные) *«не гарантированы неограниченное время»*, как отметил один пользователь; достижение квоты все равно вызывает сообщение «возвращайтесь позже». Кроме того, в течение долгого времени Claude был официально геоограничен (изначально доступен только в США/Великобритании). Международные пользователи на Reddit должны были использовать VPN или сторонние платформы для доступа, что было неудобством. Это заставило многих неамериканских пользователей чувствовать себя исключенными, пока доступ не расширился.

- **Склонность к отклонению от темы с очень большими входными данными:** Главная особенность Claude – его *100k-токеновое контекстное окно*, позволяющее использовать чрезвычайно длинные подсказки. Однако некоторые пользователи заметили, что когда вы заполняете десятки тысяч токенов в Claude, его ответы могут становиться менее сфокусированными. *«100k очень полезно, но если он не следует инструкциям должным образом и отклоняется от темы, это не так полезно»,* отметил один пользователь. Это говорит о том, что с огромными контекстами Claude может отклоняться или начинать болтать, требуя тщательной настройки подсказок, чтобы удерживать его на задаче. Это ограничение, присущее расширению контекста до крайности – модель сохраняет много, но иногда «забывает», какие детали наиболее важны, что приводит к незначительным галлюцинациям или отклонениям от темы.

- **Несогласованное форматирование или соблюдение инструкций:** В сравнительных тестах некоторые пользователи обнаружили, что Claude менее предсказуем в том, как он следует определенным директивам. Например, Claude описывается как *«более человечный в взаимодействиях. Но он менее строго следует системным сообщениям»*. Это означает, что если вы даете ему фиксированный формат для следования или очень строгую персону, Claude может отклоняться больше, чем ChatGPT. Разработчики, которые полагаются на детерминированные выходные данные (например, форматы JSON или определенные стили), иногда разочаровываются, если Claude добавляет дополнительные комментарии или не строго придерживается шаблона.

- **Ограничения контента и отказы:** Хотя не так часто критикуется, как ChatGPT, фильтры безопасности Claude все же упоминаются. Anthropic разработала Claude с акцентом на конституционном ИИ (чтобы ИИ сам следовал этическим принципам). Пользователи в целом находят Claude готовым обсуждать широкий спектр тем, но есть случаи, когда Claude отказывается от запросов, которые ChatGPT мог бы разрешить. Например, один пользователь Reddit отметил, что *«ChatGPT имеет меньше моральных ограничений... он объяснит, какие противогазы лучше для каких условий, в то время как Claude откажется»*. Это говорит о том, что Claude может быть строже в отношении определенных «чувствительных» советов (возможно, рассматривая их как потенциально опасные рекомендации). Другой пользователь попробовал игривый сценарий ролевой игры («представьте, что вас похитили инопланетяне»), от которого Claude отказался, в то время как Gemini и ChatGPT участвовали бы. Таким образом, у Claude есть фильтры, которые могут иногда удивлять пользователей, ожидающих, что он будет более разрешительным.

- **Отсутствие мультимодальных возможностей:** В отличие от ChatGPT (который к концу 2023 года получил возможность понимания изображений с GPT-4 Vision), Claude в настоящее время работает только с текстом. Пользователи Reddit отмечают, что Claude не может анализировать изображения или напрямую просматривать веб-страницы самостоятельно. Это не совсем «проблема» (Anthropic никогда не рекламировала эти функции), но это ограничение по сравнению с конкурентами. Пользователи, которые хотят, чтобы ИИ интерпретировал диаграмму или скриншот, не могут использовать Claude для этого, в то время как ChatGPT или Gemini могут с этим справиться. Аналогично, любое извлечение текущей информации требует использования Claude через сторонний инструмент (например, Poe или интеграцию с поисковой системой), поскольку у Claude в настоящее время нет официального режима просмотра.

- **Незначительные проблемы со стабильностью:** Несколько пользователей сообщили, что Claude иногда повторяется или застревает в циклах для определенных подсказок (хотя это менее распространено, чем у некоторых меньших моделей). Кроме того, более ранние версии Claude иногда преждевременно завершали ответы или занимали много времени с большими выходными данными, что можно считать незначительными неудобствами, хотя Claude 2 улучшил скорость.

### Часто запрашиваемые функции или улучшения

- **Более высокие или регулируемые лимиты на использование:** Энтузиасты Claude на Reddit часто просят Anthropic повысить лимиты на разговоры. Они хотели бы использовать 100k контекст в полной мере, не сталкиваясь с искусственным ограничением. Некоторые предлагают, чтобы даже платный Claude Pro позволял *значительно* больше токенов в день. Другие предложили идею опционального «100k расширенного режима» – например, *«Claude должен иметь 100k контекстный режим с удвоенными лимитами на использование»* – где, возможно, подписка могла бы предложить расширенный доступ для активных пользователей. По сути, существует спрос на план, который конкурирует с неограниченным (или высоким лимитом) использованием ChatGPT для подписчиков.

- **Улучшенная навигация по длинному контексту:** Хотя наличие 100k токенов является прорывом, пользователи хотят, чтобы Claude лучше *использовал* этот контекст. Одним из улучшений было бы уточнение того, как Claude приоритизирует информацию, чтобы оставаться на задаче. Anthropic могла бы работать над соблюдением моделью подсказок, когда подсказка огромна. Обсуждения на Reddit предполагают такие техники, как позволение пользователю «закреплять» определенные инструкции, чтобы они не размывались в большом контексте. Любые инструменты, помогающие сегментировать или резюмировать части ввода, также могли бы помочь Claude справляться с большими входными данными более связно. В общем, пользователи любят возможность кормить целую книгу Claude – они просто хотят, чтобы он оставался острым на протяжении всего процесса.

- **Плагины или веб-браузинг:** Многие пользователи ChatGPT привыкли к плагинам (например, просмотр, выполнение кода и т. д.) и выражают интерес к тому, чтобы Claude имел такую же расширяемость. Общий запрос – чтобы Claude имел официальную функцию поиска/просмотра веб-страниц, чтобы он мог получать актуальную информацию по запросу. В настоящее время знания Claude в основном статичны (обучающие данные до начала 2023 года, с некоторыми обновлениями). Если бы Claude мог запрашивать веб-страницы, это сняло бы это ограничение. Аналогично, система плагинов, где Claude мог бы использовать сторонние инструменты (например, калькуляторы или соединители баз данных), могла бы расширить его полезность для активных пользователей. Это остается функцией, которой не хватает Claude, и пользователи Reddit часто упоминают, как экосистема плагинов ChatGPT дает ему преимущество в определенных задачах.

- **Мультимодальный ввод (изображения или аудио):** Некоторые пользователи также задавались вопросом, будет ли Claude поддерживать ввод изображений или генерировать изображения. Google Gemini и OpenAI GPT-4 имеют мультимодальные возможности, поэтому, чтобы оставаться конкурентоспособными, пользователи ожидают, что Anthropic исследует это. Частый запрос: *«Могу ли я загрузить PDF или изображение для анализа Claude?»* В настоящее время ответ – нет (кроме обходных путей, таких как преобразование изображений в текст в другом месте). Даже просто позволить преобразование изображения в текст (OCR и описание) удовлетворило бы многих, кто хочет универсального помощника. Это в списке желаний, хотя Anthropic не анонсировала ничего подобного по состоянию на начало 2025 года.

- **Тонкая настройка или кастомизация:** Продвинутые пользователи и бизнесы иногда спрашивают, могут ли они тонко настроить Claude на своих данных или получить пользовательские версии. OpenAI предлагает тонкую настройку для некоторых моделей (пока не для GPT-4, но для GPT-3.5). Anthropic выпустила интерфейс тонкой настройки для Claude 1.3 ранее, но он не широко рекламируется для Claude 2. Пользователи Reddit интересовались возможностью обучить Claude на знаниях компании или личном стиле письма. Более простой способ сделать это (кроме инъекций подсказок каждый раз) был бы очень приветствован, так как это могло бы превратить Claude в персонализированного помощника, который запоминает конкретную базу знаний или персону.

- **Более широкая доступность:** Неамериканские пользователи часто просят, чтобы Claude был официально запущен в их странах. Посты из Канады, Европы, Индии и т. д. спрашивают, когда они смогут использовать сайт Claude без VPN или когда API Claude будет открыт более широко. Anthropic была осторожна, но спрос глобален – вероятно, улучшение в глазах многих будет просто «позволить большему количеству из нас использовать его». Постепенное расширение доступа компанией частично решило эту проблему.

### Неудовлетворенные потребности или сегменты пользователей

- **Международная пользовательская база:** Как отмечалось, в течение долгого времени основная пользовательская база Claude была ограничена географически. Это оставило многих *потенциальных* пользователей недостаточно обслуженными. Например, разработчик в Германии, заинтересованный в 100k контексте Claude, не имел официального способа его использовать. Хотя существуют обходные пути (сторонние платформы или VPN + телефонная верификация в поддерживаемой стране), эти барьеры означали, что случайные международные пользователи фактически были заблокированы. В отличие от этого, ChatGPT доступен в большинстве стран. Таким образом, неамериканские англоговорящие и особенно неанглоговорящие пользователи были недостаточно обслужены ограниченным запуском Claude. Они могут по-прежнему полагаться на ChatGPT или локальные модели просто из-за проблем с доступом.

- **Пользователи, нуждающиеся в строгом форматировании выходных данных:** Как упоминалось, Claude иногда вносит изменения в ответы. Пользователи, которым нужны строго структурированные выходные данные (например, JSON для приложения или ответ, следующий определенному формату), могут найти Claude менее надежным для этого, чем ChatGPT. Эти пользователи – часто разработчики, интегрирующие ИИ в систему – являются сегментом, который мог бы быть лучше обслужен, если бы Claude позволял «строгий режим» или улучшил свое соблюдение инструкций. Они в настоящее время могут избегать Claude для таких задач, придерживаясь моделей, известных более строгим следованием форматам.

- **Обычные пользователи вопросов и ответов (по сравнению с творческими пользователями):** Claude часто хвалят за творческие задачи – он производит плавный, человечный текст и вдумчивые эссе. Однако некоторые пользователи на Reddit отметили, что для простых вопросов-ответов или фактических запросов Claude иногда дает многословные ответы, где достаточно краткости. Пользователь, сравнивший ChatGPT и Claude, сказал, что ChatGPT, как правило, краток и пунктуален, в то время как Claude по умолчанию дает больше повествования. Пользователи, которые просто хотят быстрого фактического ответа (например, «Какова столица X и ее население?»), могут почувствовать, что Claude немного косвенный. Эти пользователи лучше обслуживаются чем-то вроде точного поиска или краткой модели. Claude может это сделать, если попросить, но его стиль может не соответствовать ожиданиям краткого вопроса-ответа, что означает, что этот сегмент может перейти к другим инструментам (например, Bing Chat или Google).

- **Пользователи, критически относящиеся к безопасности:** Напротив, некоторые пользователи, которые *требуют* очень тщательного соблюдения безопасности (например, педагоги, использующие ИИ со студентами, или корпоративные клиенты, которые хотят нулевого риска неконтролируемых выходных данных), могут считать выравнивание Claude плюсом, но поскольку ChatGPT также довольно выровнен и имеет больше корпоративных функций, эти пользователи могут не выбирать Claude специально. Это небольшой сегмент, но можно утверждать, что Claude еще не захватил его явно. Они могут быть недостаточно обслужены тем, что у них нет легкого способа *увеличить* защитные меры Claude или увидеть его «цепочку мыслей» (что Anthropic имеет внутренне через подход конституционного ИИ, но конечные пользователи не взаимодействуют с этим напрямую, кроме как замечая вежливый тон Claude).

- **Неанглоговорящие пользователи (качество выходных данных):** Claude был обучен в основном на английском языке (как и большинство крупных LLM). Некоторые пользователи тестировали его на других языках; он может отвечать на многих, но качество может варьироваться. Если, скажем, пользователь хочет очень нюансированный ответ на французском или хинди, возможно, способности Claude не так хорошо настроены там, как у ChatGPT (GPT-4 продемонстрировал сильные многоязычные возможности, часто выше, чем у других моделей в определенных тестах). Пользователи, которые в основном общаются на языках, отличных от английского, могут найти беглость или точность Claude немного слабее. Этот сегмент несколько недостаточно обслуживается просто потому, что Anthropic не выделила многоязычное обучение как приоритет публично.

### Различия в восприятии по типу пользователя

- **Разработчики/технические пользователи:** Разработчики на Reddit все чаще хвалят Claude, особенно Claude 2 / Claude 3.5, за задачи кодирования. Сдвиг восприятия в конце 2024 года был заметен: многие разработчики начали предпочитать Claude ChatGPT для помощи в программировании. Они цитируют *«потрясающую производительность в кодировании»* и способность обрабатывать большие кодовые базы за один раз. Например, один пользователь написал *«Claude Sonnet 3.5 лучше работает с кодом (анализирует, генерирует) [чем ChatGPT]»*. Разработчики ценят, что Claude может взять большой кусок проектного кода или логов и выдать связные анализы или улучшения благодаря своему огромному контексту. Однако они также замечают его причуды – например, иногда вставляет больше разговорной болтовни или не следует спецификации до буквы. В целом, многие разработчики держат под рукой и ChatGPT, и Claude: один для строгой пошаговой логики (ChatGPT) и один для широкого контекста и эмпатического понимания (Claude). Показательно, что комментатор сказал *«Если бы мне пришлось выбрать один, я бы выбрал Claude»* после ежедневного сравнения обоих. Это указывает на очень положительное восприятие среди продвинутых пользователей, особенно для таких случаев использования, как мозговой штурм, обзор кода или архитектурные предложения. Единственная общая жалоба от разработчиков – достижение лимитов использования Claude, когда они пытаются сильно его нагрузить (например, кормя 50K-токеновую подсказку для анализа целого репозитория). В общем, разработчики рассматривают Claude как чрезвычайно мощный инструмент – в некоторых случаях превосходящий ChatGPT – ограниченный только доступностью и некоторой непредсказуемостью в форматировании.

- **Обычные/нетехнические пользователи:** Обычные пользователи, которые попробовали Claude, часто комментируют, насколько *дружелюбным и красноречивым* он является. Стиль Claude, как правило, разговорный, вежливый и подробный. Новый пользователь, сравнивший его с ChatGPT, отметил, что *«Claude более эмпатичен и следует разговорному тону... ChatGPT слишком часто использует маркеры»*. Эта человечная теплота делает Claude привлекательным для людей, использующих его для креативного письма, советов или просто общения для получения информации. Некоторые даже олицетворяют Claude, приписывая ему «личность», которая является сострадательной. Обычные пользователи также любят, что бесплатная версия Claude позволила получить доступ к эквиваленту GPT-4 уровня интеллекта без подписки (по крайней мере, до лимитов скорости). С другой стороны, обычные пользователи сталкиваются с отказами Claude по определенным темам и могут не понимать, почему (поскольку Claude будет формулировать это извинительно, но твердо). Если обычный пользователь задал что-то пограничное и получил отказ от Claude, он может воспринять это как менее способное или слишком ограниченное, не осознавая, что это политическая позиция. Еще один аспект заключается в том, что у Claude нет узнаваемости – многие обычные пользователи могут даже не знать, чтобы попробовать его, если они не подключены к сообществам ИИ. Те, кто пробует, обычно комментируют, что это похоже на *«разговор с человеком»* в хорошем смысле. Они, как правило, очень довольны способностью Claude справляться с открытыми или личными вопросами. Таким образом, восприятие обычных пользователей в основном положительное в отношении *качества и тона выходных данных Claude*, с некоторым замешательством или разочарованием по поводу его доступности (необходимость использовать его в конкретном приложении или регионе) и случайных моментов «не могу это сделать».

- **Бизнес/профессиональные пользователи:** Восприятие бизнеса Claude немного сложнее оценить по публичному Reddit (поскольку меньше корпоративных пользователей публикуют подробности), но выделяются несколько тенденций. Во-первых, Anthropic позиционировала Claude как более *ориентированного на конфиденциальность* и готового подписывать корпоративные соглашения – это привлекает компании, обеспокоенные данными с OpenAI. Действительно, некоторые обсуждения на Reddit упоминают Claude в контексте таких инструментов, как Slack или Notion, где он интегрирован в качестве помощника. Профессионалы, которые использовали эти интеграции, могут даже не осознавать, что Claude является движком, но когда они это делают, они сравнивают его благоприятно с точки зрения стиля письма и способности переваривать большие корпоративные документы. Например, команда может передать длинный квартальный отчет Claude и получить приличное резюме – что-то, с чем меньший контекст ChatGPT будет бороться. Тем не менее, бизнес-пользователи также замечают отсутствие определенных функций экосистемы; например, OpenAI предлагает контроль системных сообщений, вызов функций и т. д. в своем API, который Anthropic поддерживает более ограниченно. Разработчик, работающий над бизнес-решением, отметил, что *Claude более управляем в разговорах, в то время как ChatGPT, как правило, более жесткий... [но] ChatGPT имеет доступ к вебу, что может быть очень полезно*. Импликация заключается в том, что для задач исследования или поиска данных, которые могут понадобиться бизнес-пользователю (например, конкурентная разведка), ChatGPT может напрямую получать информацию, в то время как Claude потребовал бы отдельного шага. В общем, бизнес-пользователи рассматривают Claude как очень компетентный ИИ – в некоторых случаях *лучше* для внутренних аналитических задач – но, возможно, еще не такой богатый функциями для интеграции. Стоимость – еще один фактор: цены и условия API Claude не так публичны, как у OpenAI, и некоторые стартапы на Reddit упомянули неопределенность в отношении цен или стабильности Claude. В общем, профессионалы уважают возможности Claude (особенно его надежность в следовании высокоуровневым инструкциям и резюмировании больших входных данных), но они следят за тем, как он развивается с точки зрения интеграции, поддержки и глобальной доступности, прежде чем полностью перейти на него вместо более устоявшегося ChatGPT.

---

## Google Gemini (Bard)

### Общие проблемы и ограничения

- **Неточные или «глупые» ответы:** Поток отзывов на Reddit появился, когда Google запустила обновление Bard на базе Gemini, и многие из них были негативными. Пользователи жаловались, что Gemini **плохо справляется с базовыми вопросами и ответами** по сравнению с ChatGPT. Одна откровенная оценка под заголовком «100% честное мнение о Google Gemini» гласила: *«Это сломанный, неточный чат-бот LLM»*. Другой разочарованный пользователь спросил: *«Как Gemini все еще так плох? Количество раз, когда я прошу Gemini о чем-то, и он либо дает мне неправильные ответы, либо неполные ответы, просто смешно»*. Они сравнили его бок о бок с ChatGPT-4 и обнаружили, что ChatGPT дал *«идеальный, правильный, эффективный ответ с первого раза»*, в то время как Gemini болтал и требовал нескольких подсказок, чтобы прийти к полудостойному ответу. По сути, ранние пользователи чувствовали, что Gemini часто **галлюцинирует или упускает суть** вопросов, требуя чрезмерных усилий с подсказками, чтобы извлечь правильную информацию. Эта непоследовательность в качестве была большим разочарованием, учитывая ажиотаж вокруг Gemini.

- **Чрезмерная многословность и пустословие:** Многие пользователи отметили, что Gemini (в форме нового Bard) склонен давать пространные ответы, которые не доходят до сути. Как описал один человек, *«Он болтал... 3 абзаца AI мусора... даже тогда, он [только] в конце концов упомянул ответ, зарытый в абзацах мусора»*. Это резкий контраст с ChatGPT, который часто дает более краткие ответы или маркеры, когда это уместно. Многословность становится проблемой, когда пользователи должны просеивать много текста для простой информации. Некоторые предположили, что Google мог настроить его на разговорный или «полезный» режим, но переусердствовал с *слишком большим* объяснением без содержания.

- **Плохая интеграция с собственными сервисами Google:** Одним из продающих моментов AI-помощника Google должна была быть интеграция с экосистемой Google (Gmail, Docs, Drive и т. д.). Однако ранний пользовательский опыт был очень разочаровывающим в этом отношении. Один пользователь выразил недовольство: *«Даже не начинайте говорить о его почти полной неспособности интегрироваться с собственными продуктами Google, что должно быть ‘функцией’ (которую он, по-видимому, не знает, что имеет)»*. Например, люди пытались попросить Gemini (через Bard) резюмировать документ Google или составить письмо на основе некоторой информации – функции, которые рекламировал Google – и бот отвечал, что он **не может получить доступ к этим данным**. Один пользователь на r/GooglePixel написал: *«Каждый раз, когда я пытаюсь использовать Gemini с моими Google Docs или Drive, он говорит мне, что не может ничего с ними сделать. Какой смысл вообще иметь эти функции интеграции?»*. Это показывает значительный разрыв между обещанными возможностями и фактической производительностью, оставляя пользователей с ощущением, что «AI-помощник» не очень помогает в экосистеме Google.

- **Отказы и путаница в возможностях:** Пользователи также сталкивались с странными отказами или противоречиями от Gemini. Тот же пользователь Reddit отметил, что Gemini *«отказывается делать вещи без причины, забывает, что может делать другие вещи... На днях он сказал мне, что у него нет доступа к интернету/живым данным. Что.»*. Это указывает на то, что Gemini иногда **отказывается от задач, которые он должен уметь выполнять** (например, извлечение живой информации, к которой Bard подключен) или делает неверные заявления о своих собственных возможностях. Такие переживания создавали впечатление ИИ, который не только менее умен, но и **менее надежен или самосознателен**. Другой пользователь выразил это красочно: *«Gemini – это абсолютный мусор. У вас когда-нибудь были такие моменты, когда вы просто хотите поднять руки и сказать: ‘О чем они думали?’»* – это encapsulates the frustration. Essentially, Gemini’s product integration and consistency issues made it feel *half-baked* to many early adopters.

- **Unremarkable coding abilities:** While not as widely discussed as general Q&A, several users tested Gemini (Bard) on coding tasks and found it subpar. In AI forums, Gemini’s coding capabilities were usually rated below GPT-4 and even below Claude. For instance, one user stated plainly that *“Claude 3.5 Sonnet is clearly better for coding than ChatGPT 4o… Gemini is absolute trash [in that context]”*. The consensus was that Gemini could write simple code or explain basic algorithms, but it often stumbled on more complex problems or produced code with errors. Its lack of a broad developer toolset (e.g., it doesn’t have an equivalent of Code Interpreter or robust function calling) also meant it wasn’t a first choice for programmers. So, while not every casual user cares about code, this is a limitation for that segment.

- **Mobile device limitations:** Gemini rolled out as part of Google’s Assistant on Pixel phones (branded as “Assistant with Bard”). Some Pixel users noted that using it as a voice assistant replacement had issues. It sometimes didn’t pick up voice prompts accurately or took too long to respond compared to the old Google Assistant. There were also comments about needing to opt-in and lose some classic Assistant features. This created a perception that *Gemini’s integration on devices wasn’t fully ready*, leaving power users of Google’s ecosystem feeling that they had to choose between a smart assistant and a functional one.

### Frequently Requested Features or Improvements

- **Dramatically improved accuracy and reasoning:** The number one improvement users want for Gemini is simply **to be smarter and more reliable**. Reddit feedback makes it clear that Google needs to close the gap in answer quality. Users expect Gemini to utilize Google’s vast information access to give *factual, direct answers*, not meandering or incorrect ones. So the requests (often sarcastically phrased) boil down to: *make it as good as or better than GPT-4 on general knowledge and reasoning.* This includes better handling of follow-up questions and complex prompts. Essentially, “fix the brain” of Gemini – leverage those purported multimodal training advantages so it stops missing obvious details. Google likely has heard this loud and clear: many posts compare specific answers where ChatGPT excelled and Gemini failed, which serves as informal bug reports for improvement.

- **Better integration & awareness of context:** Users want Gemini to fulfill the promise of a seamless Google ecosystem helper. This means it should **properly interface with Gmail, Calendar, Docs, Drive, etc.** If a user asks “Summarize the document I opened” or “Draft a response to the last email from my boss,” the AI should do it – and do it securely. Right now, the request is that Google *enable those features and make Gemini actually recognize when such a task is possible*. It was advertised that Bard could connect to user content (with permission), so users are effectively demanding Google “turn on” or fix this integration. This is a key feature for business users especially. Additionally, on the web browsing front: Bard (Gemini) can search the web, but some users want it to cite sources more clearly or be more timely in incorporating breaking news. So improving the *connected* nature of Gemini is a frequent request.

- **Conciseness controls:** Given complaints of verbosity, some users suggest a feature to toggle the response style. For example, a *“brief mode”* where Gemini gives a short, to-the-point answer by default, unless asked to elaborate. Conversely, maybe a “detailed mode” for those who want very thorough answers. ChatGPT implicitly allows some of this by the user prompt (“keep it brief”); with Gemini, users felt even when they didn’t ask for detail, it over-explained. So a built-in setting or just better tuning to produce concise answers when appropriate would be a welcome improvement. In essence, adjust the verbosity dial.

- **Feature parity with ChatGPT (coding, plugins, etc.):** Power users on Reddit explicitly compare features. They request that Google’s Gemini/Bard offer things like a *code execution sandbox* (similar to ChatGPT’s Code Interpreter), the ability to upload images/PDFs for analysis (since Gemini is multimodal, users want to actually feed it custom images, not just have it describe provided ones). Another frequently mentioned feature is better **memory within conversation** – while Bard does have some memory of past interactions, users want it to be as good as ChatGPT at referencing earlier context, or even have persistent conversation storage like ChatGPT’s chat history that you can scroll through and revisit. Essentially, Google is being asked to catch up on all the quality-of-life features that ChatGPT Plus users have: chat history, plugin ecosystem (or at least strong third-party integrations), coding assistance, etc.

- **Mobile app and voice improvements:** Many casual users requested a **dedicated mobile app for Bard/Gemini** (similar to the ChatGPT mobile app). Relying on a web interface or only the Pixel Assistant is limiting. An official app across iOS/Android with voice input, speaking responses (for a true assistant feel), and tight integration could greatly improve user experience. Along with that, Pixel owners want the Assistant with Bard to get faster and more functional – basically, they want the best of old Google Assistant (quick, precise actions) combined with the intelligence of Gemini. For example, things like continuing to allow “Hey Google” smart home voice commands and not just chatty responses. Google could improve the voice mode of Gemini to truly replace the legacy assistant without feature regressions.

- **Transparency and control:** Some users have asked for more insight into Bard’s sources or a way to fine-tune its style. For instance, showing which Google result Bard is pulling information from (to verify accuracy) – something Bing Chat does by citing links. Also, because Bard occasionally produces wrong info, users want to be able to flag or correct it, and ideally Bard should learn from that feedback over time. Having an easy feedback mechanism (“thumbs down – this is incorrect because…”) that leads to rapid model improvement would instill confidence that Google is listening. Basically, features to make the AI more of a collaborative assistant than a black box.

### Underserved Needs or User Segments

- **Users seeking a dependable personal assistant:** Ironically, the group that Google *targeted* – people wanting a powerful personal assistant – feel most underserved by Gemini in its current form. Early adopters who switched on the new Bard-based Assistant expected an upgrade, but many felt it was a downgrade in practical terms. For example, if someone wants a voice assistant to *accurately* answer trivia, set reminders, control devices, and integrate info from their accounts, Gemini struggled. This left the very segment of busy professionals or gadget enthusiasts (who rely on assistants for productivity) feeling that their needs weren’t met. One user commented they’d consider paying for the Pixel’s “Assistant with Bard” *“if [it] surpass[es] Google Assistant”*, implying it hadn’t yet. So that segment is still waiting for a reliable, genuinely helpful AI assistant – they’ll jump on it if Gemini improves.

- **Non-native English speakers / localization:** Google products usually have excellent localization, but it’s unclear if Bard/Gemini was equally strong in all languages at launch. Some international users reported that Bard’s answers in their native language were less fluent or useful, pushing them back to local competitors. If Gemini’s training data or optimization favored English, then non-English users are underserved. They might prefer ChatGPT or local models which have explicitly optimized multilingual capabilities. This is a space Google could traditionally excel in (given its translation tech), but user feedback on that is scant – likely indicating Gemini hasn’t yet wowed those communities.

- **Enterprise customers (so far):** Large organizations have not widely adopted Bard/Gemini based on public chatter, often because of trust and capability gaps. Enterprises need consistency, citations, and integration with their workflows (Office 365 is deeply integrated with OpenAI’s tech via MS Copilot, for example). Google’s equivalent (Duet AI with Gemini) is still evolving. Until Gemini/Bard proves it can reliably draft emails, create slide decks, or analyze data in Google Sheets at a level on par with or above GPT-4, enterprise users will feel that Google’s solution isn’t addressing their needs fully. Some posts on r/Bard from professionals are along the lines of “I tried Bard for work tasks, it wasn’t as good as ChatGPT, so we’ll wait and see.” That indicates enterprise users are an underserved segment for now – they want an AI that slots into Google Workspace and actually boosts productivity without needing constant verification of outputs.

- **Users in the Google ecosystem who prefer one-stop solutions:** There’s a segment of users who use Google for everything (search, email, documents) and *would* happily use a Google AI for all their chatbot needs – if it were as good. Right now, those users are somewhat underserved because they end up using ChatGPT for certain things and Bard for others. They might ask factual questions to ChatGPT because they trust its answer quality more, but use Bard for its browsing or integration attempts. That split experience isn’t ideal. Such users really just want to stay in one app/assistant. If Gemini improves, they’ll consolidate around it, but until then their use case of “one assistant to rule them all” isn’t fulfilled.

- **Developers/Data scientists on Google Cloud:** Google did release Gemini models via its Vertex AI platform for developers. However, early reports and benchmarks suggested Gemini (particularly the available “Gemini Pro” model) wasn’t beating GPT-4. Developers who prefer Google Cloud for AI services are thus a bit underserved by model quality – they either have to accept a slightly inferior model or integrate OpenAI’s API separately. This enterprise developer segment is hungry for a strong Google model so they can keep everything in one stack. Until Gemini’s performance clearly excels in some areas or pricing offers a compelling reason, it’s not fully serving this group’s needs in competitive terms.

### Differences in Perception by User Type

- **Developers/Tech Enthusiasts:** Tech-savvy users approached Gemini with high expectations (it’s Google, after all). Their perception quickly soured after hands-on testing. Many developers on Reddit ran benchmarks or their favorite tricky questions through Gemini and found it lagging. One programmer bluntly stated, *“Gemini is absolute trash like Llama 3.0 used to be”*, indicating they rank it even below some open models. Developers are particularly sensitive to logical errors and verbosity. So when Gemini gave verbose but incorrect answers, it lost credibility fast. On the other hand, developers recognize Google’s potential; some hold out hope that *“with more fine-tuning, Gemini will get better”* and they periodically retest it after updates. At present, however, most devs perceive it as **inferior to GPT-4** in almost all serious tasks (coding, complex problem solving). They do appreciate certain things: for example, Gemini has access to real-time information (via Google search) without needing a plugin, which is useful for up-to-date queries. A developer might use Bard for something like “search and summarize the latest papers on X,” where it can quote web data. But for self-contained reasoning, they lean toward other models. In summary, tech enthusiasts see Gemini as a promising work-in-progress that *currently* feels a generation behind. It hasn’t earned their full trust, and they often post side-by-side comparisons highlighting its mistakes to spur Google to improve it.

- **Casual/Everyday Users:** Casual users, including those who got access to the new Bard on their phones or via the web, had mixed feelings. Many casual users initially approached Bard (Gemini) because it’s free and easy to access with a Google account, unlike GPT-4 which was paywalled. Some casual users actually report decent experiences for simple uses: for example, one Redditor in r/Bard gave a positive review noting Gemini helped them with things like reviewing legal docs, copywriting, and even a fun use-case of identifying clothing sizes from a photo. They said *“Gemini has been a valuable resource for answering my questions… up-to-date information… I’ve become so accustomed to the paid version that I can’t recall how the free version performs.”* – indicating that at least *some* casual users who invested time (and money) into Bard Advanced found it useful in daily life. These users tend to use it for practical, everyday help and may not push the model to its limits. However, many other casual users (especially those who had also tried ChatGPT) were disappointed. Common people asking things like travel advice, trivia, or help with a task found Bard’s answers less clear or useful. The perception here is split: **brand-loyal Google users** vs. **those already spoiled by ChatGPT**. The former group, if they hadn’t used ChatGPT much, sometimes find Bard/Gemini “pretty good” for their needs and appreciate that it’s integrated with search and free. The latter group almost invariably compares and finds Gemini wanting. They might say, *“Why would I use Bard when ChatGPT is better 90% of the time?”*. So casual user perception really depends on their prior frame of reference. Those new to AI assistants might rate Gemini as a helpful novelty; those experienced with the competition see it as a disappointment that *“still sucks so bad”* and needs to improve.

- **Business/Professional Users:** Many professionals gave Bard a try when it launched with Google Workspace integration (Duet AI). The perception among this group is cautious skepticism. On one hand, they trust Google’s enterprise promises regarding data privacy and integration (e.g., editing Docs via AI, summarizing meetings from Calendar invites, etc.). On the other hand, early tests often showed Gemini making factual mistakes or providing generic output, which is not confidence-inspiring for business use. For example, a professional might ask Bard to draft a client report – if Bard inserts incorrect data or weak insights, it could be more hassle than help. Therefore, professional users tend to *pilot* Bard on non-critical tasks but still lean on GPT-4 or Claude for important outputs. There’s also a perception that Google was playing catch-up: many saw Bard as “not ready for prime time” and decided to wait. Some positive perception exists in areas like **real-time data queries** – e.g., a financial analyst on Reddit noted Bard could pull recent market info thanks to Google search, which ChatGPT couldn’t unless plugins were enabled. So in domains where current data is key, a few professionals saw an advantage. Another nuance: people in the Google ecosystem (e.g., companies that use Google Workspace exclusively) have a slightly more favorable view simply because Bard/Gemini is the option that fits their environment. They are rooting for it to improve rather than switching to a whole different ecosystem. In summary, business users see Gemini as *potentially very useful* (given Google’s data and tool integration), but as of early 2025, it hasn’t earned full trust. They perceive it as the “new contender that isn’t quite there yet” – worth monitoring, but not yet a go-to for mission-critical tasks. Google’s reputation buys it some patience from this crowd, but not indefinite; if Gemini doesn’t markedly improve, professionals might not adopt it widely, sticking with other solutions.

---

## Open-Source LLMs (e.g. LLaMA-based Models)

### Common Pain Points and Limitations

- **Hardware and setup requirements:** Unlike cloud chatbots, open-source LLMs typically require users to run them on local hardware or a server. This immediately presents a pain point: many models (for example, a 70-billion-parameter LLaMA model) need a powerful GPU with a lot of VRAM to run smoothly. As one Redditor succinctly put it, *“Local LLMs on most consumer hardware aren't going to have the precision needed for any complex development.”* For the average person with only an 8GB or 16GB GPU (or just a CPU), running a high-quality model can be slow or outright unfeasible. Users might resort to smaller models that fit, but those often yield lower quality output (“dumber” responses). The complexity of setup is another issue – installing model weights, setting up environments like Oobabooga or LangChain, managing tokenization libraries, etc., can be intimidating for non-developers. Even technically skilled users describe it as a hassle to keep up with new model versions, GPU driver quirks, and so on. One thread titled “Seriously, how do you actually use local LLMs?” had people sharing that many models *“either underperform or don't run smoothly on my hardware”*, and asking for practical advice.

- **Inferior performance to state-of-the-art closed models:** Open-source models have made rapid progress, but as of 2025 many users note they still lag behind the top proprietary models (GPT-4, Claude) in complex reasoning, coding, and factual accuracy. A vivid example: a user on r/LocalLLaMA compared outputs in their native language and said *“Every other model I’ve tried fails… They don’t come even close [to GPT-4]. ChatGPT 4 is absolutely amazing at writing”*. This sentiment is echoed widely: while smaller open models (like a fine-tuned 13B or 7B) can be impressive for their size, they struggle with tasks that require deep understanding or multi-step logic. Even larger open models (65B, 70B) which approach GPT-3.5 level still can falter at the kind of tricky problems GPT-4 handles. Users observe more hallucinations and errors in open models, especially on niche knowledge or when prompts deviate slightly from the training distribution. So, the gap in raw capability is a pain point – one must temper expectations when using local models, which can be frustrating for those accustomed to ChatGPT’s reliability.

- **Limited context length:** Most open-source LLMs traditionally have smaller context windows (2048 tokens, maybe 4k tokens) compared to what ChatGPT or Claude offer. Some newer finetunes and architectures are extending this (for instance, there are 8K or 16K token versions of LLaMA-2, and research like MPT-7B had a 16K context). However, practical use of very long context open models is still in early stages. This means local model users face similar memory issues – the model forgets earlier parts of the conversation or text, unless they implement external memory schemes (like vector databases for retrieval). In Reddit discussions, users often mention having to manually summarize or truncate history to stay within limits, which is laborious. This is a notable limitation especially since proprietary models are pushing context lengths further (like Claude’s 100k).

- **Lack of fine-tuned instruction-following in some models:** While many open models are instruction-tuned (Alpaca, LLaMA-2-Chat, etc.), not all are as rigorously RLHF-trained as ChatGPT. This can result in local models sometimes being less responsive to instructions or system prompts. For example, a raw LLaMA model will just continue text and ignore a user prompt format entirely – one must use a chat-tuned version. Even then, the quality of the tuning data matters. Some Reddit users noted that certain instruct models either *overly* refused (because they were tuned with heavy safety, e.g. some Facebook LLaMA-2 chat would reply with policy refusals similar to ChatGPT) or *under*-performed (not following the query precisely). A user complaint on a GitHub about CodeLlama-70B-instruct said it *“is so censored it's basically useless”*, showing frustration that an open model adopted the same strictness without the alternative of turning it off. So, depending on the model chosen, users might face either a model that is too loose (and gives irrelevant continuation) or one that is too strict/guarded. Getting a well-balanced instruction-following behavior often requires trying multiple finetunes.

- **Fragmentation and rapid change:** The open-source LLM landscape evolves extremely fast, with new models and techniques (quantization, LoRA finetunes, etc.) emerging weekly. While exciting, this is a pain point for users who don’t want to constantly tweak their setup. What worked last month might be outdated by this month. One Redditor humorously compared it to the wild west, saying the community is *“finding ways to ‘fake it’ so it feels like it’s similar [to GPT-4]”* but often these are stopgap solutions. For a casual user, it’s daunting to even choose from dozens of model names (Vicuna, Alpaca, Mythomax, Mistral, etc.), each with multiple versions and forks. Without a single unified platform, users rely on community guides – which can be confusing – to decide what model suits their needs. This fragmentation in tools and model quality is an indirect pain point: it raises the entry barrier and maintenance effort.

- **No official support or guarantees:** When something goes wrong with a local LLM (e.g., the model outputs offensive content or crashes), there’s no customer support to call. Users are on their own or reliant on community help. For hobbyists this is fine, but for professional use this lack of formal support is a barrier. Some Reddit users working in companies noted that while they’d love the privacy of an open model, they worry about who to turn to if the model malfunctions or if they need updates. Essentially, using open-source is DIY – both a strength and a weakness.

### Frequently Requested Features or Improvements

- **Better efficiency (quantization and optimization):** A major focus in the community (and thus a common request) is making large models run on smaller hardware. Users eagerly await techniques that let a 70B model run as smoothly as a 7B model. There’s already 4-bit or 8-bit quantization, and threads often discuss new methods like AWQ or RNN-like adapters. One user cited research where improved quantization could maintain quality at lower bit precision. The wish is essentially: *“Let me run a GPT-4-level model on my PC without lag.”* Every breakthrough that edges closer (like more efficient transformer architectures or GPU offloading to CPU) is celebrated. So, requests for better tooling (like the next-generation of llama.cpp or other accelerators) are common – anything to reduce the hardware barrier.

- **Larger and better models (closing the quality gap):** The community constantly pushes for new state-of-the-art open models. Users are excited about projects like LLaMA 3 (if/when Meta releases one) or collaborations that could produce a 100B+ open model. Many express optimism that *“we will have local GPT-4 models on our machines by the end of this year”*. In that quote, the user bets on LLaMA 3 plus fine-tuning to deliver GPT-4-like performance. So, one could say a “requested feature” is simply: **more weight, more training** – the community wants tech companies or research groups to open-source bigger, better models so they can run them locally. Each time a new model (like Mistral 7B or Falcon 40B) comes out, users test if it beats the last. The ultimate request is an open model that truly rivals GPT-4, eliminating the need for closed AI for those who can host it.

- **User-friendly interfaces and one-click setups:** To broaden adoption, many users ask for easier ways to use local LLMs. This includes GUI interfaces where one can download a model and start chatting without command-line work. There are projects addressing this (Oobabooga’s text-generation-webui, LM Studio, etc.), but newcomers still struggle. A recent Reddit thread might ask, *“How do I set up a ChatGPT-like LLM locally?”*, with users requesting step-by-step guides. So a frequent wish is for a **simplified installation** – perhaps an official app or Docker container that bundles everything needed, or integration into popular software (imagine an extension that brings a local LLM into VSCode or Chrome easily). Essentially, reduce the technical overhead so that less tech-savvy folks can also enjoy private LLMs.

- **Longer context and memory for local models:** Open-source developers and users are experimenting with extending context (through positional embedding tweaks or specialized models). Many users request that new models come with longer context windows by default – for example, an open model with 32k context would be very attractive. Until that happens, some rely on external “retrieval” solutions (LangChain with a vector store that feeds relevant info into the prompt). Users on r/LocalLLaMA frequently discuss their setups for pseudo-long-context, but also express desire for the models themselves to handle more. So an improvement they seek is: *“Give us a local Claude – something with tens of thousands of tokens of context.”* This would allow them to do book analysis, long conversations, or big codebase work locally.

- **Improved fine-tuning tools and model customization:** Another ask is making it easier to fine-tune or personalize models. While libraries exist to fine-tune models on new data (Alpaca did it with 52K instructions, Low-Rank Adaptation (LoRA) allows finetuning with limited compute, etc.), it’s still somewhat involved. Users would love more accessible tooling to, say, feed all their writings or company documents to the model and have it adapt. Projects like LoRA are steps in that direction, but a more automated solution (perhaps a wizard UI: “upload your documents here to fine-tune”) would be welcomed. Essentially, bring the ability that OpenAI provides via API (fine-tuning models on custom data) to the local realm in a user-friendly way.

- **Community-driven safety and moderation tools:** Given open models can produce anything (including disallowed content), some users have requested or started developing moderation layers that users can toggle or adjust. This is a bit niche, but the idea is to have *optional* filters to catch egregious outputs if someone wants them (for example, if kids or students might interact with the model locally). Since open models won’t stop themselves, having a plugin or script to scan outputs for extreme content could be useful. Some in the community work on “ethical guardrails” that you can opt into, which is interesting because it gives user control. So, features around **controlling model behavior** – whether to make it safer or to remove safeties – are often discussed and requested, depending on the user’s goals.

### Underserved Needs or User Segments

- **Non-technical users valuing privacy:** Right now, local LLMs largely cater to tech enthusiasts. A person who isn’t computer-savvy but cares about data privacy (for instance, a psychotherapist who wants AI help analyzing notes but cannot upload them to the cloud) is underserved. They need a local solution that’s easy and safe, but the complexity is a barrier. Until local AI becomes as easy as installing an app, these users remain on the sidelines – either compromising by using cloud AI and risking privacy, or not using AI at all. This segment – privacy-conscious but not highly technical individuals – is clearly underserved by the current open-source offerings.

- **Budget-conscious users in regions with poor internet:** Another segment that benefits from local models is people who don’t have reliable internet or can’t afford API calls. If someone could get a decent offline chatbot on a low-end machine, it’d be valuable (imagine educators or students in remote areas). Presently, the quality offline might not be great unless you have a high-end PC. There are some very small models that run on phones, but their ability is limited. So, users who *need offline AI* – due to connectivity or cost – are a group that open-source could serve, but the technology is just at the cusp of being helpful enough. They’ll be better served as models get more efficient.

- **Creators of NSFW or specialized content:** One reason open models gained popularity is that they can be uncensored, enabling use cases that closed AIs forbid (erotic roleplay, exploring violent fiction, etc.). While this “underserved” segment is controversial, it is real – many Reddit communities (e.g., for AI Dungeon or character chatbots) moved to local models after OpenAI and others tightened content rules. These users are now served by open models to an extent, but they often have to find or finetune models specifically for this purpose (like Mythomax for storytelling, etc.). They occasionally lament that many open models still have remnants of safety training (refusing certain requests). So they desire models explicitly tuned for uncensored creativity. Arguably they *are* being served (since they have solutions), but not by mainstream defaults – they rely on niche community forks.

- **Language and cultural communities:** Open-source models could be fine-tuned for specific languages or local knowledge, but most prominent ones are English-centric. Users from non-English communities may be underserved because neither OpenAI nor open models cater perfectly to their language/slang/cultural context. There are efforts (like BLOOM and XLM variants) to build multilingual open models, and local users request finetunes in languages like Spanish, Arabic, etc. If someone wants a chatbot deeply fluent in their regional dialect or up-to-date on local news (in their language), the major models might not deliver. This is a segment open models *could* serve well (via community finetuning) – and on Reddit we do see people collaborating on, say, a Japanese-tuned LLM. But until such models are readily available and high-quality, these users remain somewhat underserved.

- **Small businesses and self-hosters:** Some small companies or power users would love to deploy an AI model internally to avoid sending data out. They are somewhat served by open source in that it’s possible, but they face challenges in ensuring quality and maintenance. Unlike big enterprises (which can pay for OpenAI or a hosted solution), small businesses might try to self-host to save costs and protect IP. When they do, they may find the model isn’t as good, or it’s hard to keep updated. This segment is in a middle ground – not huge enough to build their own model from scratch, but capable enough to attempt using open ones. They often share tips on Reddit about which model works for customer service bots, etc. They could benefit from more turn-key solutions built on open models (some startups are emerging in this space).

### Differences in Perception by User Type

- **Developers/Hobbyists:** This group is the backbone of the open-source LLM community on Reddit (e.g., r/LocalLLaMA is full of them). Their perception is generally optimistic and enthusiastic. They trade models and benchmarks like collectors. Many developers are thrilled by how far open models have come in a short time. For instance, a user shared that a leaked 70B model fine-tuned (Miqu-1 70B) felt *“on par with GPT-4 for what I need… I canceled my ChatGPT+ subscription months ago and never looked