---
title: "تعليقات مستخدمي Reddit على أدوات الدردشة LLM الرئيسية"
tags: [الذكاء الاصطناعي, ChatGPT, Claude, Google Gemini, LLMs مفتوحة المصدر]
keywords: [أدوات الدردشة بالذكاء الاصطناعي, تعليقات المستخدمين, ChatGPT, Claude, Google Gemini, LLMs مفتوحة المصدر, تحليل Reddit]
authors: [lark]
description: تقدم هذه المقالة تحليلًا متعمقًا لمناقشات Reddit حول أدوات الدردشة بالذكاء الاصطناعي الشهيرة، بما في ذلك ChatGPT و Claude و Google Gemini و LLMs مفتوحة المصدر. تسلط الضوء على نقاط الألم التي أبلغ عنها المستخدمون، والميزات المطلوبة بشكل متكرر، والاحتياجات غير الملباة، وتقديم رؤى حول نقاط القوة والضعف لكل أداة.
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=تعليقات%20مستخدمي%20Reddit%20على%20أدوات%20الدردشة%20LLM%20الرئيسية"
---

# تعليقات مستخدمي Reddit على أدوات الدردشة LLM الرئيسية

**نظرة عامة:** يحلل هذا التقرير مناقشات Reddit حول أربعة من أدوات الدردشة بالذكاء الاصطناعي الشهيرة – **ChatGPT من OpenAI**، **Claude من Anthropic**، **Gemini (Bard) من Google**، و **LLMs مفتوحة المصدر** (مثل النماذج المستندة إلى LLaMA). يلخص نقاط الألم الشائعة التي يبلغ عنها المستخدمون لكل منها، والميزات التي يطلبونها بشكل متكرر، والاحتياجات غير الملباة أو الفئات التي تشعر بأنها غير مخدومة، والاختلافات في التصور بين المطورين والمستخدمين العاديين والمستخدمين التجاريين. تتضمن أمثلة محددة واقتباسات من سلاسل Reddit لتوضيح هذه النقاط.

![تعليقات مستخدمي Reddit على أدوات الدردشة LLM الرئيسية](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=تعليقات%20مستخدمي%20Reddit%20على%20أدوات%20الدردشة%20LLM%20الرئيسية)

## ChatGPT (OpenAI)

### نقاط الألم والقيود الشائعة

- **ذاكرة السياق المحدودة:** من الشكاوى الرئيسية هي عدم قدرة ChatGPT على التعامل مع المحادثات الطويلة أو الوثائق الكبيرة دون نسيان التفاصيل السابقة. غالبًا ما يصل المستخدمون إلى حد طول السياق (بضعة آلاف من الرموز) ويجب عليهم تقليص أو تلخيص المعلومات. أشار أحد المستخدمين إلى *"زيادة حجم نافذة السياق سيكون أكبر تحسين... هذا هو الحد الذي أواجهه أكثر"*. عندما يتم تجاوز السياق، ينسى ChatGPT التعليمات أو المحتوى الأولي، مما يؤدي إلى انخفاض الجودة بشكل محبط في منتصف الجلسة.

- **حدود الرسائل لـ GPT-4:** يأسف مستخدمو ChatGPT Plus على حد 25 رسالة/3 ساعات لاستخدام GPT-4 (حد موجود في عام 2023). يؤدي الوصول إلى هذا الحد إلى إجبارهم على الانتظار، مما يقطع العمل. يجد المستخدمون الثقيلون أن هذا التقييد نقطة ألم رئيسية.

- **مرشحات المحتوى الصارمة ("التقليل"):** يشعر العديد من مستخدمي Reddit أن ChatGPT أصبح مقيّدًا بشكل مفرط، وغالبًا ما يرفض الطلبات التي كانت الإصدارات السابقة تتعامل معها. اشتكى منشور حصل على تصويتات عالية من أن *"أي شيء تطلبه هذه الأيام يعيد 'آسف، لا أستطيع مساعدتك'... كيف انتقل هذا من الأداة الأكثر فائدة إلى ما يعادل مساعد Google؟"*. يذكر المستخدمون أمثلة مثل رفض ChatGPT إعادة تنسيق *نصهم الخاص* (مثل بيانات تسجيل الدخول) بسبب سوء الاستخدام الافتراضي. يجادل المشتركون الذين يدفعون بأن *"بعض المفاهيم الغامضة بأن المستخدم قد يفعل 'أشياء سيئة'... لا ينبغي أن تكون سببًا لعدم عرض النتائج"*, حيث يريدون مخرجات النموذج وسيستخدمونها بمسؤولية.

- **الهلوسة والأخطاء:** على الرغم من قدرته المتقدمة، يمكن لـ ChatGPT إنتاج معلومات غير صحيحة أو مختلقة بثقة. لاحظ بعض المستخدمين أن هذا يزداد سوءًا بمرور الوقت، مشككين في أن النموذج تم "تبسيطه". على سبيل المثال، قال مستخدم في مجال التمويل إن ChatGPT كان يحسب مقاييس مثل NPV أو IRR بشكل صحيح، ولكن بعد التحديثات *"أحصل على العديد من الإجابات الخاطئة... لا يزال ينتج إجابات خاطئة [حتى بعد التصحيح]. أعتقد حقًا أنه أصبح أكثر غباءً منذ التغييرات."*. تؤدي مثل هذه الأخطاء غير المتوقعة إلى تآكل الثقة في المهام التي تتطلب دقة واقعية.

- **مخرجات الكود غير المكتملة:** غالبًا ما يستخدم المطورون ChatGPT للمساعدة في البرمجة، لكنهم يبلغون أنه أحيانًا يحذف أجزاء من الحل أو يقطع الكود الطويل. شارك أحد المستخدمين أن ChatGPT الآن *"يحذف الكود، ينتج كود غير مفيد، ويفشل في الشيء الذي أحتاجه للقيام به... غالبًا ما يحذف الكثير من الكود لدرجة أنني لا أعرف حتى كيفية دمج حله."* يجبر هذا المستخدمين على طرح مطالبات متابعة لاستخراج الباقي، أو تجميع الإجابات يدويًا – وهي عملية مملة.

- **مخاوف الأداء والوقت التشغيلي:** هناك تصور بأن أداء ChatGPT للمستخدمين الفرديين انخفض مع زيادة الاستخدام المؤسسي. *"أعتقد أنهم يخصصون عرض النطاق الترددي وقوة المعالجة للشركات ويأخذونها بعيدًا عن المستخدمين، وهو أمر لا يطاق بالنظر إلى ما يكلفه الاشتراك!"* أبدى أحد المشتركين في Plus استياءه. تم ملاحظة الانقطاعات أو البطء خلال أوقات الذروة بشكل غير رسمي، مما يمكن أن يعطل سير العمل.

### الميزات أو التحسينات المطلوبة بشكل متكرر

- **نافذة سياق أطول / ذاكرة:** التحسين الأكثر طلبًا هو زيادة طول السياق. يريد المستخدمون إجراء محادثات أطول بكثير أو تغذية وثائق كبيرة دون إعادة التعيين. يقترح الكثيرون توسيع سياق ChatGPT ليطابق قدرة GPT-4 على 32K رمز (متاحة حاليًا عبر API) أو أكثر. كما قال أحد المستخدمين، *"GPT هو الأفضل مع السياق، وعندما لا يتذكر السياق الأولي، أشعر بالإحباط... إذا كانت الشائعات صحيحة بشأن ملفات PDF السياقية، فسيحل ذلك جميع مشاكلي."* هناك طلب كبير على ميزات لتحميل الوثائق أو ربط البيانات الشخصية حتى يتمكن ChatGPT من تذكرها والرجوع إليها طوال الجلسة.

- **التعامل مع الملفات والتكامل:** يطلب المستخدمون بشكل متكرر طرقًا أسهل لتغذية الملفات أو البيانات إلى ChatGPT. في المناقشات، يذكر الناس رغبتهم في *"نسخ ولصق محرك Google الخاص بي وجعله يعمل"* أو وجود مكونات إضافية تتيح لـ ChatGPT جلب السياق مباشرة من الملفات الشخصية. حاول البعض حلولاً بديلة (مثل مكونات قراءة PDF أو ربط مستندات Google)، لكنهم اشتكوا من الأخطاء والحدود. وصف أحد المستخدمين المكون الإضافي المثالي بأنه *"يعمل مثل قارئ الروابط ولكن للملفات الشخصية... اختيار الأجزاء التي أريد استخدامها في محادثة... سيحل ذلك كل مشكلة أواجهها مع GPT-4 حاليًا."*. باختصار، الدعم الأصلي الأفضل للمعرفة الخارجية (بخلاف بيانات التدريب) هو طلب شائع.

- **تقليل التقييد للمستخدمين المدفوعين:** نظرًا لأن العديد من مستخدمي Plus يصلون إلى حد رسائل GPT-4، فإنهم يطالبون بحدود أعلى أو خيار الدفع أكثر للوصول غير المحدود. يُنظر إلى حد 25 رسالة على أنه تعسفي ويعيق الاستخدام المكثف. يفضل الناس نموذجًا قائمًا على الاستخدام أو حدًا أعلى بحيث لا يتم قطع جلسات حل المشكلات الطويلة.

- **أوضاع الرقابة المخصصة أو غير المقيدة:** يرغب جزء من المستخدمين في القدرة على تبديل صرامة مرشحات المحتوى، خاصة عند استخدام ChatGPT لأنفسهم (وليس للمحتوى العام). يشعرون أن وضع "البحث" أو "غير المقيد" – مع تحذيرات ولكن بدون رفضات صارمة – سيسمح لهم بالاستكشاف بحرية أكبر. كما أشار أحد المستخدمين، يرى العملاء الذين يدفعون المال أنها أداة ويعتقدون *"أدفع المال مقابل [ذلك]."* يريدون الخيار للحصول على إجابات حتى في الاستفسارات الحدودية. بينما يجب على OpenAI تحقيق التوازن بين الأمان، يقترح هؤلاء المستخدمون وجود علم أو إعداد لتخفيف السياسات في الدردشات الخاصة.

- **تحسين الدقة الواقعية والتحديثات:** يطلب المستخدمون بشكل شائع الحصول على معرفة أكثر حداثة وتقليل الهلوسات. كان حد المعرفة في ChatGPT (سبتمبر 2021 في الإصدارات السابقة) قيدًا غالبًا ما يُثار على Reddit. قدمت OpenAI منذ ذلك الحين التصفح والمكونات الإضافية، والتي يستخدمها بعض المستخدمين، لكن البعض الآخر يطلب ببساطة تحديث النموذج الأساسي بشكل متكرر مع بيانات جديدة. تقليل الأخطاء الواضحة – خاصة في المجالات مثل الرياضيات والبرمجة – هو رغبة مستمرة. يقدم بعض المطورين ملاحظات عندما يخطئ ChatGPT على أمل تحسين النموذج.

- **مخرجات الكود والأدوات الأفضل:** لدى المطورين طلبات ميزات مثل مفسر الكود المحسن الذي لا يحذف المحتوى، والتكامل مع IDEs أو التحكم في الإصدار. (كان مكون OpenAI’s Code Interpreter الإضافي – الآن جزءًا من "تحليل البيانات المتقدم" – خطوة في هذا الاتجاه وحصل على الثناء.) ومع ذلك، غالبًا ما يطلب المستخدمون تحكمًا أدق في توليد الكود: على سبيل المثال، خيار لإخراج كود كامل وغير مفلتر حتى لو كان طويلاً، أو آليات لإصلاح الكود بسهولة إذا ارتكب الذكاء الاصطناعي خطأً. في الأساس، يريدون أن يتصرف ChatGPT كمساعد برمجة موثوق به دون الحاجة إلى مطالبات متعددة لتحسين الإجابة.

- **ملفات تعريف المستخدم الدائمة أو الذاكرة:** تحسين آخر يذكره البعض هو السماح لـ ChatGPT بتذكر أشياء عن المستخدم عبر الجلسات (بموافقة). على سبيل المثال، تذكر أسلوب الكتابة الخاص بهم، أو أنهم مهندس برمجيات، دون الحاجة إلى إعادة ذكره في كل دردشة جديدة. يمكن أن يرتبط هذا بضبط API أو ميزة "الملف الشخصي". يقوم المستخدمون بنسخ السياق المهم يدويًا إلى الدردشات الجديدة الآن، لذا فإن الذاكرة المدمجة للتفضيلات الشخصية ستوفر الوقت.

### الاحتياجات غير الملباة أو الفئات غير المخدومة

- **الباحثون والطلاب ذوو الوثائق الطويلة:** الأشخاص الذين يريدون من ChatGPT تحليل الأوراق البحثية الطويلة أو الكتب أو مجموعات البيانات الكبيرة يشعرون بأنهم غير مخدومين. تجبرهم الحدود الحالية على تقطيع النص أو الاكتفاء بالملخصات. ستستفيد هذه الفئة بشكل كبير من نوافذ السياق الأكبر أو الميزات للتعامل مع الوثائق الطويلة (كما يتضح من العديد من المنشورات حول محاولة تجاوز حدود الرموز).

- **المستخدمون الذين يبحثون عن سرد قصصي إبداعي أو لعب أدوار يتجاوز الحدود:** بينما يُستخدم ChatGPT غالبًا للكتابة الإبداعية، يشعر بعض الكتاب القصصيين بأن النموذج مقيد بنسيان نقاط الحبكة المبكرة في قصة طويلة أو رفض المحتوى البالغ/الرعب. يلجؤون إلى النماذج البديلة أو الحيل لمواصلة رواياتهم. سيكون هؤلاء المستخدمون الإبداعيون أفضل خدمة من خلال نسخة من ChatGPT بذاكرة أطول وقليل من المرونة في العنف الخيالي أو الموضوعات الناضجة (ضمن المعقول). كما أشار أحد كتاب الخيال، عندما يفقد الذكاء الاصطناعي مسار القصة، *"يجب أن أذكره بالتنسيق أو السياق الدقيق... أشعر بالإحباط لأنه كان رائعًا قبل مطلبين، لكن الآن يجب أن ألحق بالذكاء الاصطناعي."*.

- **المستخدمون الأقوياء والخبراء في المجال:** يجد المحترفون في المجالات المتخصصة (**المالية**، **الهندسة**، **الطب**) أحيانًا أن إجابات ChatGPT تفتقر إلى العمق أو الدقة في مجالهم، خاصة إذا كانت الأسئلة تتضمن تطورات حديثة. يرغب هؤلاء المستخدمون في الحصول على معرفة خبيرة أكثر موثوقية. حاول البعض ضبط النموذج عبر API أو GPTs مخصصة. أولئك الذين لا يمكنهم ضبط النموذج يقدرون نسخًا خاصة بالمجال من ChatGPT أو مكونات إضافية تدمج قواعد بيانات موثوقة. في شكله الافتراضي، قد لا يخدم ChatGPT المستخدمين الذين يحتاجون إلى معلومات دقيقة للغاية ومحددة بالمجال (غالبًا ما يضطرون إلى التحقق من عمله).

- **المستخدمون الذين يحتاجون إلى محتوى غير مقيد أو حالات حافة:** يجد أقلية من المستخدمين (المخترقين الذين يختبرون سيناريوهات الأمان، كتاب الخيال المتطرف، إلخ) أن قيود محتوى ChatGPT مفرطة لاحتياجاتهم. هم حاليًا غير مخدومين من قبل المنتج الرسمي (لأنه يتجنب صراحةً محتوى معينًا). غالبًا ما يجرب هؤلاء المستخدمون مطالبات الاختراق أو يستخدمون النماذج مفتوحة المصدر للحصول على الإجابات التي يريدونها. هذه فجوة متعمدة لـ OpenAI (للحفاظ على الأمان)، لكنها تعني أن هؤلاء المستخدمين يبحثون في مكان آخر.

- **الأفراد والشركات المهتمون بالخصوصية:** يشعر بعض المستخدمين (خاصة في البيئات المؤسسية) بعدم الارتياح لإرسال بيانات حساسة إلى ChatGPT بسبب مخاوف الخصوصية. لدى OpenAI سياسات لعدم استخدام بيانات API للتدريب، ولكن واجهة ChatGPT على الويب لم تقدم تاريخيًا مثل هذه الضمانات حتى تمت إضافة ميزة إلغاء الاشتراك. غالبًا ما تشعر الشركات التي تتعامل مع البيانات السرية (القانونية، الرعاية الصحية، إلخ) بأنها لا تستطيع استخدام ChatGPT بالكامل، مما يترك احتياجاتها غير مخدومة ما لم تبني حلولًا مستضافة ذاتيًا. على سبيل المثال، ذكر مستخدم Reddit أن شركتهم انتقلت إلى LLM محلي لأسباب الخصوصية. حتى تتوفر مثيلات ChatGPT المحلية أو الخاصة، تظل هذه الفئة حذرة أو تستخدم بائعين متخصصين أصغر.

### الاختلافات في التصور حسب نوع المستخدم

- **المطورون/المستخدمون التقنيون:** يميل المطورون إلى أن يكونوا من أكبر المدافعين عن ChatGPT وأشد المنتقدين له. يحبون قدرته على شرح الكود، وتوليد القوالب، والمساعدة في تصحيح الأخطاء. ومع ذلك، يشعرون بشدة بحدوده في السياق الأطول ودقة الكود. كما اشتكى أحد المطورين، بدأ ChatGPT *"في إنتاج كود غير مفيد"* وحذف أجزاء مهمة، مما *"يغضبني... لا أريد أن أقول له 'لا تكن كسولاً' – أريد فقط النتيجة الكاملة"*. غالبًا ما يلاحظ المطورون حتى التغييرات الطفيفة في الجودة بعد تحديثات النموذج وكانوا صريحين جدًا على Reddit بشأن "التقليل" المتصور أو التراجع في قدرة البرمجة. كما أنهم يدفعون الحدود (بناء مطالبات معقدة، ربط الأدوات)، لذا فإنهم يتوقون إلى ميزات مثل السياق الموسع، وحدود الرسائل الأقل، والتكامل الأفضل مع أدوات البرمجة. باختصار، يقدر المطورون ChatGPT لتسريع المهام الروتينية ولكنهم سريعون في الإشارة إلى الأخطاء في المنطق أو الكود – يرونه كمساعد مبتدئ لا يزال يحتاج إلى إشراف.

- **المستخدمون العاديون/اليوميون:** غالبًا ما يندهش المستخدمون العاديون – أولئك الذين يسألون عن المعرفة العامة أو النصائح أو المرح – من قدرات ChatGPT، لكن لديهم شكاواهم الخاصة. إحباط شائع للمستخدم العادي هو عندما يرفض ChatGPT طلبًا يبدو غير ضار بالنسبة لهم (من المحتمل أن يتعثر في قاعدة سياسة). كان المنشور الأصلي في أحد المواضيع مثالًا على ذلك، حيث كان *"غاضبًا جدًا عندما أكتب مطلبًا لا ينبغي أن يكون لديه مشكلة معه ويرفض الآن"*. قد يواجه المستخدمون العاديون أيضًا حد المعرفة (اكتشاف أن الروبوت لا يمكنه التعامل مع الأحداث الحالية جدًا ما لم يتم تحديثه صراحةً) وأحيانًا يلاحظون عندما يقدم ChatGPT إجابة خاطئة بشكل واضح. على عكس المطورين، قد لا يتحققون دائمًا من الذكاء الاصطناعي، مما قد يؤدي إلى خيبة أمل إذا تصرفوا بناءً على خطأ. على الجانب الإيجابي، يجد العديد من المستخدمين العاديين أن استجابات ChatGPT Plus الأسرع وإخراج GPT-4 المحسن يستحقان 20 دولارًا شهريًا – ما لم تفسد تجربة "الرفض" أو الحدود الأخرى التجربة. يريدون عمومًا مساعدًا مفيدًا متعدد الأغراض ويمكن أن يشعروا بالإحباط عندما يرد ChatGPT ببيانات السياسة أو يحتاج إلى مطلب معقد للحصول على إجابة بسيطة.

- **المستخدمون التجاريون/المحترفون:** غالبًا ما يقترب المستخدمون التجاريون من ChatGPT من منظور الإنتاجية والموثوقية. يقدرون المسودات السريعة للبريد الإلكتروني، وملخصات الوثائق، أو توليد الأفكار. ومع ذلك، فإنهم قلقون بشأن **أمان البيانات**، والاتساق، والتكامل في سير العمل. على Reddit، ناقش المحترفون رغبتهم في ChatGPT في أدوات مثل Outlook وGoogle Docs، أو كـ API في أنظمتهم الداخلية. لاحظ البعض أنه مع تحول OpenAI لخدمة العملاء المؤسسيين، يبدو أن تركيز المنتج يتحول: هناك شعور بأن تجربة المستخدم الفردي أو المجاني تدهورت قليلاً (على سبيل المثال، أبطأ أو "أقل ذكاءً") مع توسع الشركة لخدمة العملاء الأكبر. سواء كان ذلك صحيحًا أم لا، فإنه يسلط الضوء على تصور: يريد المستخدمون التجاريون الموثوقية والخدمة ذات الأولوية، ويقلق المستخدمون الفرديون من أنهم الآن من الدرجة الثانية. بالإضافة إلى ذلك، يحتاج المحترفون إلى مخرجات صحيحة – يمكن أن تكون الإجابة الخاطئة اللامعة أسوأ من عدم الإجابة. وبالتالي، فإن هذا القطاع حساس للدقة. بالنسبة لهم، تعتبر الميزات مثل السياق الأطول (لقراءة العقود، وتحليل قواعد الأكواد) والوقت التشغيلي المضمون أمرًا بالغ الأهمية. من المرجح أن يدفعوا أكثر مقابل مستويات الخدمة المتميزة، بشرط أن يتم تلبية متطلبات الامتثال والخصوصية الخاصة بهم. تستكشف بعض الشركات حتى عمليات النشر المحلية أو استخدام API الخاص بـ OpenAI مع قواعد صارمة للتعامل مع البيانات لتلبية سياسات تكنولوجيا المعلومات الخاصة بهم.

---

## Claude (Anthropic)

### نقاط الألم والقيود الشائعة

- **حدود الاستخدام وقيود الوصول:** حصل Claude على الثناء لتقديم نموذج قوي (Claude 2) مجانًا، لكن المستخدمين واجهوا بسرعة حدود الاستخدام (خاصة في الطبقة المجانية). بعد عدد معين من المطالبات أو كمية كبيرة من النصوص، قد يتوقف Claude ويقول شيئًا مثل *"آسف، يجب أن أنهي هذه المحادثة الآن. يرجى العودة لاحقًا."* يثير هذا التقييد إحباط المستخدمين الذين يعاملون Claude كشريك في البرمجة أو الكتابة الممتدة. حتى مستخدمي Claude Pro (المدفوع) *"لا يضمن لهم وقت غير محدود"*, كما أشار أحد المستخدمين؛ الوصول إلى الحصة لا يزال ينتج رسالة "العودة لاحقًا". بالإضافة إلى ذلك، لفترة طويلة كان Claude مقيدًا جغرافيًا رسميًا (متاحًا في البداية فقط في الولايات المتحدة/المملكة المتحدة). كان على المستخدمين الدوليين على Reddit استخدام VPNs أو منصات طرف ثالث للوصول إليه، مما كان يمثل إزعاجًا. جعل هذا العديد من المستخدمين غير الأمريكيين يشعرون بأنهم مستبعدون حتى توسع الوصول.

- **ميل للانحراف مع المدخلات الكبيرة جدًا:** الميزة الرئيسية لـ Claude هي *نافذة السياق 100k-token*، مما يسمح بالمطالبات الطويلة للغاية. ومع ذلك، لاحظ بعض المستخدمين أنه عندما تحشو عشرات الآلاف من الرموز في Claude، يمكن أن تصبح استجاباته أقل تركيزًا. *"100k مفيدة للغاية ولكن إذا لم يتبع التعليمات بشكل صحيح وانحرف عن المسار، فهي ليست مفيدة جدًا,"* لاحظ أحد المستخدمين. يشير هذا إلى أنه مع السياقات الضخمة، قد ينحرف Claude أو يبدأ في الثرثرة، مما يتطلب توجيهًا دقيقًا للحفاظ عليه في المهمة. إنها قيد متأصل في دفع السياق إلى أقصى الحدود – يحتفظ النموذج بالكثير ولكنه أحيانًا "ينسى" أي التفاصيل هي الأكثر صلة، مما يؤدي إلى هلوسات طفيفة أو انحرافات خارج الموضوع.

- **التنسيق غير المتسق أو الطاعة للتعليمات:** في المقارنات الجانبية، وجد بعض المستخدمين أن Claude أقل قابلية للتنبؤ في كيفية اتباعه لتوجيهات معينة. على سبيل المثال، يوصف Claude بأنه *"أكثر إنسانية في التفاعلات. ولكنه يتبع رسائل النظام بشكل أقل صرامة."*. هذا يعني إذا أعطيته تنسيقًا ثابتًا ليتبعه أو شخصية صارمة جدًا، فقد ينحرف Claude أكثر مما يفعل ChatGPT. المطورون الذين يعتمدون على المخرجات الحتمية (مثل تنسيقات JSON أو الأنماط المحددة) يشعرون أحيانًا بالإحباط إذا قدم Claude تعليقًا إضافيًا أو لم يلتزم بدقة بالقالب.

- **قيود المحتوى والرفض:** بينما لا يتم انتقادها بشكل متكرر مثل ChatGPT، فإن مرشحات الأمان في Claude تظهر. صممت Anthropic Claude مع التركيز بشكل كبير على الذكاء الاصطناعي الدستوري (حيث يتبع الذكاء الاصطناعي نفسه المبادئ الأخلاقية). يجد المستخدمون عمومًا أن Claude مستعد لمناقشة مجموعة واسعة من المواضيع، ولكن هناك حالات يرفض فيها Claude الطلبات التي قد يسمح بها ChatGPT. على سبيل المثال، لاحظ أحد مستخدمي Reddit *"لدى ChatGPT قيود أخلاقية أقل... سيشرح أي الأقنعة الغازية أفضل لأي ظروف بينما سيرفض Claude"*. يشير هذا إلى أن Claude قد يكون أكثر صرامة بشأن بعض النصائح "الحساسة" (ربما يعاملها كإرشادات خطيرة محتملة). حاول مستخدم آخر سيناريو لعب دور مرح ("تظاهر بأنك اختطفت من قبل كائنات فضائية") الذي رفضه Claude، بينما كان Gemini وChatGPT يتفاعلان. لذا، لدى Claude مرشحات يمكن أن تفاجئ المستخدمين أحيانًا الذين يتوقعون أن يكون أكثر تسامحًا.

- **نقص القدرات متعددة الوسائط:** على عكس ChatGPT (الذي، بحلول أواخر 2023، اكتسب فهم الصور مع GPT-4 Vision)، فإن Claude حاليًا نصي فقط. يلاحظ مستخدمو Reddit أن Claude لا يمكنه تحليل الصور أو تصفح الويب مباشرةً. هذا ليس بالضبط "نقطة ألم" (لم تعلن Anthropic عن هذه الميزات)، ولكنه قيد نسبيًا مقارنة بالمنافسين. المستخدمون الذين يريدون من الذكاء الاصطناعي تفسير مخطط أو لقطة شاشة لا يمكنهم استخدام Claude لذلك، بينما قد يتعامل ChatGPT أو Gemini مع ذلك. وبالمثل، يتطلب أي استرجاع للمعلومات الحالية استخدام Claude عبر أداة طرف ثالث (مثل Poe أو تكامل محرك البحث)، حيث لا يمتلك Claude وضع تصفح رسمي في هذا الوقت.

- **مشكلات استقرار طفيفة:** أبلغ بعض المستخدمين عن Claude أحيانًا يكون متكررًا أو عالقًا في حلقات لبعض المطالبات (على الرغم من أن هذا أقل شيوعًا من بعض النماذج الأصغر). أيضًا، كانت الإصدارات السابقة من Claude أحيانًا تنهي الاستجابات قبل الأوان أو تستغرق وقتًا طويلاً مع المخرجات الكبيرة، مما يمكن اعتباره إزعاجات طفيفة، على الرغم من أن Claude 2 قد تحسن في السرعة.

### الميزات أو التحسينات المطلوبة بشكل متكرر

- **حدود استخدام أعلى أو قابلة للتعديل:** غالبًا ما يطلب عشاق Claude على Reddit من Anthropic رفع حدود المحادثة. يرغبون في استخدام سياق 100k إلى أقصى حد دون الوصول إلى توقف مصطنع. يقترح البعض أن حتى Claude Pro المدفوع يجب أن يسمح *بشكل كبير* بمزيد من الرموز يوميًا. طرح آخرون فكرة "وضع سياق 100k الممتد" اختياريًا – على سبيل المثال، *"يجب أن يكون لدى Claude وضع سياق 100k مع ضعف حدود الاستخدام"* – حيث يمكن أن يقدم الاشتراك وصولاً موسعًا للمستخدمين الثقيلين. باختصار، هناك طلب على خطة تنافس استخدام ChatGPT غير المحدود (أو ذو الحد العالي) للمشتركين.

- **تحسين التنقل في السياق الطويل:** بينما يعد امتلاك 100k رمزًا أمرًا رائدًا، يريد المستخدمون أن يستفيد Claude بشكل أفضل من هذا السياق. سيكون أحد التحسينات هو تحسين كيفية تحديد Claude للأولويات حتى يظل في المسار. يمكن أن تعمل Anthropic على التزام النموذج بالمطالبات عندما يكون المطلب ضخمًا. تشير مناقشات Reddit إلى تقنيات مثل السماح للمستخدم "بتثبيت" تعليمات معينة حتى لا يتم تخفيفها في سياق كبير. يمكن أن تساعد أي أدوات لتقسيم أو تلخيص أجزاء من المدخلات أيضًا Claude في التعامل مع المدخلات الكبيرة بشكل أكثر اتساقًا. باختصار، يحب المستخدمون إمكانية تغذية كتاب كامل لـ Claude – يريدون فقط أن يظل حادًا طوال الوقت.

- **المكونات الإضافية أو التصفح عبر الويب:** اعتاد العديد من مستخدمي ChatGPT على المكونات الإضافية (على سبيل المثال، التصفح، تنفيذ الكود، إلخ) ويعبرون عن اهتمامهم بأن يكون لدى Claude نفس القابلية للتمديد. طلب شائع هو أن يكون لدى Claude وظيفة بحث/تصفح عبر الويب رسمية، حتى يتمكن من جلب المعلومات المحدثة عند الطلب. حاليًا، تكون معرفة Claude ثابتة في الغالب (بيانات التدريب حتى أوائل 2023، مع بعض التحديثات). إذا كان Claude يمكنه استعلام الويب، فسوف يخفف من هذا القيد. وبالمثل، يمكن أن يوسع نظام المكونات الإضافية حيث يمكن لـ Claude استخدام أدوات الطرف الثالث (مثل الآلات الحاسبة أو موصلات قواعد البيانات) من فائدته للمستخدمين الأقوياء. تظل هذه ميزة يفتقر إليها Claude، وغالبًا ما يذكر مستخدمو Reddit كيف يمنح نظام المكونات الإضافية في ChatGPT ميزة في مهام معينة.

- **المدخلات متعددة الوسائط (الصور أو الصوت):** تساءل بعض المستخدمين أيضًا عما إذا كان Claude سيدعم مدخلات الصور أو يولد الصور. تتمتع Google’s Gemini وOpenAI’s GPT-4 بقدرات متعددة الوسائط، لذا للبقاء في المنافسة، يتوقع المستخدمون أن تستكشف Anthropic هذا. طلب متكرر هو: *"هل يمكنني تحميل ملف PDF أو صورة لتحليلها بواسطة Claude؟"* حاليًا الإجابة هي لا (بخلاف الحلول البديلة مثل تحويل الصور إلى نص في مكان آخر). حتى السماح فقط بتحويل الصورة إلى نص (OCR والوصف) سيلبي العديد من الذين يريدون مساعدًا شاملاً. هذا في قائمة الأمنيات، على الرغم من أن Anthropic لم تعلن عن أي شيء مشابه حتى أوائل 2025.

- **التخصيص أو الضبط الدقيق:** يطلب المستخدمون المتقدمون والشركات أحيانًا ما إذا كان بإمكانهم ضبط Claude على بياناتهم الخاصة أو الحصول على إصدارات مخصصة. تقدم OpenAI الضبط الدقيق لبعض النماذج (ليس GPT-4 بعد، ولكن لـ GPT-3.5). أصدرت Anthropic واجهة ضبط دقيقة لـ Claude 1.3 في وقت سابق، لكنها ليست معلنة على نطاق واسع لـ Claude 2. استفسر مستخدمو Reddit عن إمكانية تدريب Claude على معرفة الشركة أو أسلوب الكتابة الشخصي. سيكون من المرحب به طريقة أسهل للقيام بذلك (بخلاف حقن المطالبات في كل مرة)، حيث يمكن أن يحول Claude إلى مساعد شخصي يتذكر قاعدة معرفية أو شخصية محددة.

- **توفر أوسع:** يطلب المستخدمون غير الأمريكيين بشكل متكرر أن يتم إطلاق Claude رسميًا في بلدانهم. تنشر منشورات من كندا وأوروبا والهند، إلخ، تسأل متى يمكنهم استخدام موقع Claude دون VPN أو متى سيتم فتح Claude API بشكل أوسع. كانت Anthropic حذرة، لكن الطلب عالمي – من المحتمل أن يكون تحسينًا في نظر الكثيرين هو ببساطة "السماح للمزيد منا باستخدامه." أدى التوسع التدريجي للشركة في الوصول إلى معالجة هذا جزئيًا.

### الاحتياجات غير الملباة أو الفئات غير المخدومة

- **قاعدة المستخدمين الدولية:** كما ذُكر، لفترة طويلة كانت قاعدة مستخدمي Claude الأساسية محدودة بالجغرافيا. ترك هذا العديد من المستخدمين *المحتملين* غير مخدومين. على سبيل المثال، مطور في ألمانيا مهتم بسياق Claude 100k لم يكن لديه طريقة رسمية لاستخدامه. بينما توجد حلول بديلة (منصات الطرف الثالث، أو VPN + التحقق من الهاتف في بلد مدعوم)، كانت هذه الحواجز تعني أن المستخدمين الدوليين العاديين كانوا فعليًا مغلقين. على النقيض من ذلك، يتوفر ChatGPT في معظم البلدان. لذا، فإن المتحدثين باللغة الإنجليزية غير الأمريكيين وخاصة غير المتحدثين باللغة الإنجليزية كانوا غير مخدومين بسبب طرح Claude المحدود. قد لا يزالون يعتمدون على ChatGPT أو النماذج المحلية ببساطة بسبب قضايا الوصول.

- **المستخدمون الذين يحتاجون إلى تنسيق مخرجات صارم:** كما ذكر، يأخذ Claude أحيانًا حريات في الاستجابات. المستخدمون الذين يحتاجون إلى مخرجات منظمة للغاية (مثل JSON لتطبيق، أو إجابة تتبع تنسيقًا دقيقًا) قد يجدون Claude أقل موثوقية لذلك من ChatGPT. هؤلاء المستخدمون – غالبًا المطورون الذين يدمجون الذكاء الاصطناعي في نظام – هم شريحة يمكن أن تكون أفضل خدمة إذا سمح Claude بوضع "صارم" أو حسن التزامه بالتعليمات. قد يتجنبون Claude حاليًا لمثل هذه المهام، متمسكين بالنماذج المعروفة باتباع التنسيقات بشكل أكثر صرامة.

- **المستخدمون العاديون للأسئلة والأجوبة (مقابل المستخدمين الإبداعيين):** غالبًا ما يُشاد بـ Claude للمهام الإبداعية – فهو ينتج نثرًا متدفقًا يشبه الإنسان ومقالات مدروسة. ومع ذلك، لاحظ بعض المستخدمين على Reddit أنه للأسئلة والإجابات المباشرة أو الاستفسارات الواقعية، يقدم Claude أحيانًا إجابات مطولة حيث يكون الإيجاز كافيًا. المستخدم الذي قارن بين ChatGPT وClaude قال إن ChatGPT يميل إلى أن يكون موجزًا ونقطيًا، بينما يقدم Claude المزيد من السرد بشكل افتراضي. المستخدمون الذين يريدون إجابة واقعية سريعة (مثل "ما هي عاصمة X وعدد سكانها؟") قد يشعرون أن Claude غير مباشر بعض الشيء. هؤلاء المستخدمون يخدمهم بشكل أفضل شيء مثل بحث دقيق أو نموذج موجز. يمكن لـ Claude القيام بذلك إذا طُلب منه، ولكن قد لا يتطابق أسلوبه مع توقعات الأسئلة والأجوبة الموجزة، مما يعني أن هذه الشريحة قد تنزلق إلى أدوات أخرى (مثل Bing Chat أو Google).

- **المستخدمون الحساسون للأمان:** على العكس من ذلك، قد يعتبر بعض المستخدمين الذين *يتطلبون* التزامًا دقيقًا جدًا بالأمان (على سبيل المثال، المعلمون الذين يستخدمون الذكاء الاصطناعي مع الطلاب، أو العملاء المؤسسيون الذين يريدون صفر مخاطر من المخرجات المارقة) أن توافق Claude ميزة، ولكن نظرًا لأن ChatGPT متوافق أيضًا إلى حد كبير ولديه المزيد من الميزات المؤسسية، قد لا يختار هؤلاء المستخدمون Claude بشكل خاص. إنها شريحة صغيرة، ولكن يمكن القول إن Claude لم يلتقطها بشكل مميز بعد. قد يكونون غير مخدومين في أنهم لا يملكون طريقة سهلة *لزيادة* ضمانات Claude أو رؤية "سلسلة التفكير" الخاصة به (التي تمتلكها Anthropic داخليًا عبر نهج الذكاء الاصطناعي الدستوري، ولكن المستخدمين النهائيين لا يتفاعلون مباشرة مع ذلك باستثناء ملاحظة نغمة Claude المهذبة عمومًا).

- **المتحدثون بغير الإنجليزية (جودة المخرجات):** تم تدريب Claude في المقام الأول على اللغة الإنجليزية (مثل معظم LLMs الكبيرة). اختبره بعض المستخدمين بلغات أخرى؛ يمكنه الرد في العديد منها، ولكن قد تختلف الجودة. إذا أراد، على سبيل المثال، مستخدم إجابة دقيقة جدًا باللغة الفرنسية أو الهندية، فمن الممكن أن تكون قدرات Claude ليست مضبوطة بدقة هناك مثل ChatGPT (أظهر GPT-4 أداءً متعدد اللغات قويًا، غالبًا أعلى من النماذج الأخرى في معايير معينة). قد يجد المستخدمون الذين يتحدثون بشكل أساسي بلغات غير الإنجليزية أن طلاقة Claude أو دقته أضعف قليلاً. هذه الشريحة غير مخدومة إلى حد ما ببساطة لأن Anthropic لم تسلط الضوء على التدريب متعدد اللغات كأولوية علنية.

### الاختلافات في التصور حسب نوع المستخدم

- **المطورون/المستخدمون التقنيون:** أشاد المطورون على Reddit بشكل متزايد بـ Claude، خاصة Claude 2 / Claude 3.5، لمهام البرمجة. كان التحول في التصور في أواخر 2024 ملحوظًا: بدأ العديد من المطورين في تفضيل Claude على ChatGPT للمساعدة في البرمجة. يستشهدون بأداء *"مذهل في البرمجة"* والقدرة على التعامل مع قواعد الأكواد الكبيرة في وقت واحد. على سبيل المثال، كتب أحد المستخدمين *"Claude Sonnet 3.5 أفضل للعمل مع الكود (تحليل، توليد) [من ChatGPT]."* يقدر المطورون أن Claude يمكنه أخذ جزء كبير من كود المشروع أو السجلات وإنتاج تحليلات أو تحسينات متماسكة، بفضل سياقه الضخم. ومع ذلك، يلاحظون أيضًا غرائبه – مثل إدخال المزيد من الحشو الحواري أحيانًا أو عدم اتباع المواصفات حرفيًا. على التوازن، يحتفظ العديد من المطورين بكل من ChatGPT وClaude في متناول اليد: واحد للمنطق الصارم خطوة بخطوة (ChatGPT) وواحد للسياق الواسع والفهم المتعاطف (Claude). من الدال أن أحد المعلقين قال *"إذا كان علي اختيار واحد فسأختار Claude"* بعد مقارنة الاثنين يوميًا. يشير هذا إلى تصور إيجابي جدًا بين المستخدمين المتقدمين، خاصة لحالات الاستخدام مثل العصف الذهني، مراجعة الكود، أو الاقتراحات المعمارية. الشكوى الشائعة الوحيدة من المطورين هي الوصول إلى حدود استخدام Claude عندما يحاولون دفعه بقوة (مثل تغذية مطلب 50K-token لتحليل مستودع كامل). باختصار، يرى المطورون Claude كأداة قوية للغاية – في بعض الحالات متفوقة على ChatGPT – مقيدة فقط بالتوافر وبعض عدم التنبؤ في التنسيق.

- **المستخدمون العاديون/غير التقنيين:** غالبًا ما يعلق المستخدمون العاديون الذين جربوا Claude على مدى *ودودته وبلاغته*. يميل أسلوب Claude إلى أن يكون حواريًا، مهذبًا، ومفصلًا. لاحظ مستخدم جديد يقارنه بـ ChatGPT أن *"Claude أكثر تعاطفًا، ويتبع نبرة حوارية... ChatGPT يميل إلى النقاط كثيرًا"*. تجعل هذه الدفء الشبيه بالإنسان Claude جذابًا للأشخاص الذين يستخدمونه للكتابة الإبداعية، النصائح، أو مجرد الدردشة للحصول على المعلومات. حتى أن البعض يجسد Claude على أنه يمتلك "شخصية" تتسم بالرحمة. كما يحب المستخدمون العاديون أن النسخة المجانية من Claude سمحت بالوصول إلى ما يعادل ذكاء GPT-4 دون اشتراك (على الأقل حتى حدود المعدل). على الجانب الآخر، يصطدم المستخدمون العاديون برفضات Claude في مواضيع معينة وقد لا يفهمون السبب (حيث سيصيغ Claude ذلك باعتذار ولكن بحزم). إذا طلب مستخدم عادي شيئًا حدوديًا وحصل على رفض من Claude، فقد يرونه أقل قدرة أو مقيدًا جدًا، دون إدراك أنه موقف سياسي. جانب آخر هو أن Claude يفتقر إلى الاعتراف بالاسم – قد لا يعرف العديد من المستخدمين العاديين حتى تجربته ما لم يكونوا متصلين بمجتمعات الذكاء الاصطناعي. أولئك الذين يجربون عمومًا يعلقون على أنه يشعر *"مثل التحدث إلى إنسان"* بطريقة جيدة. يميلون إلى أن يكونوا راضين جدًا عن قدرة Claude على التعامل مع الأسئلة المفتوحة أو الشخصية. لذا، فإن تصور المستخدم العادي إيجابي إلى حد كبير فيما يتعلق بـ *جودة مخرجات Claude ونبرته*، مع بعض الارتباك أو الإحباط حول توفره (الحاجة إلى استخدامه على تطبيق معين أو منطقة) ولحظات "لا يمكنني فعل ذلك" العرضية.

- **المستخدمون التجاريون/المحترفون:** من الصعب بعض الشيء قياس تصورات الأعمال عن Claude من Reddit العام (حيث ينشر عدد أقل من المستخدمين المؤسسيين بالتفصيل)، ولكن تظهر بعض الاتجاهات. أولاً، وضعت Anthropic Claude كأكثر *تركيزًا على الخصوصية* ومستعدة لتوقيع اتفاقيات مؤسسية – وهذا يجذب الشركات التي تقلق بشأن البيانات مع OpenAI. في الواقع، تذكر بعض مناقشات Reddit Claude في سياق أدوات مثل Slack أو Notion، حيث يتم دمجه كمساعد. قد لا يدرك المحترفون الذين استخدموا تلك التكاملات حتى أن Claude هو المحرك، ولكن عندما يفعلون، يقارنونه بشكل إيجابي من حيث أسلوب الكتابة والقدرة على هضم الوثائق الكبيرة للشركات. على سبيل المثال، قد تغذي فريق تقريرًا ربع سنويًا طويلًا إلى Claude وتحصل على ملخص لائق – شيء سيكافح ChatGPT بسياقه الأصغر. ومع ذلك، يلاحظ المستخدمون التجاريون أيضًا نقص بعض ميزات النظام البيئي؛ على سبيل المثال، تقدم OpenAI تحكمًا في رسائل النظام، واستدعاء الوظائف، إلخ، في API الخاص بهم، والذي تدعمه Anthropic بشكل أكثر محدودية. علق مطور يعمل على حل تجاري أن *Claude أكثر قابلية للتوجيه في المحادثات، بينما يميل ChatGPT إلى أن يكون أكثر صرامة... [لكن] ChatGPT لديه وصول إلى الويب الذي يمكن أن يكون مفيدًا جدًا*. يشير هذا إلى أنه بالنسبة لمهام البحث أو استرجاع البيانات التي قد يحتاجها مستخدم الأعمال (مثل الذكاء التنافسي)، يمكن لـ ChatGPT جلب المعلومات مباشرة، بينما يتطلب Claude خطوة منفصلة. بشكل عام، يبدو أن المستخدمين التجاريين يرون Claude كذكاء اصطناعي كفء جدًا – في بعض الحالات *أفضل* للمهام التحليلية الداخلية – ولكن ربما ليس غنيًا بالميزات بعد للتكامل. التكلفة عامل آخر: تسعير Claude API وشروطه ليست علنية مثل OpenAI، وذكرت بعض الشركات الناشئة على Reddit عدم اليقين بشأن تسعير Claude أو استقراره. باختصار، يحترم المحترفون قدرات Claude (خاصة موثوقيته في اتباع التعليمات عالية المستوى وتلخيص المدخلات الكبيرة)، لكنهم يراقبون كيف يتطور من حيث التكامل والدعم والتوافر العالمي قبل الالتزام الكامل به على حساب ChatGPT الأكثر شهرة.

---

## Google Gemini (Bard)

### نقاط الألم والقيود الشائعة

- **استجابات غير دقيقة أو "غبية":** ظهر سيل من التعليقات على Reddit عندما أطلقت Google ترقية Bard المدعومة من Gemini، كان الكثير منها سلبيًا. اشتكى المستخدمون من أن Gemini **أداءه ضعيف في الأسئلة والأجوبة الأساسية** مقارنة بـ ChatGPT. تقييم صريح بعنوان "رأي صادق 100% حول Google Gemini" قال: *"إنه روبوت محادثة LLM مكسور وغير دقيق"*. سأل مستخدم آخر محبط: *"كيف لا يزال Gemini سيئًا جدًا؟ عدد المرات التي أطلب فيها من Gemini شيئًا ويعطيني إما إجابات غير صحيحة أو غير مكتملة أمر سخيف"*. قارنوه جنبًا إلى جنب مع ChatGPT-4 ووجدوا أن ChatGPT أعطى *"إجابة مثالية وصحيحة وفعالة في مرة واحدة،"* بينما كان Gemini يثرثر ويتطلب مطالبات متعددة للوصول إلى إجابة نصف مرضية. في الأساس، شعر المستخدمون الأوائل أن Gemini كثيرًا ما **يهلو أو يفوت النقطة** من الأسئلة، مما يتطلب جهدًا مفرطًا في المطالبة لاستخراج المعلومات الصحيحة. كان هذا التناقض في الجودة خيبة أمل كبيرة بالنظر إلى الضجة حول Gemini.

- **الإسهاب المفرط والحشو:** لاحظ العديد من المستخدمين أن Gemini (في شكل Bard الجديد) يميل إلى إنتاج إجابات مطولة لا تصل إلى النقطة. كما وصفها شخص واحد، *"كان يثرثر... 3 فقرات من القمامة الذكاء الاصطناعي... حتى بعد ذلك، ذكر الإجابة في النهاية مدفونة في فقرات من القمامة"*. هذا تناقض صارخ مع ChatGPT، الذي غالبًا ما يقدم إجابات أكثر إيجازًا أو نقاطًا عند الاقتضاء. يصبح الإسهاب نقطة ألم عندما يضطر المستخدمون إلى غربلة الكثير من النص للحصول على حقيقة بسيطة. تكهن البعض أن Google قد ضبطته ليكون حواريًا أو "مفيدًا"، لكنه تجاوز الحد إلى *الكثير* من الشرح دون مضمون.

- **التكامل السيئ مع خدمات Google الخاصة:** من المفترض أن يكون أحد نقاط البيع لمساعد الذكاء الاصطناعي من Google هو التكامل مع نظام Google البيئي (Gmail وDocs وDrive، إلخ). ومع ذلك، كانت تجارب المستخدمين المبكرة مخيبة للآمال للغاية في هذا الصدد. تنفيس مستخدم: *"لا تجعلني أبدأ في عدم قدرته الكاملة تقريبًا على التكامل مع منتجات Google الخاصة التي من المفترض أن تكون 'ميزة' (التي يبدو أنه لا يعرف أنها لديه)."*. على سبيل المثال، كان الناس يحاولون طلب من Gemini (عبر Bard) تلخيص مستند Google أو صياغة بريد إلكتروني بناءً على بعض المعلومات – ميزات أعلنت عنها Google – وكان الروبوت يرد بأنه **لا يمكنه الوصول إلى تلك البيانات**. كتب مستخدم على r/GooglePixel: *"في كل مرة أحاول فيها استخدام Gemini مع مستندات Google أو Drive الخاصة بي، يخبرني أنه لا يمكنه فعل أي شيء بها. ما الفائدة من وجود هذه الميزات التكاملية؟"*. يظهر هذا فجوة كبيرة بين القدرات الموعودة والأداء الفعلي، مما يترك المستخدمين يشعرون بأن "مساعد الذكاء الاصطناعي" لا يساعد كثيرًا داخل نظام Google البيئي.

- **الرفض والارتباك في القدرات:** واجه المستخدمون أيضًا رفضات غريبة أو تناقضات من Gemini. لاحظ نفس مستخدم Reddit أن Gemini *"يرفض القيام بأشياء بدون سبب، ينسى أنه يمكنه القيام بأشياء أخرى... في اليوم الآخر أخبرني أنه ليس لديه وصول إلى الإنترنت/البيانات الحية. ماذا."*. يشير هذا إلى أن Gemini سي **يرفض أحيانًا المهام التي يجب أن يكون قادرًا على القيام بها** (مثل استرجاع المعلومات الحية، التي يتصل بها Bard) أو يقدم تصريحات غير صحيحة حول قدراته الخاصة. مثل هذه التجارب أعطت انطباعًا عن ذكاء اصطناعي ليس فقط أقل ذكاءً، ولكن أيضًا **أقل موثوقية أو وعيًا ذاتيًا**. تعليق مستخدم آخر الملون: *"Gemini هو قمامة مطلقة. هل سبق لك أن مررت بلحظة حيث تريد فقط رفع يديك والقول، 'ماذا كانوا يفكرون؟'"* يجسد الإحباط. في الأساس، جعلت مشكلات تكامل المنتج والاتساق في Gemini تشعر بأنها *غير مكتملة* للعديد من المتبنين الأوائل.

- **قدرات برمجة غير ملحوظة:** بينما لم يتم مناقشتها على نطاق واسع مثل الأسئلة والأجوبة العامة، اختبر العديد من المستخدمين Gemini (Bard) في مهام البرمجة ووجدوه دون المستوى. في منتديات الذكاء الاصطناعي، كانت قدرات برمجة Gemini عادةً تُقيم أدنى من GPT-4 وحتى أدنى من Claude. على سبيل المثال، صرح أحد المستخدمين بوضوح أن *"Claude 3.5 Sonnet أفضل بوضوح في البرمجة من ChatGPT 4o... Gemini هو قمامة مطلقة [في هذا السياق]"*. كان الإجماع هو أن Gemini يمكنه كتابة كود بسيط أو شرح الخوارزميات الأساسية، لكنه غالبًا ما يتعثر في المشكلات الأكثر تعقيدًا أو ينتج كودًا يحتوي على أخطاء. كما أن افتقاره إلى مجموعة أدوات مطور واسعة (على سبيل المثال، ليس لديه ما يعادل مفسر الكود أو استدعاء الوظائف القوي) يعني أيضًا أنه لم يكن الخيار الأول للمبرمجين. لذا، بينما لا يهتم كل مستخدم عادي بالكود، فإن هذا قيد لتلك الشريحة.

- **قيود الجهاز المحمول:** تم طرح Gemini كجزء من مساعد Google على هواتف Pixel (بعلامة "مساعد مع Bard"). لاحظ بعض مستخدمي Pixel أن استخدامه كبديل للمساعد الصوتي كان به مشكلات. أحيانًا لم يلتقط مطالبات الصوت بدقة أو استغرق وقتًا طويلاً للرد مقارنة بالمساعد القديم من Google. كانت هناك أيضًا تعليقات حول الحاجة إلى الاشتراك وفقدان بعض ميزات المساعد الكلاسيكية. خلق هذا تصورًا أن *تكامل Gemini على الأجهزة لم يكن جاهزًا بالكامل*، مما ترك المستخدمين الأقوياء لنظام Google البيئي يشعرون بأنهم يجب أن يختاروا بين مساعد ذكي وواحد وظيفي.

### الميزات أو التحسينات المطلوبة بشكل متكرر

- **تحسين الدقة والتفكير بشكل كبير:** التحسين الأول الذي يريده المستخدمون لـ Gemini هو ببساطة **أن يكون أكثر ذكاءً وموثوقية**. توضح تعليقات Reddit أن Google تحتاج إلى سد الفجوة في جودة الإجابة. يتوقع المستخدمون أن يستفيد Gemini من الوصول الواسع للمعلومات في Google لتقديم *إجابات واقعية ومباشرة*، وليس متعرجة أو غير صحيحة. لذا فإن الطلبات (غالبًا ما تكون مصاغة بسخرية) تتلخص في: *اجعلها جيدة مثل أو أفضل من GPT-4 في المعرفة العامة والتفكير.* يتضمن ذلك تحسين التعامل مع الأسئلة المتابعة والمطالبات المعقدة. في الأساس، "إصلاح الدماغ" لـ Gemini – الاستفادة من تلك المزايا التدريبية متعددة الوسائط المزعومة حتى يتوقف عن فقدان التفاصيل الواضحة. من المحتمل أن Google سمعت هذا بصوت عالٍ وواضح: العديد من المنشورات تقارن إجابات محددة حيث تفوق ChatGPT وفشل Gemini، مما يخدم كتقارير غير رسمية للأخطاء للتحسين.

- **تحسين التكامل والوعي بالسياق:** يريد المستخدمون أن يحقق Gemini وعد مساعد النظام البيئي السلس لـ Google. يعني هذا أنه يجب أن **يتفاعل بشكل صحيح مع Gmail وCalendar وDocs وDrive، إلخ.** إذا طلب مستخدم "تلخيص المستند الذي فتحته" أو "صياغة رد على آخر بريد إلكتروني من رئيسي"، يجب أن يقوم الذكاء الاصطناعي بذلك – ويفعله بأمان. حاليًا، الطلب هو أن *تُمكن Google تلك الميزات وتجعل Gemini يتعرف فعليًا عندما يكون مثل هذا المهمة ممكنًا*. تم الإعلان عن أن Bard يمكنه الاتصال بمحتوى المستخدم (بإذن)، لذا يطالب المستخدمون فعليًا Google "بتشغيل" أو إصلاح هذا التكامل. هذه ميزة رئيسية للمستخدمين التجاريين خاصة. بالإضافة إلى ذلك، على جبهة التصفح عبر الويب: يمكن لـ Bard (Gemini) البحث في الويب، ولكن بعض المستخدمين يريدون منه أن يقتبس المصادر بشكل أوضح أو يكون أكثر دقة في دمج الأخبار العاجلة. لذا فإن تحسين الطبيعة *المتصلة* لـ Gemini هو طلب متكرر.

- **عناصر تحكم في الإيجاز:** بالنظر إلى شكاوى الإسهاب، يقترح بعض المستخدمين ميزة لتبديل أسلوب الاستجابة. على سبيل المثال، وضع *"موجز"* حيث يقدم Gemini إجابة قصيرة ومباشرة افتراضيًا، ما لم يُطلب منه التوسع. على العكس من ذلك، ربما وضع "مفصل" لأولئك الذين يريدون إجابات شاملة للغاية. يسمح ChatGPT ضمنيًا ببعض هذا من خلال مطلب المستخدم ("اجعلها موجزة")؛ مع Gemini، شعر المستخدمون أنه حتى عندما لم يطلبوا التفاصيل، كان يبالغ في الشرح. لذا فإن إعدادًا مدمجًا أو مجرد ضبط أفضل لإنتاج إجابات موجزة عند الاقتضاء سيكون تحسينًا مرحبًا به. في الأساس، ضبط قرص الإسهاب.

- **تكافؤ الميزات مع ChatGPT (البرمجة، المكونات الإضافية، إلخ):** يقارن المستخدمون الأقوياء على Reddit الميزات صراحةً. يطلبون أن تقدم Google’s Gemini/Bard أشياء مثل *صندوق رمل لتنفيذ الكود* (مشابه لمفسر الكود في ChatGPT)، القدرة على تحميل الصور/ملفات PDF للتحليل (نظرًا لأن Gemini متعدد الوسائط، يريد المستخدمون فعليًا تغذيته بالصور المخصصة، وليس فقط أن يصف الصور المقدمة). ميزة أخرى مذكورة بشكل متكرر هي ذاكرة **أفضل داخل المحادثة** – بينما لدى Bard بعض الذاكرة عن التفاعلات السابقة، يريد المستخدمون أن يكون جيدًا مثل ChatGPT في الإشارة إلى السياق السابق، أو حتى أن يكون لديه تخزين محادثة دائم مثل تاريخ دردشة ChatGPT الذي يمكنك التمرير من خلاله وإعادة زيارته. في الأساس، يُطلب من Google اللحاق بجميع ميزات جودة الحياة التي يتمتع بها مستخدمو ChatGPT Plus: تاريخ الدردشة، نظام المكونات الإضافية (أو على الأقل تكاملات قوية مع الطرف الثالث)، مساعدة البرمجة، إلخ.

- **تحسينات التطبيق المحمول والصوت:** طلب العديد من المستخدمين العاديين **تطبيقًا محمولًا مخصصًا لـ Bard/Gemini** (مشابه لتطبيق ChatGPT المحمول). الاعتماد على واجهة الويب أو فقط مساعد Pixel هو أمر محدود. يمكن أن يحسن تطبيق رسمي عبر iOS/Android مع إدخال الصوت، واستجابات التحدث (لإحساس مساعد حقيقي)، وتكامل محكم تجربة المستخدم بشكل كبير. إلى جانب ذلك، يريد مالكو Pixel أن يصبح المساعد مع Bard أسرع وأكثر وظيفية – في الأساس، يريدون أفضل ما في مساعد Google القديم (إجراءات سريعة ودقيقة) مجتمعة مع ذكاء Gemini. على سبيل المثال، أشياء مثل الاستمرار في السماح بأوامر الصوت الذكية "Hey Google" وليس فقط الردود الحوارية. يمكن أن تحسن Google وضع الصوت في Gemini ليحل محل المساعد القديم حقًا دون تراجع الميزات.

- **الشفافية والتحكم:** طلب بعض المستخدمين مزيدًا من البصيرة في مصادر Bard أو طريقة لضبط أسلوبه. على سبيل المثال، إظهار النتيجة التي يسحب Bard المعلومات منها (للتحقق من الدقة) – شيء يفعله Bing Chat عن طريق الاستشهاد بالروابط. أيضًا، نظرًا لأن Bard ينتج أحيانًا معلومات خاطئة، يريد المستخدمون أن يكونوا قادرين على الإبلاغ عنها أو تصحيحها، ومن الناحية المثالية يجب أن يتعلم Bard من تلك الملاحظات بمرور الوقت. وجود آلية ملاحظات سهلة ("إبهام لأسفل – هذا غير صحيح لأن...") يؤدي إلى تحسين النموذج بسرعة سيعزز الثقة بأن Google تستمع. في الأساس، ميزات لجعل الذكاء الاصطناعي مساعدًا تعاونيًا أكثر من كونه صندوقًا أسود.

### الاحتياجات غير الملباة أو الفئات غير المخدومة

- **المستخدمون الذين يبحثون عن مساعد شخصي موثوق:** من المفارقات، أن المجموعة التي استهدفتها Google – الأشخاص الذين يريدون مساعدًا شخصيًا قويًا – يشعرون بأنهم غير مخدومين من قبل Gemini في شكله الحالي. توقع المتبنون الأوائل الذين قاموا بتشغيل المساعد الجديد المستند إلى Bard ترقية، لكن الكثيرين شعروا أنه كان تراجعًا من الناحية العملية. على سبيل المثال، إذا أراد شخص ما مساعدًا صوتيًا للرد بدقة على الأسئلة التافهة، وتعيين التذكيرات، والتحكم في الأجهزة، ودمج المعلومات من حساباتهم، كافح Gemini. ترك هذا الفئة من المحترفين المشغولين أو عشاق الأدوات (الذين يعتمدون على المساعدين للإنتاجية) يشعرون بأن احتياجاتهم لم تُلبى. علق أحد المستخدمين أنهم سيفكرون في الدفع مقابل "المساعد مع Bard" من Pixel *"إذا تجاوز [ذلك] مساعد Google"*, مما يعني أنه لم يفعل بعد. لذا فإن تلك الفئة لا تزال تنتظر مساعدًا ذكيًا ومفيدًا حقًا – سيقفزون عليه إذا تحسن Gemini.

- **المتحدثون بغير الإنجليزية / التوطين:** عادةً ما تتمتع منتجات Google بتوطين ممتاز، ولكن من غير الواضح ما إذا كان Bard/Gemini قويًا بنفس القدر في جميع اللغات عند الإطلاق. أبلغ بعض المستخدمين الدوليين أن إجابات Bard بلغتهم الأم كانت أقل طلاقة أو فائدة، مما دفعهم للعودة إلى المنافسين المحليين. إذا كانت بيانات تدريب Gemini أو تحسينه تفضل الإنجليزية، فإن المستخدمين غير الناطقين بالإنجليزية غير مخدومين. قد يفضلون ChatGPT أو النماذج المحلية التي قامت بتحسين القدرات متعددة اللغات بشكل صريح. هذه مساحة يمكن أن تتفوق فيها Google تقليديًا (نظرًا لتقنيتها في الترجمة)، ولكن ملاحظات المستخدمين على ذلك نادرة – مما يشير على الأرجح إلى أن Gemini لم يدهش تلك المجتمعات بعد.

- **العملاء المؤسسيون (حتى الآن):** لم تتبنى المنظمات الكبيرة Bard/Gemini على نطاق واسع بناءً على الدردشة العامة، غالبًا بسبب فجوات الثقة والقدرات. تحتاج المؤسسات إلى الاتساق، والاستشهادات، والتكامل مع سير العمل الخاص بهم (يتم دمج Office 365 بعمق مع تقنية OpenAI عبر MS Copilot، على سبيل المثال). لا يزال المكافئ من Google (Duet AI مع Gemini) يتطور. حتى يثبت Gemini/Bard أنه يمكنه صياغة رسائل البريد الإلكتروني بشكل موثوق، وإنشاء العروض التقديمية، أو تحليل البيانات في Google Sheets على مستوى يضاهي أو يتفوق على GPT-4، سيشعر المستخدمون المؤسسيون أن حل Google لا يلبي احتياجاتهم بالكامل. بعض المنشورات على r/Bard من المحترفين تدور حول "جربت Bard للمهام العملية، لم يكن جيدًا مثل ChatGPT، لذا سننتظر ونرى." يشير ذلك إلى أن المستخدمين المؤسسيين هم شريحة غير مخدومة حتى الآن – يريدون ذكاءً اصطناعيًا يناسب Google Workspace ويعزز الإنتاجية بالفعل دون الحاجة إلى التحقق المستمر من المخرجات.

- **المستخدمون في نظام Google البيئي الذين يفضلون الحلول الشاملة:** هناك شريحة من المستخدمين الذين يستخدمون Google لكل شيء (البحث، البريد الإلكتروني، المستندات) و*سيستخدمون بسعادة ذكاءً اصطناعيًا من Google لجميع احتياجاتهم في الدردشة – إذا كان جيدًا. حاليًا، يتم تقديم هؤلاء المستخدمين بشكل غير كامل لأنهم ينتهي بهم الأمر باستخدام ChatGPT لأشياء معينة وBard لأخرى. قد يطرحون أسئلة واقعية على ChatGPT لأنهم يثقون في جودة إجاباته أكثر، ولكن يستخدمون Bard لمحاولات التكامل أو التصفح. تلك التجربة المنقسمة ليست مثالية. يريد هؤلاء المستخدمون حقًا البقاء في تطبيق/مساعد واحد. إذا تحسن Gemini، فسوف يتجمعون حوله، ولكن حتى ذلك الحين، لم يتم تلبية حالتهم الاستخدامية "مساعد واحد ليحكمهم جميعًا".

- **المطورون/علماء البيانات على Google Cloud:** أصدرت Google نماذج Gemini عبر منصة Vertex AI للمطورين. ومع ذلك، أشارت التقارير والمعايير المبكرة إلى أن Gemini (خاصة النموذج المتاح "Gemini Pro") لم يكن يتفوق على GPT-4. المطورون الذين يفضلون Google Cloud لخدمات الذكاء الاصطناعي هم بالتالي غير مخدومين قليلاً من حيث جودة النموذج – إما أن يقبلوا نموذجًا أقل قليلاً أو يدمجوا API الخاص بـ OpenAI بشكل منفصل. هذه الشريحة من المطورين المؤسسيين جائعة لنموذج Google قوي حتى يتمكنوا من الاحتفاظ بكل شيء في حزمة واحدة. حتى يتفوق أداء Gemini بوضوح في بعض المجالات أو يقدم التسعير سببًا مقنعًا، فإنه لا يخدم احتياجات هذه المجموعة بشكل كامل من حيث التنافسية.

### الاختلافات في التصور حسب نوع المستخدم

- **المطورون/عشاق التكنولوجيا:** اقترب المستخدمون التقنيون من Gemini بتوقعات عالية (إنها Google، بعد كل شيء). تدهورت تصوراتهم بسرعة بعد الاختبار العملي. أجرى العديد من المطورين على Reddit معايير أو أسئلتهم المفضلة الصعبة عبر Gemini ووجدوا أنه يتخلف. صرح أحد المبرمجين بصراحة، *"Gemini هو قمامة مطلقة مثلما كان Llama 3.0"*، مما يشير إلى أنهم يصنفونه حتى أقل من بعض النماذج المفتوحة. المطورون حساسون بشكل خاص للأخطاء المنطقية والإسهاب. لذا عندما قدم Gemini إجابات مطولة ولكن غير صحيحة، فقد المصداقية بسرعة. من ناحية أخرى، يدرك المطورون إمكانات Google؛ يحتفظ البعض بالأمل في أن *"مع المزيد من الضبط الدقيق، سيتحسن Gemini"* ويعيدون اختباره دوريًا بعد التحديثات. في الوقت الحالي، ومع ذلك، يرى معظم المطورين أنه **أقل من GPT-4** في جميع المهام الجادة تقريبًا (البرمجة، حل المشكلات المعقدة). يقدرون بعض الأشياء: على سبيل المثال، لدى Gemini وصول إلى المعلومات في الوقت الفعلي (عبر بحث Google) دون الحاجة إلى مكون إضافي، وهو مفيد للاستفسارات المحدثة. قد يستخدم المطور Bard لشيء مثل "البحث وتلخيص أحدث الأوراق حول X"، حيث يمكنه اقتباس بيانات الويب. ولكن بالنسبة للتفكير الذاتي، يميلون نحو النماذج الأخرى. باختصار، يرى عشاق التكنولوجيا Gemini كمشروع واعد قيد التقدم الذي *حاليًا* يشعر بأنه جيل متأخر. لم يكسب ثقتهم الكاملة، وغالبًا ما ينشرون مقارنات جنبًا إلى جنب تسلط الضوء على أخطائه لتحفيز Google على تحسينه.

- **المستخدمون العاديون/اليوميون:** كان لدى المستخدمين العاديين، بما في ذلك أولئك الذين حصلوا على الوصول إلى Bard الجديد على هواتفهم أو عبر الويب، مشاعر مختلطة. اقترب العديد من المستخدمين العاديين في البداية من Bard (Gemini) لأنه مجاني وسهل الوصول إليه بحساب Google، على عكس GPT-4 الذي كان محجوبًا. يبلغ بعض المستخدمين العاديين عن تجارب لائقة للاستخدامات البسيطة: على سبيل المثال، قدم أحد مستخدمي Reddit في r/Bard مراجعة إيجابية مشيرًا إلى أن Gemini ساعدهم في أشياء مثل مراجعة الوثائق القانونية، وكتابة النصوص، وحتى حالة استخدام ممتعة لتحديد أحجام الملابس من صورة. قالوا *"كان Gemini مصدرًا قيمًا للإجابة على أسئلتي... معلومات محدثة... لقد أصبحت معتادًا جدًا على الإصدار المدفوع لدرجة أنني لا أستطيع تذكر كيف يعمل الإصدار المجاني."* – مما يشير إلى أن *بعض* المستخدمين العاديين الذين استثمروا الوقت (والمال) في Bard Advanced وجدوه مفيدًا في الحياة اليومية. يميل هؤلاء المستخدمون إلى استخدامه للمساعدة العملية واليومية وقد لا يدفعون النموذج إلى حدوده. ومع ذلك، كان العديد من المستخدمين العاديين الآخرين (خاصة أولئك الذين جربوا أيضًا ChatGPT) محبطين. وجد الأشخاص العاديون الذين يطلبون أشياء مثل نصائح السفر، أو الأسئلة التافهة، أو المساعدة في مهمة أن إجابات Bard أقل وضوحًا أو فائدة. التصور هنا منقسم: **المستخدمون المخلصون لعلامة Google التجارية** مقابل **أولئك الذين أفسدهم ChatGPT بالفعل**. المجموعة الأولى، إذا لم يستخدموا ChatGPT كثيرًا، يجدون أحيانًا Bard/Gemini "جيدًا جدًا" لاحتياجاتهم ويقدرون أنه متكامل مع البحث ومجاني. المجموعة الثانية تقارن دائمًا تقريبًا وتجد Gemini غير كافٍ. قد يقولون، *"لماذا أستخدم Bard عندما يكون ChatGPT أفضل بنسبة 90% من الوقت؟"*. لذا يعتمد تصور المستخدم العادي حقًا على إطارهم المرجعي السابق. قد يقيم أولئك الجدد على مساعدي الذكاء الاصطناعي Gemini كجدة مفيدة؛ أولئك الذين لديهم خبرة مع المنافسة يرونه كخيبة أمل *"لا يزال سيئًا جدًا"* ويحتاج إلى التحسين.

- **المستخدمون التجاريون/المحترفون:** جرب العديد من المحترفين Bard عندما أطلق مع تكامل Google Workspace (Duet AI). التصور بين هذه المجموعة هو الشك الحذر. من ناحية، يثقون في وعود Google المؤسسية بشأن خصوصية البيانات والتكامل (على سبيل المثال، تحرير المستندات عبر الذكاء الاصطناعي، تلخيص الاجتماعات من دعوات التقويم، إلخ). من ناحية أخرى، أظهرت الاختبارات المبكرة غالبًا أن Gemini يرتكب أخطاء واقعية أو يقدم مخرجات عامة، وهو ليس ملهمًا للثقة للاستخدام التجاري. على سبيل المثال، قد يطلب محترف من Bard صياغة تقرير للعميل – إذا أدخل Bard بيانات غير صحيحة أو رؤى ضعيفة، فقد يكون أكثر إزعاجًا من المساعدة. لذلك، يميل المستخدمون المحترفون إلى *تجربة* Bard في المهام غير الحرجة ولكن لا يزالون يعتمدون على GPT-4 أو Claude للمخرجات المهمة. هناك أيضًا تصور أن Google كانت تلعب اللحاق بالركب: رأى الكثيرون Bard على أنه "غير جاهز للعرض" وقرروا الانتظار. يوجد بعض التصور الإيجابي في مجالات مثل **استفسارات البيانات في الوقت الفعلي** – على سبيل المثال، لاحظ محلل مالي على Reddit أن Bard يمكنه سحب معلومات السوق الأخيرة بفضل بحث Google، وهو ما لا يمكن لـ ChatGPT القيام به إلا إذا تم تمكين المكونات الإضافية. لذا في المجالات التي تكون فيها البيانات الحالية هي المفتاح، رأى عدد قليل من المحترفين ميزة. فارق آخر: الأشخاص في نظام Google البيئي (على سبيل المثال، الشركات التي تستخدم Google Workspace حصريًا) لديهم وجهة نظر أكثر إيجابية قليلاً ببساطة لأن Bard/Gemini هو الخيار الذي يناسب بيئتهم. إنهم يشجعون على تحسينه بدلاً من التحول إلى نظام بيئي مختلف تمامًا. باختصار، يرى المستخدمون التجاريون Gemini كـ *مفيد جدًا محتملًا* (نظرًا لبيانات Google وتكامل الأدوات)، ولكن اعتبارًا من أوائل 2025، لم يكسب الثقة الكاملة. يرونه كالمنافس الجديد الذي لم يصل بعد" – يستحق المراقبة، ولكن ليس بعد الذهاب إلى المهام الحرجة. سمعة Google تشتري له بعض الصبر من هذا الحشد، ولكن ليس إلى الأبد؛ إذا لم يتحسن Gemini بشكل ملحوظ، فقد لا يتبناه المحترفون على نطاق واسع، متمسكين بحلول أخرى.

---

## LLMs مفتوحة المصدر (مثل النماذج المستندة إلى LLaMA)

### نقاط الألم والقيود الشائعة

- **متطلبات الأجهزة والإعداد:** على عكس روبوتات المحادثة السحابية، تتطلب LLMs مفتوحة المصدر عادةً من المستخدمين تشغيلها على الأجهزة المحلية أو الخادم. يقدم هذا على الفور نقطة ألم: تحتاج العديد من النماذج (على سبيل المثال، نموذج LLaMA ذو 70 مليار معلمة) إلى وحدة معالجة رسومات قوية مع الكثير من VRAM لتعمل بسلاسة. كما وضعها أحد مستخدمي Reddit باختصار، *"LLMs المحلية على معظم الأجهزة الاستهلاكية لن تكون لديها الدقة اللازمة لأي تطوير معقد."* بالنسبة للشخص العادي الذي يمتلك فقط وحدة معالجة رسومات بسعة 8 جيجابايت أو 16 جيجابايت (أو مجرد وحدة معالجة مركزية)، يمكن أن يكون تشغيل نموذج عالي الجودة بطيئًا أو غير ممكن تمامًا. قد يلجأ المستخدمون إلى النماذج الأصغر التي تناسب، ولكن تلك غالبًا ما تنتج مخرجات ذات جودة أقل ("إجابات أكثر غباءً"). التعقيد في الإعداد هو قضية أخرى – تثبيت أوزان النموذج، إعداد البيئات مثل Oobabooga أو LangChain، إدارة مكتبات الترميز، إلخ، يمكن أن يكون مخيفًا لغير المطورين. حتى المستخدمين المهرة تقنيًا يصفونه بأنه متاعب لمواكبة إصدارات النموذج الجديدة، ومشكلات برامج تشغيل وحدة معالجة الرسومات، وهكذا. كان أحد المواضيع بعنوان "بجدية، كيف تستخدم LLMs المحلية فعليًا؟" حيث كان الناس يشاركون أن العديد من النماذج *"إما أنها تؤدي بشكل ضعيف أو لا تعمل بسلاسة على أجهزتي"*, ويطلبون نصائح عملية.

- **أداء أقل من النماذج المغلقة المتطورة:** حققت النماذج المفتوحة تقدمًا سريعًا، ولكن اعتبارًا من 2025 يلاحظ العديد من المستخدمين أنها لا تزال تتخلف عن النماذج الملكية الأعلى (GPT-4، Claude) في التفكير المعقد، البرمجة، والدقة الواقعية. مثال حي: قارن مستخدم على r/LocalLLaMA المخرجات بلغتهم الأم وقال *"كل نموذج آخر جربته يفشل... لا يقتربون حتى [من GPT-4]. ChatGPT 4 مذهل تمامًا في الكتابة"*. يتردد هذا الشعور على نطاق واسع: بينما يمكن أن تكون النماذج المفتوحة الأصغر (مثل نموذج 13B أو 7B المحسن) مثيرة للإعجاب لحجمها، فإنها تكافح مع المهام التي تتطلب فهمًا عميقًا أو منطقًا متعدد الخطوات. حتى النماذج المفتوحة الأكبر (65B، 70B) التي تقترب من مستوى GPT-3.5 لا تزال يمكن أن تتعثر في نوع المشاكل الصعبة التي يتعامل معها GPT-4. يلاحظ المستخدمون المزيد من الهلوسات والأخطاء في النماذج المفتوحة، خاصة في المعرفة المتخصصة أو عندما تنحرف المطالبات قليلاً عن توزيع التدريب. لذا، فإن الفجوة في القدرة الخام هي نقطة ألم – يجب أن يخفف المرء التوقعات عند استخدام النماذج المحلية، مما يمكن أن يكون محبطًا لأولئك المعتادين على موثوقية ChatGPT.

- **حدود السياق المحدودة:** تحتوي معظم LLMs مفتوحة المصدر تقليديًا على نوافذ سياق أصغر (2048 رمزًا، ربما 4k رمزًا) مقارنة بما تقدمه ChatGPT أو Claude. بعض التحسينات الجديدة والهياكل المعمارية تمدد هذا (على سبيل المثال، هناك إصدارات 8K أو 16K رمز من LLaMA-2، والبحث مثل MPT-7B كان لديه سياق 16K). ومع ذلك، فإن الاستخدام العملي للنماذج المفتوحة ذات السياق الطويل جدًا لا يزال في مراحله الأولى. هذا يعني أن مستخدمي النموذج المحلي يواجهون مشكلات ذاكرة مماثلة – ينسى النموذج الأجزاء السابقة من المحادثة أو النص، ما لم يقوموا بتنفيذ مخططات ذاكرة خارجية (مثل قواعد البيانات المتجهية للاسترجاع). في مناقشات Reddit، يذكر المستخدمون غالبًا الحاجة إلى تلخيص أو تقليص التاريخ يدويًا للبقاء ضمن الحدود، وهو أمر مرهق. هذا قيد ملحوظ خاصةً نظرًا لأن النماذج الملكية تدفع بطول السياق إلى أبعد من ذلك (مثل 100k لـ Claude).

- **نقص في ضبط التعليمات في بعض النماذج:** بينما يتم ضبط العديد من النماذج المفتوحة على التعليمات (Alpaca، LLaMA-2-Chat، إلخ)، ليست جميعها مدربة بشكل صارم على RLHF مثل ChatGPT. يمكن أن يؤدي هذا إلى أن تكون النماذج المحلية أحيانًا أقل استجابة للتعليمات أو مطالبات النظام. على سبيل المثال، سيستمر نموذج LLaMA الخام في النص ويتجاهل تنسيق مطلب المستخدم تمامًا – يجب استخدام نسخة مضبوطة على الدردشة. حتى في ذلك الحين، فإن جودة بيانات الضبط مهمة. لاحظ بعض مستخدمي Reddit أن بعض نماذج التعليم إما *رفضت بشكل مفرط* (لأنها تم ضبطها بأمان شديد، على سبيل المثال، بعض دردشة Facebook LLaMA-2 سترد برفضات سياسية مشابهة لـ ChatGPT) أو *أداؤها ضعيف* (لم تتبع الاستعلام بدقة). شكوى مستخدم على GitHub حول CodeLlama-70B-instruct قالت إنها *"مراقبة لدرجة أنها عديمة الفائدة"*، مما يظهر الإحباط من أن نموذج مفتوح اعتمد نفس الصرامة دون بديل لإيقافها. لذا، اعتمادًا على النموذج المختار، قد يواجه المستخدمون إما نموذجًا فضفاضًا جدًا (ويعطي استمرارًا غير ذي صلة) أو واحدًا صارمًا/محميًا جدًا. الحصول على سلوك ضبط التعليمات المتوازن جيدًا غالبًا ما يتطلب تجربة تحسينات متعددة.

- **التجزئة والتغيير السريع:** يتطور مشهد LLM مفتوح المصدر بسرعة كبيرة، مع ظهور نماذج وتقنيات جديدة (التكميم، تحسينات LoRA، إلخ) أسبوعيًا. بينما يكون ذلك مثيرًا، فإنه يمثل نقطة ألم للمستخدمين الذين لا يريدون تعديل إعداداتهم باستمرار. ما كان يعمل الشهر الماضي قد يكون قديمًا هذا الشهر. قارن أحد مستخدمي Reddit ذلك بشكل فكاهي بالغرب المتوحش، قائلاً إن المجتمع *"يجد طرقًا 'لتزييفها' حتى تشعر بأنها مشابهة [لـ GPT-4]"* ولكن غالبًا ما تكون هذه حلول مؤقتة. بالنسبة للمستخدم العادي، من المرهق حتى اختيار من بين عشرات أسماء النماذج (Vicuna، Alpaca، Mythomax، Mistral، إلخ)، كل منها مع إصدارات وفروع متعددة. بدون منصة موحدة واحدة، يعتمد المستخدمون على أدلة المجتمع – التي يمكن أن تكون مربكة – لتحديد النموذج الذي يناسب احتياجاتهم. هذه التجزئة في الأدوات وجودة النموذج هي نقطة ألم غير مباشرة: إنها ترفع حاجز الدخول وجهد الصيانة.

- **لا يوجد دعم رسمي أو ضمانات:** عندما يحدث خطأ ما مع LLM محلي (على سبيل المثال، ينتج النموذج محتوى مسيء أو يتعطل)، لا يوجد دعم عملاء للاتصال به. يعتمد المستخدمون على أنفسهم أو على مساعدة المجتمع. بالنسبة للهواة هذا جيد، ولكن للاستخدام المهني يمثل هذا نقص الدعم الرسمي حاجزًا. لاحظ بعض مستخدمي Reddit الذين يعملون في الشركات أنه بينما يرغبون في الخصوصية لنموذج مفتوح، فإنهم قلقون بشأن من يلجأون إليه إذا تعطل النموذج أو إذا كانوا بحاجة إلى تحديثات. في الأساس، استخدام المصدر المفتوح هو DIY – كل من القوة والضعف.

### الميزات أو التحسينات المطلوبة بشكل متكرر

- **كفاءة أفضل (التكميم والتحسين):** يركز المجتمع بشكل كبير (وبالتالي طلب شائع) على جعل النماذج الكبيرة تعمل على أجهزة أصغر. ينتظر المستخدمون بفارغ الصبر تقنيات تسمح لنموذج 70B بالعمل بسلاسة كنموذج 7B. هناك بالفعل تكميم 4 بت أو 8 بت، وغالبًا ما تناقش المواضيع طرقًا جديدة مثل AWQ أو محولات تشبه RNN. استشهد أحد المستخدمين بالبحث حيث يمكن أن يحافظ التكميم المحسن على الجودة عند دقة بت أقل. الرغبة هي أساسًا: *"دعني أشغل نموذجًا بمستوى GPT-4 على جهاز الكمبيوتر الخاص بي دون تأخير."* يتم الاحتفال بكل اختراق يقترب (مثل الهياكل المعمارية المحسنة للمحول أو إزاحة وحدة معالجة الرسومات إلى وحدة المعالجة المركزية). لذا، فإن الطلبات على أدوات أفضل (مثل الجيل التالي من llama.cpp أو المسرعات الأخرى) شائعة – أي شيء لتقليل حاجز الأجهزة.

- **نماذج أكبر وأفضل (سد فجوة الجودة):** يدفع المجتمع باستمرار للحصول على نماذج مفتوحة جديدة متطورة. يشعر المستخدمون بالحماس حول المشاريع مثل LLaMA 3 (إذا/عندما تصدر Meta واحدة) أو التعاونات التي يمكن أن تنتج نموذجًا مفتوح