---
title: "GitHub Copilot, Cursor, Windsurf의 에이전트 시스템 아키텍처"
tags:
  [AI, 프로그래밍 보조 도구, GitHub Copilot, Cursor, Windsurf, 에이전트 시스템]
keywords:
  [
    AI 아키텍처,
    GitHub Copilot,
    Cursor,
    Windsurf,
    프로그래밍 보조 도구,
    에이전트 시스템,
    작업 분해,
    모델 호출,
    컨텍스트 관리,
  ]
authors: [lark]
description: GitHub Copilot, Cursor, Windsurf의 에이전트 시스템 아키텍처를 심층 분석하여, AI 기반 프로그래밍 지원에 미치는 영향을 이해하기 위해 이들의 설계 철학, 작업 분해, 모델 호출 전략 및 컨텍스트 관리에 중점을 둡니다.
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=GitHub%20Copilot%2C%20Cursor%2C%20Windsurf%EC%9D%98%20%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98"
---

## GitHub Copilot, Cursor, Windsurf의 에이전트 시스템 아키텍처

최근 몇 년 동안 GitHub Copilot, Cursor, Windsurf와 같은 여러 AI 프로그래밍 보조 제품이 등장했습니다. 이들의 구현은 모두 "에이전트"(지능형 에이전트) 개념을 도입하여 AI가 코딩 작업을 보다 능동적으로 지원할 수 있도록 합니다. 이 글은 이러한 제품들의 에이전트 시스템 구축을 공학적 아키텍처 관점에서 심층적으로 조사하며, 아키텍처 설계 철학, 작업 분해 및 계획, 모델 호출 전략, 컨텍스트 상태 관리, 플러그인 확장 메커니즘, 그리고 각 설계의 주요 절충점과 혁신을 포함합니다. 다음 내용은 주로 공식 엔지니어링 블로그, 프로젝트 개발자들의 글, 그리고 관련 기술 자료를 기반으로 합니다.

![](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=GitHub%20Copilot%2C%20Cursor%2C%20Windsurf%EC%9D%98%20%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98)

### GitHub Copilot의 에이전트 아키텍처

**아키텍처 설계 철학:** GitHub Copilot은 처음에 개발자의 "AI 페어 프로그래머"로 자리매김했으며, 이제 "에이전트" 모드로 이 개념을 확장했습니다. Copilot의 에이전트 시스템은 독립적인 에이전트들의 집합이 아니라, 다중 턴 대화와 다단계 작업 실행에 참여할 수 있는 임베디드 지능형 에이전트이며, 다중 모달 입력(예: 비전 모델을 사용하여 스크린샷 해석)을 지원합니다. Copilot은 개발자 대체보다는 AI 지원을 강조합니다. 에이전트 모드에서 Copilot은 팀 내 자동화된 엔지니어처럼 작동하며, 할당된 작업을 수락하고, 자율적으로 코드를 작성하고, 디버깅하며, Pull Request를 통해 결과를 제출합니다. 이 에이전트는 채팅 인터페이스를 통해 트리거되거나 GitHub Issue를 Copilot에 할당하여 활성화할 수 있습니다.

### 작업 분해 및 계획

**작업 분해 및 계획:** Copilot의 에이전트는 복잡한 소프트웨어 작업을 하위 작업으로 분해하고 Chain-of-Thought와 유사한 내부 추론 과정을 사용하여 하나씩 완료하는 데 탁월합니다. 사용자 요구 사항이 충족될 때까지 "문제 분석 → 코드 변경 또는 명령 실행 → 결과 확인" 과정을 반복적으로 순환합니다. 예를 들어, 에이전트 모드에서 Copilot은 사용자가 지정한 단계를 실행할 뿐만 아니라, 주 목표를 달성하는 데 필요한 추가 단계를 _암묵적으로_ 추론하고 자동으로 실행합니다. 프로세스 중에 컴파일 오류나 테스트 실패가 발생하면, 에이전트가 스스로 오류를 식별하고 수정하여 다시 시도하므로, 개발자는 오류 메시지를 프롬프트로 반복해서 복사하여 붙여넣을 필요가 없습니다. VS Code 블로그는 Copilot 에이전트의 작업 주기를 다음과 같이 요약합니다: Copilot 에이전트는 편집할 관련 컨텍스트와 파일을 자율적으로 결정하고, 코드 수정 및 실행할 명령을 제안하며, 편집 또는 터미널 출력의 정확성을 모니터링하고, 작업이 완료될 때까지 지속적으로 반복합니다. 이러한 자동화된 다중 턴 실행을 통해 Copilot은 간단한 애플리케이션 생성부터 여러 파일에 걸친 대규모 리팩토링에 이르기까지 다양한 작업을 처리할 수 있습니다.

### 모델 호출 전략

**모델 호출 전략:** GitHub Copilot의 기반 모델은 처음에는 OpenAI의 Codex였으나, 이제는 더욱 강력한 다중 모델 아키텍처로 업그레이드되었습니다. Copilot은 사용자에게 "모델 옵션"에서 OpenAI의 GPT-4(내부 코드명 gpt-4o) 및 그 간소화 버전, Anthropic의 Claude 3.5(코드명 Sonnet), Google의 최신 Gemini 2.0 Flash 등 다양한 기본 모델을 선택할 수 있도록 합니다. 이러한 다중 모델 지원은 Copilot이 작업 요구 사항이나 사용자 선호도에 따라 모델 소스를 전환할 수 있음을 의미합니다. Copilot Edits(다중 파일 편집) 기능에서 GitHub은 효율성 향상을 위해 듀얼 모델 아키텍처도 사용합니다: 먼저, 선택된 "대규모 모델"이 전체 컨텍스트와 함께 초기 편집 계획을 생성한 다음, 전문화된 "추측성 디코딩(speculative decoding)" 엔드포인트가 이러한 변경 사항을 신속하게 적용합니다. 추측성 디코더는 대규모 모델이 코드 변경을 고려하는 동안 편집 결과를 미리 생성하는 경량 모델 또는 규칙 엔진으로 볼 수 있으며, 이를 통해 지연 시간을 줄입니다. 요약하자면, Copilot의 모델 전략은 클라우드에서 여러 최첨단 LLM을 통합하고, 다양한 시나리오에 최적화하며, 엔지니어링 수단(듀얼 모델 파이프라인)을 통해 응답 속도와 정확성의 균형을 맞추는 것입니다.

### 상태 관리 및 컨텍스트 유지

**상태 관리 및 컨텍스트 유지:** Copilot 에이전트는 개발 컨텍스트 활용에 큰 중점을 둡니다. 전체 저장소 코드를 대규모 모델에 직접 입력으로 제공하는 것은 비실용적이므로, Copilot은 **검색 증강 생성(Retrieval-Augmented Generation, RAG)** 전략을 사용합니다: GitHub Code Search와 같은 도구를 사용하여 저장소 내에서 관련 콘텐츠를 검색하고, 검색된 코드 스니펫을 모델의 컨텍스트에 동적으로 주입합니다. 에이전트가 시작될 때, 프로젝트 코드를 격리된 환경으로 복제하고 먼저 코드베이스 구조를 분석하여 토큰을 절약하기 위한 필요한 요약을 생성합니다. 예를 들어, Copilot이 구성하는 프롬프트는 "프로젝트 파일 구조 요약 + 주요 파일 내용 + 사용자 요청"을 포함할 수 있습니다. 이를 통해 모델은 컨텍스트 길이 제한을 초과하지 않고 솔루션을 생성할 때 전체 그림을 이해할 수 있습니다. 대화 중에도 Copilot은 연속성을 유지하기 위해 세션 기록(예: 사용자가 채팅에서 이전에 제공한 지침)을 추적합니다. 동시에 Copilot은 GitHub 플랫폼과 깊이 통합되어 있어, 이슈 설명, 관련 PR 논의 등을 추가 컨텍스트로 활용할 수 있습니다. 특히, 저장소에 코딩 표준이나 AI 사용에 대한 이전 지침을 지정하는 구성 파일이 있는 경우, 에이전트는 이러한 사용자 지정 저장소 지침도 준수합니다. Copilot 자체는 사용자 코드에 대한 장기 기억을 가지고 있지 않다는 점에 유의해야 합니다. 즉, 각 세션 이후 다음 세션을 위해 상태를 자동으로 저장하지 않습니다(사용자가 문서에 하드코딩하지 않는 한). 그러나 GitHub의 Issue/PR 메커니즘을 통해 사용자는 에이전트에 영구적인 작업 설명과 스크린샷을 효과적으로 제공할 수 있으며, 이는 컨텍스트를 전달하는 수단으로 볼 수 있습니다.

### 플러그인 시스템 및 확장 메커니즘

**플러그인 시스템 및 확장 메커니즘:** GitHub Copilot 에이전트는 도구 호출(Tool Use)을 통해 IDE 및 외부 환경에서 작업을 수행합니다. 한편, 로컬 또는 Codespaces 환경에서 Copilot은 VS Code 확장 프로그램이 제공하는 API를 호출하여 파일 읽기, 편집기 열기, 코드 스니펫 삽입, 터미널 명령 실행과 같은 작업을 수행할 수 있습니다. 다른 한편으로, GitHub은 에이전트의 "시야"와 기능을 확장하기 위해 **모델 컨텍스트 프로토콜(Model Context Protocol, MCP)**을 도입했습니다. MCP는 외부 "리소스 서버"를 구성할 수 있도록 하며, 에이전트는 표준화된 인터페이스를 통해 추가 데이터나 작업을 요청할 수 있습니다. 예를 들어, GitHub은 공식적으로 자체 MCP 서버를 제공하여 에이전트가 현재 저장소에 대한 더 많은 정보(예: 코드 검색 결과, 프로젝트 Wiki 등)를 얻을 수 있도록 합니다. MCP 메커니즘은 타사도 지원합니다: MCP 인터페이스를 구현하는 한, 에이전트는 데이터베이스 쿼리 서비스 호출이나 HTTP 요청 전송과 같이 연결할 수 있습니다. Copilot 에이전트는 이미 일부 다중 모달 기능을 가지고 있습니다. 비전 모델과 통합하여 사용자가 이슈에 첨부한 스크린샷, 디자인 다이어그램 및 기타 이미지를 보조 입력으로 파싱할 수 있습니다. 이는 UI 문제를 디버깅하거나 오류를 재현할 때 개발자가 Copilot에 스크린샷을 제공할 수 있으며, 에이전트가 "그림을 보고 말하며" 해당 코드 수정 제안을 제공할 수 있음을 의미합니다. 또한, 작업을 완료한 후 Copilot 에이전트는 Git을 통해 변경 사항을 자동으로 커밋하고 Draft PR을 열며, 관련 개발자를 **@멘션**하여 검토를 요청합니다. 검토자의 의견과 피드백(예: 특정 구현 수정 요청)도 에이전트에 의해 읽히고 새로운 지침으로 작용하여 다음 코드 업데이트를 트리거합니다. 전체 프로세스는 인간 개발자 협업과 유사합니다: AI 에이전트가 코드를 제출 → 인간이 검토하고 피드백 제공 → AI 에이전트가 개선, 인간이 항상 통제권을 갖도록 보장합니다.

### 주요 설계 절충 및 혁신

**주요 설계 절충 및 혁신:** GitHub Copilot의 에이전트 시스템은 기존 GitHub 플랫폼 생태계를 최대한 활용하며, 이는 중요한 특징입니다. 한편으로는 코드 실행 환경을 GitHub Actions 클라우드 컨테이너에 구축하여 우수한 격리성과 확장성을 달성합니다. "Project Padawan"은 이 아키텍처의 코드명으로, 새로운 실행 인프라를 처음부터 구축하는 대신 성숙한 CI/CD 시스템을 기반으로 합니다. 다른 한편으로, Copilot은 보안 측면에서 엄격한 절충안을 만듭니다: 기본적으로 에이전트는 새로 생성된 브랜치에만 코드를 푸시할 수 있으며, 메인 브랜치를 직접 수정할 수 없고, 트리거된 PR은 병합 전에 다른 사람의 승인을 받아야 하며, CI 파이프라인은 승인 전에 일시 중지됩니다. 이러한 전략은 AI 자동화 도입이 팀의 기존 검토 시스템 및 릴리스 게이트를 방해하지 않도록 보장합니다. 모델 컨텍스트 프로토콜의 제안은 Copilot의 중요한 엔지니어링 혁신으로 볼 수 있습니다. 이는 LLM 에이전트가 외부 도구/데이터에 접근하기 위한 개방형 표준을 정의하여, GitHub 내부와 외부의 다양한 데이터 소스를 미래에 AI 프롬프트에 원활하게 통합할 수 있도록 합니다. 또한, Copilot 에이전트는 실행 중에 도구 호출 단계와 생성된 출력을 포함하는 사고 로그(세션 로그)를 기록하고, 이 기록을 개발자에게 제시합니다. 이러한 투명성은 사용자가 에이전트의 "생각"과 행동을 검토할 수 있도록 하여 디버깅 및 신뢰 구축을 용이하게 합니다. 전반적으로 GitHub Copilot은 개발 수명 주기(코딩 → PR 제출 → 코드 검토)의 다양한 단계에 AI 에이전트를 내장하고, 일련의 아키텍처 결정을 통해 자동화와 기존 워크플로우의 원활한 통합을 달성합니다.

### Cursor의 에이전트 아키텍처

**아키텍처 설계 철학:** Cursor는 스타트업 Anysphere가 개발한 AI 기반 코딩 도구입니다. 본질적으로 AI 어시스턴트와 깊이 통합된 코드 에디터(VS Code 기반으로 수정됨)입니다. Cursor는 두 가지 주요 상호작용 모드를 제공합니다: 채팅 어시스턴트와 자율 에이전트. 일반 대화 모드에서는 전통적인 코드 어시스턴트처럼 질문에 답하거나 지시에 따라 코드를 생성합니다. 에이전트 모드("Composer"라고도 함)로 전환하면 Cursor는 개발자를 대신하여 일련의 작업을 능동적으로 실행할 수 있습니다. 이 아키텍처는 사용자에게 필요에 따라 선택할 자유를 줍니다: 간단한 작업은 어시스턴트 모드에서 한 줄씩 질문하여 처리할 수 있고, 복잡하거나 반복적인 작업은 에이전트를 호출하여 일괄 처리할 수 있습니다. Cursor는 현재 주로 텍스트(코드) 도메인 지원에 중점을 두며, 다중 모달 입출력은 강조하지 않습니다(음성 입력 기능을 제공하여 음성을 텍스트 프롬프트로 변환하기는 함). Copilot과 유사하게, Cursor의 에이전트 시스템 또한 여러 에이전트가 병렬로 작동하는 것이 아니라 단일 지능형 에이전트가 직렬로 작동합니다. 하지만 그 특징은 인간-AI 협업을 강조한다는 점입니다: 에이전트 모드에서 AI는 가능한 한 많은 작업을 수행하지만, 전반적으로 개발자가 언제든지 개입하여 제어할 수 있도록 허용하며, 장시간 완전히 감독 없이 실행되지는 않습니다.

**작업 분해 및 계획:** Cursor의 에이전트 모드에서 AI는 복잡한 파일 간 작업을 처리할 수 있지만, 설계는 단계별 요청 방식에 가깝습니다. 사용자로부터 상위 수준의 지시를 받으면, 에이전트는 관련 코드 스니펫을 자율적으로 검색하고, 편집이 필요한 파일을 열고, 수정 계획을 생성하며, 심지어 테스트/빌드 명령을 실행하여 효과를 검증합니다. 하지만 Copilot이나 Windsurf의 에이전트와 달리, Cursor의 에이전트는 일반적으로 초기 제안을 완료한 후 일시 중지하여 사용자 검토 및 추가 지시를 기다립니다. 이는 Cursor의 에이전트가 사용자로부터 새로운 프롬프트를 받지 않는 한 지속적으로 반복적으로 스스로를 개선하지 않는다는 것을 의미합니다. 예를 들어, Cursor에게 프로젝트 간 리팩토링을 수행하도록 요청하면, 수정이 필요한 모든 위치를 수집하고 각 파일에 대한 diff를 생성하여 사용자가 검토하도록 합니다. 이 시점에서 사용자는 어떤 변경 사항을 수락하고 적용할지 결정합니다. 이러한 변경 사항이 새로운 문제를 발생시키더라도, 사용자가 "발생한 문제를 해결해 줘"와 같은 추가 요청을 하지 않는 한 Cursor는 임의로 수정을 계속하지 않습니다. 이 메커니즘은 중요한 결정 지점에서 인간의 감독을 보장하여 AI가 통제 불능 상태로 실행되는 것을 방지합니다. 하지만 이는 또한 Cursor의 에이전트가 장기적인 계획에 대한 자율성이 부족하여 복잡한 폐쇄 루프를 완료하기 위해 단계별로 인간의 지도가 필요하다는 것을 의미합니다. 부분적으로 연속적인 자율성을 개선하기 위해 Cursor 팀은 에이전트 시스템에 일부 반복 기능을 추가했습니다. 예를 들어, 코드를 컴파일하고 실행하여 오류를 포착하고, 구문 오류나 린트 오류와 같은 일부 간단한 문제를 자동으로 수정하려고 시도하지만, 일반적으로 몇 번의 시도 후에 중단하고 사용자에게 제어권을 반환합니다. 개발자들은 Cursor의 에이전트가 로컬 리팩토링이나 제한된 범위의 변경에서는 매우 효율적으로 작동하지만, 광범위한 변경의 경우 사용자가 작업을 단계별로 완료하기 위해 세그먼트별로 프롬프트를 제공해야 하는 경우가 많다는 것을 관찰했습니다. 전반적으로 Cursor는 에이전트를 전능한 자동 프로그래밍 로봇이 아닌 "스마트 실행 보조자"로 포지셔닝합니다. 그 작업 계획은 단기 실행, 적시 보고, 그리고 인간이 다음 단계를 결정하도록 하는 경향이 있습니다.

**모델 호출 전략:** Cursor는 자체 대규모 언어 모델을 훈련하지 않고, 타사 API를 통합하는 전략을 채택합니다. 사용자는 Cursor 내에서 OpenAI 또는 Anthropic과 같은 공급업체의 API 키를 구성할 수 있으며, 그러면 Cursor의 백엔드가 사용자를 대신하여 해당 대규모 모델을 호출합니다. 사용자가 어떤 모델 공급자를 선택하든, 모든 AI 요청은 Cursor 자체 서버를 통과합니다: 로컬 애플리케이션은 에디터 컨텍스트와 사용자 질문을 묶어 클라우드로 보내고, Cursor 서버는 완전한 프롬프트를 구성하여 모델을 호출한 다음, 결과를 에디터로 반환합니다. 이 아키텍처는 Cursor의 프롬프트 최적화 및 세션 상태의 통합 관리를 용이하게 하지만, 온라인으로 사용해야 하며 오프라인 모드에서는 핵심 AI 기능을 사용할 수 없다는 것을 의미하기도 합니다. 개발자 비용 고려 사항으로, Cursor는 사용자가 자체 API 할당량을 사용하도록 지원하지만(따라서 모델 호출 비용은 사용자에게 청구됨), 그럼에도 불구하고 요청은 코드 임베딩 검색 및 응답 형식 지정과 같은 작업을 위해 공식 서버를 통과합니다. 모델 선택 측면에서 Cursor는 일반적으로 몇 가지 주류 모델(예: GPT-4, GPT-3.5, Claude 2 등)을 선택할 수 있도록 제공합니다. 사용자는 하나를 선호할 수 있지만, Cursor가 지원하지 않는 모델에는 접근할 수 없습니다. 대조적으로, Windsurf와 같은 시스템은 기본 엔진을 교체할 수 있지만, Cursor는 더 폐쇄적이며 모델 업데이트 및 조정은 주로 공식 팀에 의해 제어됩니다. 또한 Cursor는 Copilot Enterprise와 같은 로컬 배포 솔루션을 제공하지 않으며, 오픈 소스 모델을 통합하지도 않습니다. 전적으로 클라우드 서비스 지향적이므로 최신 대규모 모델 버전을 빠르게 따라잡을 수 있지만, 사용자에게 클라우드 처리 신뢰 및 관련 개인정보 보호 정책 준수를 요구합니다. Cursor가 "사고 모드(Thinking mode)"를 제공한다는 점도 주목할 만합니다. 사용자

### Windsurf (Codeium) 에이전트 아키텍처

**아키텍처 설계 철학:** Windsurf는 Codeium 팀이 출시한 AI 기반 프로그래밍 제품으로, 업계 최초의 "Agentic IDE"(지능형 에이전트 통합 개발 환경)로 자리매김하고 있습니다. Chat/Agent 모드 간 전환이 필요한 Copilot과 달리, Windsurf의 AI 어시스턴트(Cascade라고 명명)는 처음부터 에이전트 기능을 갖추고 있어, 필요에 따라 질문 답변과 다단계 작업의 자율적 실행 사이를 원활하게 전환합니다. Codeium은 공식적으로 그들의 철학을 "Flows = Agents + Copilots"로 요약합니다. Flow는 개발자와 AI가 동기화된 협업 상태에 있음을 의미합니다. AI는 언제든지 비서처럼 제안을 제공하고, 필요할 때 일련의 작업을 능동적으로 인계하여 실행할 수 있으며, 이 모든 과정은 개발자의 작업과 실시간으로 동기화됩니다. 이 아키텍처에는 명확한 인간-기계 역할 전환 지점이 없습니다. AI는 개발자의 행동을 끊임없이 "엿듣고" 리듬에 맞춰 적응합니다. Windsurf에서 Cascade와 채팅할 때, Cascade는 직접 질문에 답하거나 사용자의 진술을 작업으로 해석하여 일련의 작업을 트리거할 수 있습니다. 예를 들어, 사용자가 Cascade에게 대화에서 단순히 "사용자 인증을 구현하고 관련 코드 섹션을 업데이트해 주세요"라고 말하면, Cascade는 이를 모듈 간 요구 사항으로 자동 이해할 수 있습니다. 즉, 코드베이스를 검색하여 사용자 인증과 관련된 파일을 찾고, 이 파일들을 열어 편집(예: 인증 기능 추가, 새 구성 생성, 호출 로직 수정)하고, 필요한 경우 프로젝트 테스트를 실행한 다음, 최종적으로 사용자에게 완료 상태를 보고합니다. 이 모든 과정에서 개발자는 모드를 전환하거나 단계별로 프롬프트를 제공할 필요가 없습니다. 다중 모드 측면에서 현재 Windsurf/Cascade는 주로 코드 텍스트 도메인에 중점을 두고 있으며, 이미지 또는 오디오 구문 분석 지원에 대해서는 아직 언급되지 않았습니다. 그러나 Cascade의 "개발자 의도" 파악은 순수한 텍스트 입력뿐만 아니라 IDE 환경의 다양한 신호(아래 컨텍스트 섹션 참조)에서도 비롯됩니다. 전반적으로 Windsurf의 아키텍처 철학은 AI를 IDE에 통합하는 것입니다. 즉, 수동적인 질문 답변 도구에서 능동적인 협업 파트너로 진화하여 개발 효율성을 극대화하는 것입니다.

**작업 분해 및 자율성:** Cascade는 현재 제품 중 가장 강력한 자율 오케스트레이션 기능 중 하나를 보유하고 있습니다. 사용자가 제공

### 시스템 비교 요약

아래 표는 GitHub Copilot, Cursor, Windsurf의 에이전트 아키텍처 유사점과 차이점을 요약하여 보여줍니다:

| 기능 차원                           | GitHub Copilot                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Cursor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Windsurf (Codeium)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| ----------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **아키텍처 포지셔닝**               | 프로그래밍 지원을 위한 챗봇으로 시작하여 "에이전트 모드"(코드명 Project Padawan)로 확장; 에이전트는 GitHub 플랫폼에 내장될 수 있으며, Issues/PR 워크플로와 통합됩니다. 다중 턴 대화 단일 에이전트이며, 명시적인 다중 에이전트 아키텍처는 없습니다. 다중 모달 입력(이미지)을 지원합니다.                                                                                                                                                                                                                                                                                                | AI 우선 로컬 편집기(VS Code 파생), 채팅 모드 및 에이전트 모드 상호 작용을 포함합니다. 기본 어시스턴트 모드는 Q&A 및 코드 완성에 중점을 두며, 에이전트 모드는 AI가 자율적으로 작업을 실행하기 위해 명시적인 활성화가 필요합니다. 단일 에이전트 아키텍처이며, 다중 모달 처리는 없습니다.                                                                                                                                                                                                                                                                                                                                                                        | 처음부터 "에이전트 중심 IDE"로 설계되었습니다: AI 어시스턴트 Cascade는 항상 온라인 상태이며, 채팅과 자율적인 다단계 작업을 모두 수행할 수 있으며, 모드 전환이 필요 없습니다. 단일 에이전트 실행이며, Flows를 통해 인간과 AI 간의 동기식 협업을 달성하며, 현재는 코드 텍스트에 중점을 둡니다.                                                                                                                                                                                                                                                                                                                                                                                |
| **작업 계획 및 실행**               | 자동 작업 분해 및 반복 실행을 지원합니다. 에이전트는 사용자 요청을 하위 작업으로 분해하고 목표에 도달하거나 명시적으로 중지될 때까지 반복적으로 완료합니다. 자가 치유 기능(컴파일/테스트 오류를 식별하고 수정할 수 있음)을 가집니다. 각 작업 완료 후 PR로 결과를 제공하고 인간 검토를 기다립니다; 검토 피드백은 다음 반복을 트리거합니다.                                                                                                                                                                                                                                              | 파일 간 수정 사항을 처리할 수 있지만 단일 턴 실행에 가깝습니다: 에이전트는 지침을 받고 모든 수정 제안을 한 번에 제공하며, 사용자 승인을 위해 diff를 나열합니다. 일반적으로 여러 턴으로 자율적으로 반복하지 않으며(사용자가 다시 프롬프트하지 않는 한), 오류는 종종 AI가 수정할지 여부를 사용자가 결정하도록 남겨둡니다. 기본적으로 제한된 수의 자동 수정 주기만 수행하여 무한정 중단되는 것을 방지합니다.                                                                                                                                                                                                                                                     | 심층 자율성: Cascade는 상위 수준 요구 사항을 일련의 작업으로 분해하고 작업이 완료될 때까지 지속적으로 실행할 수 있습니다. 대규모 리팩토링 및 모듈 간 작업에 탁월하며, 코드가 자체 검사를 통과할 때까지 편집, 파일 생성, 명령 실행, 테스트 검증 등에 대한 호출을 자동으로 연결합니다. 프로세스 중에 새로운 문제가 발견되면 계속해서 반복하고 수정하며, 최종 결과 외에는 거의 인간 개입이 필요하지 않습니다(하지만 중요한 변경 사항은 인간의 최종 확인이 필요합니다).                                                                                                                                                                                                         |
| **모델 전략**                       | 클라우드 다중 모델 융합: OpenAI GPT-4, GPT-3.5 시리즈(내부 코드명 o1, o3-mini 등), Anthropic Claude 3.5, Google Gemini 2.0 등을 지원하며, 사용자는 인터페이스에서 선호하는 모델을 전환할 수 있습니다. 듀얼 모델 아키텍처(대규모 모델이 솔루션을 생성하고, 소규모 모델이 변경 사항을 빠르게 적용)를 통해 효율성을 향상시킵니다. 모델은 GitHub에 의해 통합적으로 호스팅되고 호출됩니다; Copilot Enterprise 사용자 요청은 전용 인스턴스를 통해 처리됩니다. 프라이빗 배포를 지원하지 않습니다.                                                                                             | 전적으로 타사 대규모 모델 API에 의존합니다: 모든 요청은 Cursor의 클라우드를 통해 중계되고 OpenAI/Anthropic 모델을 호출합니다. 사용자는 자체 API 키를 사용할 수 있지만(청구는 자체 관리), 호출은 여전히 공식 서버에서 발생합니다. 오프라인 또는 로컬 모델 옵션은 없습니다. 모델 유형은 Cursor가 지원하는 범위에 따라 달라지며; 사용자는 새로운 모델을 자유롭게 통합할 수 없습니다. Cursor는 모델을 직접 훈련하지 않고 프롬프트 최적화를 통해 외부 모델을 조정합니다.                                                                                                                                                                                           | 주로 자체 개발 모델, 유연한 백엔드: 기본적으로 Codeium의 독점 코드 모델을 사용하며, 엔터프라이즈 사용자가 자체 호스팅 배포를 선택할 수 있도록 합니다. 아키텍처는 다양한 모델 엔진(Codeium "Sonnet" 모델 또는 오픈 소스 등) 변경을 지원하며, 향후 타사 인터페이스를 확장할 수 있습니다. 일부 경량 기능은 대기 시간을 줄이기 위해 로컬/엣지 컴퓨팅을 위해 소규모 모델을 사용합니다. AI 환경에 대한 사용자 제어(모델 업데이트 속도, 사용자 제어 버전 안정성)를 강조합니다.                                                                                                                                                                                                     |
| **컨텍스트 및 메모리**              | RAG 전략을 사용하여 코드 컨텍스트를 얻습니다: GitHub 코드 검색을 통해 관련 코드 스니펫을 검색하고 프롬프트에 주입합니다. 프롬프트에는 토큰 절약을 위해 전체 텍스트 대신 프로젝트 구조 요약이 포함됩니다. 작업 의도 및 프로젝트 표준을 이해하기 위해 이슈 설명, 관련 PR 논의를 컨텍스트에 포함하는 것을 지원합니다. 대화 기록은 단일 세션 내에서 유지됩니다; 자동 교차 세션 메모리는 없습니다(교차 세션 정보를 전달하기 위해 이슈/PR 또는 README에 의존해야 함).                                                                                                                        | 시작 시 프로젝트에 대한 벡터 인덱스를 구축하여 의미론적 검색을 지원합니다. 모델 프롬프트는 사용자가 현재 제공하는 코드 컨텍스트(열린 파일 또는 스니펫)에 중점을 둡니다; 다른 부분이 필요한 경우 의미론적 관련성을 통해 검색되어 삽입됩니다. `.cursor/rules` 파일 메커니즘을 제공하여 개발자가 프로젝트에 대한 영구 지식 및 표준을 설정할 수 있도록 합니다; 에이전트는 각 대화에서 이 규칙을 읽으며, 이는 인간이 제공하는 장기 기억과 동일합니다. 기본적으로 자동 교차 세션 메모리는 없습니다(사용자가 규칙 파일에 수동으로 기록해야 함).                                                                                                                      | 전체 프로젝트 의미론적 인덱싱: 전체 코드베이스를 로컬에서 사전 스캔하여 인덱스를 구축합니다; Cascade는 언제든지 모든 파일 내용을 컨텍스트로 검색할 수 있습니다. 중요한 대화 내용과 사용자 지정 메모/규칙을 자동으로 영구적으로 저장하는 Memories 시스템을 특징으로 하여 교차 세션 메모리를 달성합니다. 따라서 Cascade는 다시 시작한 후에도 프로젝트 규칙 및 이전 논의를 "기억"합니다. 또한 IDE 환경 상태를 컨텍스트 소스로 통합합니다: 사용자가 연 파일, 커서 위치, 터미널 출력 등을 실시간으로 인식하여 이 암시적 정보를 사용하여 사용자 의도를 이해합니다. 전반적으로 Cascade는 더 넓고 동적인 컨텍스트 보기를 가집니다.                                                  |
| **도구 및 확장**                    | GitHub 워크플로와의 심층 통합: 에이전트는 GitHub Actions를 통해 클라우드에서 격리된 개발 환경을 얻으며, 단위 테스트 실행, 프로젝트 실행 등을 수행할 수 있습니다. 내장 도구에는 파일 읽기, 저장소 검색, 코드 변경 적용, 터미널 명령 등이 포함되며, LLM이 필요에 따라 호출할 수 있습니다. MCP(Model Context Protocol) 표준을 도입하여 외부 데이터 소스 및 서비스 연결을 지원합니다; 공식 MCP 플러그인은 GitHub 데이터에 액세스할 수 있으며, 타사 확장을 위한 전역 개방형 인터페이스를 제공합니다. 컴퓨터 비전 기능을 보유하여 이슈에 첨부된 스크린샷을 문제의 근거로 파싱할 수 있습니다. | 풍부한 IDE 조작 도구를 제공하며, 시스템 프롬프트에 의해 사용 방법이 정확하게 안내됩니다(예: AI가 수정하기 전에 파일 내용을 읽도록 요구하여 컨텍스트에 기반하지 않은 맹목적인 작성을 방지). MCP 인터페이스를 통해 플러그인 기능을 달성하여 사용자 지정 도구/데이터 소스에 연결하여 에이전트 기능을 확장할 수 있습니다. 예를 들어, 개발자는 데이터베이스 쿼리 플러그인을 추가하여 Cursor 에이전트가 코드에서 최신 데이터베이스 스키마 정보를 사용하도록 할 수 있습니다. Cursor 에이전트는 도구 사용에 대한 사전 정의된 규칙을 엄격하게 따르며(예: 호출 전에 작업 설명), 상호 작용 예측 가능성을 향상시킵니다.                                                   | 가장 포괄적인 도구 통합: Cascade는 파일 시스템부터 터미널까지 편집기 및 시스템에 대한 광범위한 운영 제어 권한을 가집니다. 자동 명령 실행(예: 빌드, 테스트) 및 후속 작업에 결과 활용을 지원합니다. Wave 3부터 MCP 플러그인을 지원하여 JSON 구성을 통해 외부 서비스가 Cascade의 도구(예: 지도 API, 데이터베이스 인터페이스)가 될 수 있도록 합니다. Cascade는 더 스마트한 응답을 위해 IDE 상태(클립보드 내용, 현재 선택 영역 등)도 모니터링합니다. 보안을 위해 Windsurf는 중요한 변경 사항에 대한 사용자 확인과 외부 서비스 호출에 대한 사전 구성을 요구하여 오용을 방지합니다. 전반적으로 Cascade는 IDE 플러그인 및 셸 스크립트 기능을 갖춘 AI 개발 파트너와 거의 동일합니다. |
| **엔지니어링 트레이드오프 및 혁신** | 플랫폼 통합: 기존 GitHub 인프라(Actions, PR 메커니즘 등)를 최대한 활용하여 에이전트를 호스팅합니다. 보안 우선: 검토되지 않은 코드가 메인 브랜치 및 프로덕션 환경에 직접 영향을 미 미치지 않도록 내장된 정책을 가집니다. MCP 개방형 표준을 제안하여 LLM이 외부 도구를 호출하는 범용 솔루션에 대한 업계 탐색을 선도합니다. 투명성: 사용자가 에이전트 실행 로그를 볼 수 있도록 하여 의사 결정 과정을 이해하고 신뢰를 높입니다. 혁신은 개발 워크플로의 다양한 단계에 AI를 깊이 통합하여 폐쇄 루프 인간-AI 협업 개발을 달성하는 데 있습니다.                                                | 클라우드 서비스: 선택된 클라우드 아키텍처는 대규모 모델 성능과 통합 관리를 보장하지만, 오프라인 기능을 희생합니다. 미세 조정된 프롬프트: LLM을 전문 코드 어시스턴트로 전환하는 것은 방대한 시스템 프롬프트 및 도구 지침 모음에 의존합니다; 이 분야에 대한 Cursor의 투자는 생성 품질을 높이 평가받게 했습니다. 인간 감독: AI에게 코드 수정의 완전한 자유를 주기보다는 인간 확인 단계를 추가하는 것을 선호합니다—이러한 보수적인 전략은 오류 위험을 줄이고 사용자 신뢰를 높입니다. 사용자 정의 가능성: 규칙 파일 및 플러그인을 통해 Cursor는 고급 사용자에게 AI 동작을 사용자 정의하고 기능을 확장하는 방법을 제공하며, 이는 주요 엔지니어링 유연성 이점입니다. | 인간 중심: 초기 에이전트 비동기 실행의 낮은 효율성을 해결하기 위해 Flows 모드를 도입하여 AI 작업과 인간 간의 실                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
