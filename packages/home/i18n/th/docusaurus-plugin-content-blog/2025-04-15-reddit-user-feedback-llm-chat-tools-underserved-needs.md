---
title: "ความคิดเห็นของผู้ใช้ Reddit เกี่ยวกับเครื่องมือแชท LLM หลัก"
tags: [AI, ChatGPT, Claude, Google Gemini, Open-Source LLMs]
keywords: [เครื่องมือแชท AI, ข้อเสนอแนะจากผู้ใช้, ChatGPT, Claude, Google Gemini, open-source LLMs, การวิเคราะห์ Reddit]
authors: [lark]
description: บทความนี้ให้การวิเคราะห์เชิงลึกเกี่ยวกับการสนทนาใน Reddit เกี่ยวกับเครื่องมือแชท AI ยอดนิยม รวมถึง ChatGPT, Claude, Google Gemini และ open-source LLMs โดยเน้นถึงปัญหาที่ผู้ใช้รายงานบ่อย ๆ ฟีเจอร์ที่ร้องขอบ่อย ๆ และความต้องการที่ยังไม่ได้รับการตอบสนอง โดยให้ข้อมูลเชิงลึกเกี่ยวกับจุดแข็งและจุดอ่อนของแต่ละเครื่องมือ
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=ความคิดเห็นของผู้ใช้%20Reddit%20เกี่ยวกับเครื่องมือแชท%20LLM%20หลัก"
---

# ความคิดเห็นของผู้ใช้ Reddit เกี่ยวกับเครื่องมือแชท LLM หลัก

**ภาพรวม:** รายงานนี้วิเคราะห์การสนทนาใน Reddit เกี่ยวกับเครื่องมือแชท AI ยอดนิยมสี่ตัว ได้แก่ **ChatGPT ของ OpenAI**, **Claude ของ Anthropic**, **Gemini ของ Google (Bard)** และ **open-source LLMs** (เช่น โมเดลที่ใช้ LLaMA) โดยสรุปปัญหาที่ผู้ใช้รายงานบ่อย ๆ ฟีเจอร์ที่ร้องขอบ่อย ๆ ความต้องการที่ยังไม่ได้รับการตอบสนอง หรือกลุ่มผู้ใช้ที่รู้สึกว่าไม่ได้รับการตอบสนอง และความแตกต่างในการรับรู้ระหว่างนักพัฒนา ผู้ใช้ทั่วไป และผู้ใช้ธุรกิจ ตัวอย่างเฉพาะและคำพูดจากกระทู้ Reddit ถูกนำมาใช้เพื่อแสดงให้เห็นถึงประเด็นเหล่านี้

![ความคิดเห็นของผู้ใช้ Reddit เกี่ยวกับเครื่องมือแชท LLM หลัก](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=ความคิดเห็นของผู้ใช้%20Reddit%20เกี่ยวกับเครื่องมือแชท%20LLM%20หลัก)

## ChatGPT (OpenAI)

### ปัญหาและข้อจำกัดทั่วไป

- **หน่วยความจำบริบทที่จำกัด:** ข้อร้องเรียนอันดับต้น ๆ คือความสามารถของ ChatGPT ในการจัดการกับการสนทนาที่ยาวหรือเอกสารขนาดใหญ่โดยไม่ลืมรายละเอียดก่อนหน้า ผู้ใช้มักจะเจอขีดจำกัดความยาวบริบท (ไม่กี่พันโทเค็น) และต้องตัดหรือสรุปข้อมูล ผู้ใช้คนหนึ่งกล่าวว่า *“การเพิ่มขนาดหน้าต่างบริบทจะเป็นการปรับปรุงที่ใหญ่ที่สุด... นั่นคือขีดจำกัดที่ฉันเจอบ่อยที่สุด”* เมื่อเกินบริบท ChatGPT จะลืมคำแนะนำหรือเนื้อหาเริ่มต้น ทำให้คุณภาพลดลงกลางเซสชัน

- **ขีดจำกัดข้อความสำหรับ GPT-4:** ผู้ใช้ ChatGPT Plus บ่นเกี่ยวกับขีดจำกัด 25 ข้อความ/3 ชั่วโมงในการใช้ GPT-4 (ขีดจำกัดที่มีในปี 2023) การเจอขีดจำกัดนี้ทำให้พวกเขาต้องรอ ขัดจังหวะการทำงาน ผู้ใช้หนัก ๆ พบว่าการจำกัดนี้เป็นปัญหาใหญ่

- **ตัวกรองเนื้อหาที่เข้มงวด (“nerfs”):** ผู้ใช้ Reddit หลายคนรู้สึกว่า ChatGPT มีข้อจำกัดมากเกินไป มักปฏิเสธคำขอที่เวอร์ชันก่อนหน้านี้จัดการได้ โพสต์ที่ได้รับการโหวตสูงบ่นว่า *“แทบทุกอย่างที่คุณถามมันในทุกวันนี้จะได้รับคำตอบว่า ‘ขอโทษ ไม่สามารถช่วยได้’... มันกลายเป็นเครื่องมือที่มีประโยชน์ที่สุดไปเป็นเทียบเท่ากับ Google Assistant ได้อย่างไร?”* ผู้ใช้ยกตัวอย่างเช่น ChatGPT ปฏิเสธที่จะจัดรูปแบบใหม่ *ข้อความของตัวเอง* (เช่น ข้อมูลเข้าสู่ระบบ) เนื่องจากการใช้งานที่ผิดพลาดที่เป็นไปได้ ผู้สมัครสมาชิกที่จ่ายเงินโต้แย้งว่า *“แนวคิดที่คลุมเครือว่าผู้ใช้อาจทำสิ่ง 'ไม่ดี'... ไม่ควรเป็นเหตุผลในการไม่แสดงผลลัพธ์”* เนื่องจากพวกเขาต้องการผลลัพธ์ของโมเดลและจะใช้อย่างรับผิดชอบ

- **ภาพหลอนและข้อผิดพลาด:** แม้จะมีความสามารถขั้นสูง แต่ ChatGPT สามารถสร้างข้อมูลที่ไม่ถูกต้องหรือแต่งขึ้นด้วยความมั่นใจ ผู้ใช้บางคนสังเกตเห็นว่าสิ่งนี้แย่ลงเมื่อเวลาผ่านไป สงสัยว่าโมเดลถูก “ทำให้โง่ลง” ตัวอย่างเช่น ผู้ใช้ในด้านการเงินกล่าวว่า ChatGPT เคยคำนวณเมตริกเช่น NPV หรือ IRR ได้อย่างถูกต้อง แต่หลังจากการอัปเดต *“ฉันได้รับคำตอบที่ผิดมากมาย... มันยังคงให้คำตอบที่ผิด [แม้หลังจากการแก้ไข] ฉันเชื่อจริง ๆ ว่ามันโง่ลงมากตั้งแต่มีการเปลี่ยนแปลง”* ความไม่ถูกต้องที่คาดเดาไม่ได้เช่นนี้ทำให้ความไว้วางใจลดลงสำหรับงานที่ต้องการความแม่นยำของข้อเท็จจริง

- **ผลลัพธ์โค้ดที่ไม่สมบูรณ์:** นักพัฒนามักใช้ ChatGPT เพื่อขอความช่วยเหลือเกี่ยวกับการเขียนโค้ด แต่พวกเขารายงานว่าบางครั้งมันละเว้นส่วนของโซลูชันหรือย่อโค้ดยาว ๆ ผู้ใช้คนหนึ่งแชร์ว่า ChatGPT ตอนนี้ *“ละเว้นโค้ด ผลิตโค้ดที่ไม่มีประโยชน์ และแย่ในสิ่งที่ฉันต้องการให้มันทำ... มันมักละเว้นโค้ดมากจนฉันไม่รู้ด้วยซ้ำว่าจะรวมโซลูชันของมันอย่างไร”* สิ่งนี้บังคับให้ผู้ใช้ต้องถามคำถามติดตามเพื่อดึงส่วนที่เหลือออกมา หรือเย็บคำตอบเข้าด้วยกันด้วยตนเอง ซึ่งเป็นกระบวนการที่น่าเบื่อ

- **ข้อกังวลเกี่ยวกับประสิทธิภาพและเวลาใช้งาน:** มีการรับรู้ว่า ประสิทธิภาพของ ChatGPT สำหรับผู้ใช้รายบุคคลลดลงเมื่อการใช้งานขององค์กรเพิ่มขึ้น *“ฉันคิดว่าพวกเขากำลังจัดสรรแบนด์วิดท์และพลังการประมวลผลให้กับธุรกิจและดึงมันออกจากผู้ใช้ ซึ่งเป็นสิ่งที่ทนไม่ได้เมื่อพิจารณาจากค่าใช้จ่ายในการสมัครสมาชิก!”* ผู้ใช้ Plus ที่หงุดหงิดคนหนึ่งกล่าว การหยุดทำงานหรือการช้าลงในช่วงเวลาที่มีการใช้งานสูงสุดได้รับการบันทึกไว้โดยบังเอิญ ซึ่งอาจขัดขวางการทำงาน

### ฟีเจอร์หรือการปรับปรุงที่ร้องขอบ่อย

- **หน้าต่างบริบท / หน่วยความจำที่ยาวขึ้น:** การปรับปรุงที่ร้องขอมากที่สุดคือความยาวบริบทที่ใหญ่ขึ้น ผู้ใช้ต้องการมีการสนทนาที่ยาวขึ้นมากหรือป้อนเอกสารขนาดใหญ่โดยไม่ต้องรีเซ็ต หลายคนแนะนำให้ขยายบริบทของ ChatGPT ให้ตรงกับความสามารถของ GPT-4 ที่มี 32K โทเค็น (ปัจจุบันมีให้ใช้งานผ่าน API) หรือมากกว่านั้น ตามที่ผู้ใช้คนหนึ่งกล่าวไว้ว่า *“GPT ดีที่สุดเมื่อมีบริบท และเมื่อมันจำบริบทเริ่มต้นไม่ได้ ฉันก็หงุดหงิด... ถ้าข่าวลือเป็นจริงเกี่ยวกับ PDF บริบท นั่นจะแก้ปัญหาของฉันได้แทบทั้งหมด”* มีความต้องการสูงสำหรับฟีเจอร์ในการอัปโหลดเอกสารหรือเชื่อมโยงข้อมูลส่วนบุคคลเพื่อให้ ChatGPT สามารถจดจำและอ้างอิงได้ตลอดเซสชัน

- **การจัดการไฟล์และการรวมระบบ:** ผู้ใช้มักจะขอวิธีที่ง่ายกว่าในการป้อนไฟล์หรือข้อมูลเข้า ChatGPT ในการสนทนา ผู้คนพูดถึงการต้องการ *“คัดลอกและวาง Google Drive ของฉันและให้มันทำงาน”* หรือมีปลั๊กอินที่ให้ ChatGPT ดึงบริบทจากไฟล์ส่วนตัวได้โดยตรง บางคนได้ลองใช้วิธีแก้ปัญหา (เช่น ปลั๊กอินอ่าน PDF หรือการเชื่อมโยง Google Docs) แต่บ่นเกี่ยวกับข้อผิดพลาดและขีดจำกัด ผู้ใช้คนหนึ่งอธิบายปลั๊กอินในอุดมคติของพวกเขาว่าเป็นปลั๊กอินที่ *“ทำงานเหมือน Link Reader แต่สำหรับไฟล์ส่วนตัว... เลือกส่วนใดของไดรฟ์ของฉันที่จะใช้ในการสนทนา... นั่นจะแก้ปัญหาทุกอย่างที่ฉันมีกับ GPT-4 ในปัจจุบัน”* สรุปคือ การสนับสนุนเนื้อหาภายนอกที่ดีกว่า (นอกเหนือจากข้อมูลการฝึกอบรม) เป็นคำขอที่ได้รับความนิยม

- **การลดการจำกัดสำหรับผู้ใช้ที่ชำระเงิน:** เนื่องจากผู้ใช้ Plus จำนวนมากเจอขีดจำกัดข้อความของ GPT-4 พวกเขาจึงเรียกร้องขีดจำกัดที่สูงขึ้นหรือทางเลือกในการจ่ายเงินเพิ่มสำหรับการเข้าถึงไม่จำกัด ขีดจำกัด 25 ข้อความถูกมองว่าเป็นการจำกัดโดยพลการและขัดขวางการใช้งานอย่างเข้มข้น ผู้คนต้องการโมเดลที่ใช้ตามการใช้งานหรือขีดจำกัดที่สูงขึ้นเพื่อให้เซสชันการแก้ปัญหาที่ยาวนานไม่ถูกตัดขาด

- **โหมดการกลั่นกรองเนื้อหาที่ “ไม่เซ็นเซอร์” หรือกำหนดเอง:** ผู้ใช้บางกลุ่มต้องการความสามารถในการสลับความเข้มงวดของตัวกรองเนื้อหา โดยเฉพาะอย่างยิ่งเมื่อใช้ ChatGPT สำหรับตัวเอง (ไม่ใช่เนื้อหาที่เผยแพร่สู่สาธารณะ) พวกเขารู้สึกว่าโหมด “การวิจัย” หรือ “ไม่เซ็นเซอร์” – ที่มีคำเตือนแต่ไม่ปฏิเสธอย่างหนัก – จะช่วยให้พวกเขาสำรวจได้อย่างอิสระมากขึ้น ตามที่ผู้ใช้คนหนึ่งกล่าวไว้ว่า ลูกค้าที่จ่ายเงินมองว่าเป็นเครื่องมือและเชื่อว่า *“ฉันจ่ายเงินสำหรับ [มัน]”* พวกเขาต้องการตัวเลือกในการรับคำตอบแม้ในคำถามที่อยู่ในขอบเขต ในขณะที่ OpenAI ต้องสร้างสมดุลระหว่างความปลอดภัย ผู้ใช้เหล่านี้แนะนำให้ใช้ธงหรือการตั้งค่าเพื่อผ่อนคลายนโยบายในการแชทส่วนตัว

- **ความแม่นยำของข้อเท็จจริงและการอัปเดตที่ดีขึ้น:** ผู้ใช้มักขอความรู้ที่ทันสมัยและภาพหลอนน้อยลง ขีดจำกัดความรู้ของ ChatGPT (กันยายน 2021 ในเวอร์ชันก่อนหน้า) เป็นข้อจำกัดที่มักถูกหยิบยกขึ้นมาใน Reddit OpenAI ได้แนะนำการท่องเว็บและปลั๊กอิน ซึ่งผู้ใช้บางคนใช้ประโยชน์ แต่คนอื่น ๆ เพียงแค่ขอให้โมเดลพื้นฐานได้รับการอัปเดตบ่อยขึ้นด้วยข้อมูลใหม่ การลดข้อผิดพลาดที่ชัดเจน – โดยเฉพาะในโดเมนเช่นคณิตศาสตร์และการเขียนโค้ด – เป็นความปรารถนาที่ต่อเนื่อง นักพัฒนาบางคนให้ข้อเสนอแนะเมื่อ ChatGPT ทำผิดพลาดโดยหวังว่าจะมีการปรับปรุงโมเดล

- **ผลลัพธ์โค้ดและเครื่องมือที่ดีขึ้น:** นักพัฒนามีคำขอฟีเจอร์ เช่น ตัวแปลโค้ดที่ได้รับการปรับปรุงซึ่งไม่ละเว้นเนื้อหา และการรวมเข้ากับ IDE หรือการควบคุมเวอร์ชัน (ปลั๊กอินตัวแปลโค้ดของ OpenAI – ปัจจุบันเป็นส่วนหนึ่งของ “การวิเคราะห์ข้อมูลขั้นสูง” – เป็นก้าวหนึ่งในทิศทางนี้และได้รับคำชม) อย่างไรก็ตาม ผู้ใช้มักขอการควบคุมที่ละเอียดกว่าในการสร้างโค้ด: เช่น ตัวเลือกในการส่งออกโค้ดที่สมบูรณ์ ไม่กรอง แม้ว่าจะยาว หรือกลไกในการแก้ไขโค้ดได้ง่ายหาก AI ทำผิดพลาด โดยพื้นฐานแล้วพวกเขาต้องการให้ ChatGPT ทำตัวเหมือนผู้ช่วยการเขียนโค้ดที่เชื่อถือได้มากขึ้นโดยไม่จำเป็นต้องมีหลายคำถามเพื่อปรับคำตอบ

- **โปรไฟล์ผู้ใช้หรือหน่วยความจำที่คงอยู่:** การปรับปรุงอีกอย่างที่บางคนกล่าวถึงคือการให้ ChatGPT จดจำสิ่งต่าง ๆ เกี่ยวกับผู้ใช้ข้ามเซสชัน (ด้วยความยินยอม) ตัวอย่างเช่น การจดจำสไตล์การเขียนของตนเอง หรือว่าพวกเขาเป็นวิศวกรซอฟต์แวร์ โดยไม่ต้องระบุใหม่ทุกการแชทใหม่ สิ่งนี้สามารถผูกเข้ากับการปรับแต่ง API หรือฟีเจอร์ “โปรไฟล์” ผู้ใช้คัดลอกบริบทที่สำคัญไปยังการแชทใหม่ด้วยตนเองในขณะนี้ ดังนั้นหน่วยความจำในตัวสำหรับการตั้งค่าส่วนบุคคลจะช่วยประหยัดเวลา

### ความต้องการหรือกลุ่มผู้ใช้ที่ยังไม่ได้รับการตอบสนอง

- **นักวิจัยและนักเรียนที่มีเอกสารยาว:** ผู้ที่ต้องการให้ ChatGPT วิเคราะห์เอกสารวิจัย หนังสือ หรือชุดข้อมูลขนาดใหญ่รู้สึกว่าไม่ได้รับการตอบสนอง ขีดจำกัดปัจจุบันบังคับให้พวกเขาต้องตัดข้อความหรือยอมรับการสรุป กลุ่มนี้จะได้รับประโยชน์อย่างมากจากหน้าต่างบริบทที่ใหญ่ขึ้นหรือฟีเจอร์ในการจัดการเอกสารยาว (ตามที่เห็นได้จากโพสต์จำนวนมากเกี่ยวกับการพยายามหลีกเลี่ยงขีดจำกัดโทเค็น)

- **ผู้ใช้ที่ต้องการการเล่าเรื่องสร้างสรรค์หรือการเล่นบทบาทเกินขีดจำกัด:** ในขณะที่ ChatGPT มักใช้สำหรับการเขียนเชิงสร้างสรรค์ นักเล่าเรื่องบางคนรู้สึกถูกจำกัดโดยโมเดลที่ลืมจุดพล็อตเริ่มต้นในเรื่องยาวหรือปฏิเสธเนื้อหาสำหรับผู้ใหญ่/สยองขวัญ พวกเขาหันไปใช้โมเดลทางเลือกหรือการแฮ็กเพื่อดำเนินการเล่าเรื่องต่อไป ผู้ใช้ที่มีความคิดสร้างสรรค์เหล่านี้จะได้รับการตอบสนองที่ดีกว่าด้วยเวอร์ชันของ ChatGPT ที่มีหน่วยความจำยาวขึ้นและมีความยืดหยุ่นมากขึ้นเกี่ยวกับความรุนแรงในนิยายหรือธีมสำหรับผู้ใหญ่ (ในขอบเขตที่เหมาะสม) ตามที่นักเขียนนิยายคนหนึ่งกล่าวไว้ว่า เมื่อ AI สูญเสียการติดตามเรื่องราว *“ฉันต้องเตือนมันถึงรูปแบบหรือบริบทที่แน่นอน... ฉันรู้สึกหงุดหงิดที่มันยอดเยี่ยมเมื่อสองคำถามที่แล้ว แต่ตอนนี้ฉันต้องตาม AI ให้ทัน”*

- **ผู้ใช้พลังงานและผู้เชี่ยวชาญด้านโดเมน:** ผู้เชี่ยวชาญในสาขาเฉพาะทาง (**การเงิน**, **วิศวกรรม**, **การแพทย์**) บางครั้งพบว่าคำตอบของ ChatGPT ขาดความลึกหรือความแม่นยำในโดเมนของตน โดยเฉพาะอย่างยิ่งหากคำถามเกี่ยวข้องกับการพัฒนาล่าสุด ผู้ใช้เหล่านี้ต้องการความรู้จากผู้เชี่ยวชาญที่เชื่อถือได้มากขึ้น บางคนได้ลองปรับแต่งผ่าน API หรือ GPTs ที่กำหนดเอง ผู้ที่ไม่สามารถปรับแต่งได้จะชื่นชมเวอร์ชัน ChatGPT เฉพาะโดเมนหรือปลั๊กอินที่ฝังฐานข้อมูลที่เชื่อถือได้ ในรูปแบบเริ่มต้น ChatGPT อาจไม่ตอบสนองผู้ใช้ที่ต้องการข้อมูลเฉพาะด้านที่มีความแม่นยำสูง (พวกเขามักต้องตรวจสอบงานของมันอีกครั้ง)

- **ผู้ใช้ที่ต้องการเนื้อหาที่ไม่เซ็นเซอร์หรือกรณีขอบ:** ผู้ใช้ส่วนน้อย (แฮ็กเกอร์ที่ทดสอบสถานการณ์ความปลอดภัย นักเขียนนิยายสุดขั้ว ฯลฯ) พบว่าข้อจำกัดเนื้อหาของ ChatGPT จำกัดเกินไปสำหรับความต้องการของพวกเขา ปัจจุบันพวกเขาไม่ได้รับการตอบสนองจากผลิตภัณฑ์อย่างเป็นทางการ (เนื่องจากหลีกเลี่ยงเนื้อหาบางประเภทโดยชัดแจ้ง) ผู้ใช้เหล่านี้มักทดลองใช้คำถามเจลเบรกหรือใช้โมเดลโอเพ่นซอร์สเพื่อให้ได้คำตอบที่ต้องการ นี่เป็นช่องว่างโดยเจตนาสำหรับ OpenAI (เพื่อรักษาความปลอดภัย) แต่หมายความว่าผู้ใช้ดังกล่าวมองหาที่อื่น

- **บุคคลและองค์กรที่ใส่ใจเรื่องความเป็นส่วนตัว:** ผู้ใช้บางคน (โดยเฉพาะในองค์กร) ไม่สบายใจที่จะส่งข้อมูลที่ละเอียดอ่อนให้กับ ChatGPT เนื่องจากข้อกังวลด้านความเป็นส่วนตัว OpenAI มีนโยบายที่จะไม่ใช้ข้อมูล API เพื่อการฝึกอบรม แต่ UI เว็บของ ChatGPT ในอดีตไม่ได้ให้การรับประกันดังกล่าวจนกว่าจะมีฟีเจอร์ยกเลิกการเข้าร่วม บริษัทที่จัดการข้อมูลลับ (กฎหมาย การดูแลสุขภาพ ฯลฯ) มักรู้สึกว่าพวกเขาไม่สามารถใช้ประโยชน์จาก ChatGPT ได้อย่างเต็มที่ ทำให้ความต้องการของพวกเขาไม่ได้รับการตอบสนอง เว้นแต่พวกเขาจะสร้างโซลูชันที่โฮสต์เอง ตัวอย่างเช่น ผู้ใช้ Reddit รายหนึ่งกล่าวถึงบริษัทของตนที่เปลี่ยนไปใช้ LLM ในพื้นที่ด้วยเหตุผลด้านความเป็นส่วนตัว จนกว่าจะมีการใช้งาน ChatGPT ในสถานที่หรืออินสแตนซ์ส่วนตัว กลุ่มนี้ยังคงระมัดระวังหรือใช้ผู้ขายเฉพาะรายที่มีขนาดเล็กกว่า

### ความแตกต่างในการรับรู้ตามประเภทผู้ใช้

- **นักพัฒนา/ผู้ใช้ทางเทคนิค:** นักพัฒนามักจะเป็นทั้งผู้สนับสนุนที่ใหญ่ที่สุดและนักวิจารณ์ที่รุนแรงที่สุดของ ChatGPT พวกเขาชื่นชอบความสามารถในการอธิบายโค้ด สร้างโค้ดต้นแบบ และช่วยในการดีบัก อย่างไรก็ตาม พวกเขารู้สึกถึงข้อจำกัดในบริบทที่ยาวขึ้นและความแม่นยำของโค้ดอย่างมาก ตามที่นักพัฒนาคนหนึ่งบ่นว่า ChatGPT เริ่ม *“ผลิตโค้ดที่ไม่มีประโยชน์”* และละเว้นส่วนสำคัญ ซึ่ง *“ทำให้ฉันโกรธ... ฉันไม่ต้องการบอกมันว่า ‘อย่าขี้เกียจ’ – ฉันแค่ต้องการผลลัพธ์ทั้งหมด”* นักพัฒนามักสังเกตเห็นแม้กระทั่งการเปลี่ยนแปลงคุณภาพที่ละเอียดอ่อนหลังจากการอัปเดตโมเดลและได้แสดงความคิดเห็นอย่างมากใน Reddit เกี่ยวกับการรับรู้ “nerfs” หรือการลดลงของความสามารถในการเขียนโค้ด พวกเขายังผลักดันขีดจำกัด (สร้างคำถามที่ซับซ้อน เชื่อมโยงเครื่องมือ) ดังนั้นพวกเขาจึงต้องการฟีเจอร์เช่นบริบทที่ขยายออกไป ขีดจำกัดข้อความที่น้อยลง และการรวมเข้ากับเครื่องมือการเขียนโค้ดได้ดีขึ้น โดยสรุป นักพัฒนามองว่า ChatGPT เป็นเครื่องมือในการเร่งงานประจำ แต่พร้อมที่จะชี้ให้เห็นข้อผิดพลาดในตรรกะหรือโค้ด – พวกเขามองว่าเป็นผู้ช่วยระดับจูเนียร์ที่ยังต้องการการดูแล

- **ผู้ใช้ทั่วไป/ผู้ใช้ประจำวัน:** ผู้ใช้ทั่วไปมากขึ้น – ผู้ที่ถามหาความรู้ทั่วไป คำแนะนำ หรือความสนุก – มักจะทึ่งในความสามารถของ ChatGPT แต่พวกเขาก็มีปัญหาของตัวเอง ความหงุดหงิดทั่วไปของผู้ใช้ทั่วไปคือเมื่อ ChatGPT ปฏิเสธคำขอที่ดูเหมือนไม่มีพิษภัยสำหรับพวกเขา (อาจเป็นเพราะกฎนโยบาย) ผู้โพสต์ต้นฉบับในกระทู้หนึ่งเป็นตัวอย่างของสิ่งนี้ โดย *“โกรธมากเมื่อฉันเขียนคำถามที่มันไม่ควรมีปัญหาและตอนนี้มันปฏิเสธ”* ผู้ใช้ทั่วไปอาจเจอขีดจำกัดความรู้ (พบว่า bot ไม่สามารถจัดการกับเหตุการณ์ปัจจุบันมาก ๆ ได้เว้นแต่จะอัปเดตอย่างชัดเจน) และบางครั้งสังเกตเห็นเมื่อ ChatGPT ให้คำตอบที่ผิดอย่างชัดเจน ไม่เหมือนนักพัฒนา พวกเขาอาจไม่ตรวจสอบ AI ซ้ำเสมอ ซึ่งอาจนำไปสู่ความผิดหวังหากพวกเขาดำเนินการตามความผิดพลาด ในด้านบวก ผู้ใช้ทั่วไปจำนวนมากพบว่าการตอบสนองที่รวดเร็วของ ChatGPT Plus และผลลัพธ์ที่ดีขึ้นของ GPT-4 คุ้มค่ากับ $20/เดือน – เว้นแต่ปัญหา “การปฏิเสธ” หรือข้อจำกัดอื่น ๆ จะทำให้ประสบการณ์เสีย พวกเขาต้องการผู้ช่วยที่มีประโยชน์สำหรับทุกวัตถุประสงค์และอาจรู้สึกหงุดหงิดเมื่อ ChatGPT ตอบกลับด้วยคำแถลงนโยบายหรือจำเป็นต้องมีคำถามที่ซับซ้อนเพื่อให้ได้คำตอบง่าย ๆ

- **ผู้ใช้ธุรกิจ/ผู้ใช้มืออาชีพ:** ผู้ใช้ธุรกิจมักจะเข้าหา ChatGPT จากมุมมองของประสิทธิภาพและความน่าเชื่อถือ พวกเขาชื่นชมการร่างอีเมลอย่างรวดเร็ว สรุปเอกสาร หรือสร้างไอเดีย อย่างไรก็ตาม พวกเขากังวลเกี่ยวกับ **ความปลอดภัยของข้อมูล** ความสม่ำเสมอ และการรวมเข้ากับเวิร์กโฟลว์ ใน Reddit ผู้เชี่ยวชาญได้พูดคุยเกี่ยวกับการต้องการ ChatGPT ในเครื่องมือเช่น Outlook, Google Docs หรือเป็น API ในระบบภายในของพวกเขา บางคนสังเกตว่าเมื่อ OpenAI เปลี่ยนไปให้บริการลูกค้าองค์กร ดูเหมือนว่าจุดสนใจของผลิตภัณฑ์จะเปลี่ยนไป: มีความรู้สึกว่าประสบการณ์ของผู้ใช้ฟรีหรือรายบุคคลลดลงเล็กน้อย (เช่น ช้าลงหรือ “ฉลาดน้อยลง”) เมื่อบริษัทขยายขนาดเพื่อให้บริการลูกค้าที่ใหญ่ขึ้น ไม่ว่าจะจริงหรือไม่ มันเน้นการรับรู้: ผู้ใช้ธุรกิจต้องการความน่าเชื่อถือและบริการที่มีลำดับความสำคัญ และผู้ใช้รายบุคคลกังวลว่าตอนนี้พวกเขาเป็นชั้นสอง นอกจากนี้ ผู้เชี่ยวชาญต้องการผลลัพธ์ที่ถูกต้อง – คำตอบที่ฉูดฉาดแต่ผิดอาจแย่กว่าการไม่มีคำตอบ ดังนั้นกลุ่มนี้จึงมีความอ่อนไหวต่อความแม่นยำ สำหรับพวกเขา ฟีเจอร์เช่นบริบทที่ยาวขึ้น (สำหรับการอ่านสัญญา การวิเคราะห์ฐานโค้ด) และการรับประกันเวลาใช้งานเป็นสิ่งสำคัญ พวกเขามีแนวโน้มที่จะจ่ายเงินมากขึ้นสำหรับระดับการบริการระดับพรีเมียม หากข้อกำหนดด้านการปฏิบัติตามข้อกำหนดและความเป็นส่วนตัวของพวกเขาได้รับการตอบสนอง บางองค์กรถึงกับสำรวจการปรับใช้ในสถานที่หรือการใช้ API ของ OpenAI พร้อมกฎการจัดการข้อมูลที่เข้มงวดเพื่อตอบสนองนโยบาย IT ของพวกเขา

---

## Claude (Anthropic)

### ปัญหาและข้อจำกัดทั่วไป

- **ขีดจำกัดการใช้งานและข้อจำกัดการเข้าถึง:** Claude ได้รับคำชมสำหรับการเสนอโมเดลที่ทรงพลัง (Claude 2) ฟรี แต่ผู้ใช้พบขีดจำกัดการใช้งานอย่างรวดเร็ว (โดยเฉพาะในระดับฟรี) หลังจากจำนวนคำถามหรือข้อความจำนวนมาก Claude อาจหยุดและพูดบางอย่างเช่น *“ขอโทษ ฉันต้องจบบทสนทนานี้ชั่วคราว กรุณากลับมาใหม่ภายหลัง”* การจำกัดนี้ทำให้ผู้ใช้ที่ปฏิบัติต่อ Claude เป็นคู่หูในการเขียนโค้ดหรือการเขียนที่ขยายออกไปหงุดหงิด แม้แต่ผู้ใช้ Claude Pro (ที่ชำระเงิน) ก็ *“ไม่ได้รับการรับประกันเวลาที่ไม่จำกัด”* ตามที่ผู้ใช้คนหนึ่งกล่าวไว้ การเจอโควต้ายังคงสร้างข้อความ “กลับมาใหม่ภายหลัง” นอกจากนี้ Claude ยังถูกจำกัดภูมิศาสตร์อย่างเป็นทางการเป็นเวลานาน (ในตอนแรกมีให้บริการเฉพาะในสหรัฐอเมริกา/สหราชอาณาจักร) ผู้ใช้ต่างประเทศใน Reddit ต้องใช้ VPN หรือแพลตฟอร์มของบุคคลที่สามเพื่อเข้าถึง ซึ่งเป็นความไม่สะดวก สิ่งนี้ทำให้ผู้ใช้ที่ไม่ใช่ชาวสหรัฐฯ หลายคนรู้สึกถูกทิ้งจนกว่าจะมีการขยายการเข้าถึง

- **แนวโน้มที่จะออกนอกเส้นทางด้วยอินพุตที่ใหญ่มาก:** ฟีเจอร์พาดหัวของ Claude คือ *หน้าต่างบริบท 100k โทเค็น* ซึ่งอนุญาตให้มีคำถามที่ยาวมาก อย่างไรก็ตาม ผู้ใช้บางคนสังเกตว่าเมื่อคุณใส่โทเค็นหลายหมื่นเข้าไปใน Claude คำตอบของมันอาจกลายเป็นไม่โฟกัส *“100k มีประโยชน์มาก แต่ถ้ามันไม่ทำตามคำแนะนำอย่างถูกต้องและออกนอกเส้นทาง มันก็ไม่ค่อยมีประโยชน์”* ผู้ใช้คนหนึ่งกล่าว สิ่งนี้บ่งชี้ว่าในบริบทที่ใหญ่โต Claude อาจหลุดหรือเริ่มพูดเพ้อเจ้อ ต้องการคำถามที่ระมัดระวังเพื่อให้มันอยู่ในงาน เป็นข้อจำกัดที่เกิดจากการผลักดันบริบทไปสู่ขีดสุด – โมเดลยังคงรักษาไว้ได้มาก แต่บางครั้ง “ลืม” ว่ารายละเอียดใดมีความเกี่ยวข้องมากที่สุด นำไปสู่ภาพหลอนเล็กน้อยหรือการเบี่ยงเบนที่ไม่เกี่ยวข้อง

- **การจัดรูปแบบหรือการเชื่อฟังคำแนะนำที่ไม่สอดคล้องกัน:** ในการเปรียบเทียบแบบเคียงข้างกัน ผู้ใช้บางคนพบว่า Claude คาดเดาได้น้อยกว่าในวิธีที่มันทำตามคำสั่งบางอย่าง ตัวอย่างเช่น Claude ถูกอธิบายว่า *“มีลักษณะเหมือนมนุษย์มากกว่าในการโต้ตอบ แต่ปฏิบัติตามข้อความระบบน้อยกว่า”* ซึ่งหมายความว่าหากคุณให้รูปแบบคงที่หรือบุคลิกที่เข้มงวดมาก Claude อาจเบี่ยงเบนมากกว่า ChatGPT นักพัฒนาที่ต้องการผลลัพธ์ที่กำหนดได้ (เช่น รูปแบบ JSON หรือสไตล์เฉพาะ) บางครั้งรู้สึกหงุดหงิดหาก Claude เพิ่มคำอธิบายเพิ่มเติมหรือไม่ปฏิบัติตามเทมเพลตอย่างเคร่งครัด

- **ข้อจำกัดเนื้อหาและการปฏิเสธ:** แม้จะไม่ได้รับการวิพากษ์วิจารณ์บ่อยเท่ากับของ ChatGPT แต่ตัวกรองความปลอดภัยของ Claude ก็มีการพูดถึง Anthropic ออกแบบ Claude โดยเน้นหนักไปที่ AI ตามรัฐธรรมนูญ (ให้ AI เองปฏิบัติตามแนวทางจริยธรรม) ผู้ใช้มักพบว่า Claude ยินดีที่จะพูดคุยในหัวข้อที่หลากหลาย แต่มีบางกรณีที่ Claude ปฏิเสธคำขอที่ ChatGPT อาจอนุญาต ตัวอย่างเช่น ผู้ใช้ Reddit รายหนึ่งกล่าวว่า *“ChatGPT มีข้อจำกัดทางศีลธรรมน้อยกว่า... มันจะอธิบายว่าหน้ากากแก๊สชนิดใดดีกว่าสำหรับสภาวะใด ในขณะที่ Claude จะปฏิเสธ”* สิ่งนี้บ่งชี้ว่า Claude อาจเข้มงวดมากกว่าเกี่ยวกับคำแนะนำ “ที่ละเอียดอ่อน” บางอย่าง (อาจถือว่าเป็นคำแนะนำที่อาจเป็นอันตราย) ผู้ใช้อีกรายลองสถานการณ์เล่นบทบาทที่สนุกสนาน (“แกล้งทำเป็นว่าคุณถูกเอเลี่ยนลักพาตัว”) ซึ่ง Claude ปฏิเสธ ในขณะที่ Gemini และ ChatGPT จะมีส่วนร่วม ดังนั้น Claude จึงมีตัวกรองที่บางครั้งทำให้ผู้ใช้ประหลาดใจที่คาดหวังว่าจะอนุญาตมากกว่า

- **ขาดความสามารถหลายรูปแบบ:** ไม่เหมือนกับ ChatGPT (ซึ่งในช่วงปลายปี 2023 ได้รับความเข้าใจเกี่ยวกับภาพด้วย GPT-4 Vision) Claude ปัจจุบันเป็นเพียงข้อความเท่านั้น ผู้ใช้ Reddit สังเกตว่า Claude ไม่สามารถวิเคราะห์ภาพหรือท่องเว็บได้โดยตรงด้วยตัวเอง นี่ไม่ใช่ “ปัญหา” (Anthropic ไม่เคยโฆษณาฟีเจอร์เหล่านั้น) แต่มันเป็นข้อจำกัดเมื่อเทียบกับคู่แข่ง ผู้ใช้ที่ต้องการ AI เพื่อแปลความหมายของไดอะแกรมหรือภาพหน้าจอไม่สามารถใช้ Claude ได้ ในขณะที่ ChatGPT หรือ Gemini อาจจัดการได้ ในทำนองเดียวกัน การดึงข้อมูลปัจจุบันใด ๆ ต้องใช้ Claude ผ่านเครื่องมือของบุคคลที่สาม (เช่น Poe หรือการรวมเครื่องมือค้นหา) เนื่องจาก Claude ไม่มีโหมดการท่องเว็บอย่างเป็นทางการในขณะนี้

- **ปัญหาความเสถียรเล็กน้อย:** ผู้ใช้บางคนรายงานว่า Claude บางครั้งซ้ำซากหรือวนซ้ำในคำถามบางอย่าง (แม้ว่าจะพบได้น้อยกว่าบางโมเดลที่เล็กกว่า) นอกจากนี้ เวอร์ชันก่อนหน้าของ Claude บางครั้งสิ้นสุดการตอบสนองก่อนกำหนดหรือต้องใช้เวลานานกับผลลัพธ์ขนาดใหญ่ ซึ่งอาจถูกมองว่าเป็นความรำคาญเล็กน้อย แม้ว่า Claude 2 จะปรับปรุงเรื่องความเร็วแล้ว

### ฟีเจอร์หรือการปรับปรุงที่ร้องขอบ่อย

- **ขีดจำกัดการใช้งานที่สูงขึ้นหรือปรับได้:** ผู้ที่ชื่นชอบ Claude ใน Reddit มักขอให้ Anthropic เพิ่มขีดจำกัดการสนทนา พวกเขาต้องการใช้บริบท 100k ให้เต็มที่โดยไม่เจอการหยุดที่ไม่จำเป็น บางคนแนะนำว่าควรให้ Claude Pro ที่ชำระเงินอนุญาตให้ใช้โทเค็นได้มากขึ้น *อย่างมาก* ต่อวัน คนอื่น ๆ เสนอแนวคิดของ “โหมดบริบท 100k ที่ขยายออกไป” – เช่น *“Claude ควรมีโหมดบริบท 100k ที่มีขีดจำกัดการใช้งานเพิ่มขึ้นเป็นสองเท่า”* – ซึ่งอาจมีการสมัครสมาชิกที่ให้การเข้าถึงที่ขยายออกไปสำหรับผู้ใช้หนัก โดยสรุป มีความต้องการแผนที่แข่งขันกับการใช้งานไม่จำกัด (หรือขีดจำกัดสูง) ของ ChatGPT สำหรับสมาชิก

- **การนำทางบริบทยาวที่ดีขึ้น:** ในขณะที่มีโทเค็น 100k เป็นการบุกเบิก ผู้ใช้ต้องการให้ Claude ใช้บริบทนั้นได้ดีขึ้น การปรับปรุงอย่างหนึ่งคือการปรับปรุงวิธีที่ Claude จัดลำดับความสำคัญของข้อมูลเพื่อให้มันอยู่ในเส้นทาง Anthropic สามารถทำงานเกี่ยวกับการปฏิบัติตามคำถามของโมเดลเมื่อคำถามมีขนาดใหญ่ การสนทนาใน Reddit แนะนำเทคนิคเช่นการอนุญาตให้ผู้ใช้ “ปักหมุด” คำแนะนำบางอย่างเพื่อไม่ให้ถูกเจือจางในบริบทขนาดใหญ่ เครื่องมือใด ๆ ที่ช่วยแบ่งส่วนหรือสรุปส่วนต่าง ๆ ของอินพุตก็สามารถช่วยให้ Claude จัดการกับอินพุตขนาดใหญ่ได้อย่างสอดคล้องกัน โดยสรุป ผู้ใช้ชื่นชอบความเป็นไปได้ในการป้อนหนังสือทั้งเล่มให้กับ Claude – พวกเขาแค่ต้องการให้มันเฉียบคมตลอด

- **ปลั๊กอินหรือการท่องเว็บ:** ผู้ใช้ ChatGPT จำนวนมากคุ้นเคยกับปลั๊กอิน (เช่น การท่องเว็บ การดำเนินการโค้ด ฯลฯ) และพวกเขาแสดงความสนใจใน Claude ที่มีความสามารถในการขยายตัวคล้ายกัน คำขอทั่วไปคือให้ Claude มีฟังก์ชันการค้นหา/การท่องเว็บอย่างเป็นทางการ เพื่อให้สามารถดึงข้อมูลที่ทันสมัยได้ตามต้องการ ปัจจุบันความรู้ของ Claude ส่วนใหญ่เป็นแบบคงที่ (ข้อมูลการฝึกอบรมจนถึงต้นปี 2023 โดยมีการอัปเดตบางส่วน) หาก Claude สามารถค้นหาเว็บได้ ก็จะบรรเทาข้อจำกัดนั้นได้ ในทำนองเดียวกัน ระบบปลั๊กอินที่ Claude สามารถใช้เครื่องมือของบุคคลที่สาม (เช่น เครื่องคิดเลขหรือตัวเชื่อมต่อฐานข้อมูล) สามารถขยายประโยชน์ใช้สอยสำหรับผู้ใช้พลังงานได้ นี่เป็นฟีเจอร์ที่ Claude ขาด และผู้ใช้ Reddit มักพูดถึงว่าอีโคซิสเต็มของปลั๊กอินของ ChatGPT ทำให้มันได้เปรียบในงานบางอย่าง

- **อินพุตหลายรูปแบบ (ภาพหรือเสียง):** ผู้ใช้บางคนสงสัยว่า Claude จะรองรับอินพุตภาพหรือสร้างภาพหรือไม่ Google’s Gemini และ OpenAI’s GPT-4 มีความสามารถหลายรูปแบบ ดังนั้นเพื่อให้สามารถแข่งขันได้ ผู้ใช้คาดหวังว่า Anthropic จะสำรวจสิ่งนี้ คำขอบ่อย ๆ คือ: *“ฉันสามารถอัปโหลด PDF หรือภาพให้ Claude วิเคราะห์ได้ไหม?”* ปัจจุบันคำตอบคือไม่ (นอกเหนือจากการแก้ปัญหาเช่นการแปลงภาพเป็นข้อความที่อื่น) แม้แต่การอนุญาตให้แปลงภาพเป็นข้อความ (OCR และคำอธิบาย) ก็จะทำให้หลายคนพอใจที่ต้องการผู้ช่วยครบวงจร นี่อยู่ในรายการความปรารถนา แม้ว่า Anthropic จะยังไม่ได้ประกาศอะไรที่คล้ายกันในต้นปี 2025

- **การปรับแต่งหรือการปรับแต่ง:** ผู้ใช้ขั้นสูงและธุรกิจบางครั้งถามว่าพวกเขาสามารถปรับแต่ง Claude บนข้อมูลของตนเองหรือรับเวอร์ชันที่กำหนดเองได้หรือไม่ OpenAI เสนอการปรับแต่งสำหรับโมเดลบางตัว (ยังไม่ใช่ GPT-4 แต่สำหรับ GPT-3.5) Anthropic เปิดตัวอินเทอร์เฟซการปรับแต่งสำหรับ Claude 1.3 ก่อนหน้านี้ แต่ไม่ได้โฆษณาอย่างกว้างขวางสำหรับ Claude 2 ผู้ใช้ Reddit ได้สอบถามเกี่ยวกับความสามารถในการฝึก Claude บนความรู้ของบริษัทหรือสไตล์การเขียนส่วนตัว วิธีที่ง่ายกว่าในการทำเช่นนี้ (นอกเหนือจากการฉีดคำถามทุกครั้ง) จะเป็นที่ต้อนรับอย่างมาก เนื่องจากสามารถเปลี่ยน Claude ให้เป็นผู้ช่วยส่วนบุคคลที่จดจำฐานความรู้หรือบุคลิกเฉพาะได้

- **การเข้าถึงที่กว้างขึ้น:** ผู้ใช้ที่ไม่ใช่ชาวสหรัฐฯ มักขอให้ Claude เปิดตัวอย่างเป็นทางการในประเทศของตน โพสต์จากแคนาดา ยุโรป อินเดีย ฯลฯ ถามว่าพวกเขาสามารถใช้เว็บไซต์ของ Claude ได้เมื่อใดโดยไม่ต้องใช้ VPN หรือเมื่อ Claude API จะเปิดให้บริการอย่างกว้างขวางมากขึ้น Anthropic ระมัดระวัง แต่ความต้องการเป็นสากล – การปรับปรุงในสายตาของหลายคนคือเพียงแค่ “ให้พวกเรามากขึ้นใช้มัน” การขยายการเข้าถึงของบริษัทอย่างค่อยเป็นค่อยไปได้แก้ไขปัญหานี้บางส่วนแล้ว

### ความต้องการหรือกลุ่มผู้ใช้ที่ยังไม่ได้รับการตอบสนอง

- **ฐานผู้ใช้ระหว่างประเทศ:** ดังที่ได้กล่าวไว้เป็นเวลานาน ฐานผู้ใช้หลักของ Claude ถูกจำกัดตามภูมิศาสตร์ สิ่งนี้ทำให้ผู้ใช้ที่ *อาจจะ* จำนวนมากไม่ได้รับการตอบสนอง ตัวอย่างเช่น นักพัฒนาในเยอรมนีที่สนใจบริบท 100k ของ Claude ไม่มีวิธีการใช้อย่างเป็นทางการ แม้ว่าจะมีวิธีแก้ปัญหา (แพลตฟอร์มของบุคคลที่สาม หรือ VPN + การยืนยันโทรศัพท์ในประเทศที่รองรับ) อุปสรรคเหล่านี้หมายความว่าผู้ใช้ทั่วไปในต่างประเทศถูกล็อกออกไปอย่างมีประสิทธิภาพ ในทางตรงกันข้าม ChatGPT มีให้บริการในประเทศส่วนใหญ่ ดังนั้นผู้ใช้ที่ไม่ใช่ชาวสหรัฐฯ ที่พูดภาษาอังกฤษและโดยเฉพาะอย่างยิ่งผู้ที่ไม่พูดภาษาอังกฤษจึงไม่ได้รับการตอบสนองจากการเปิดตัวที่จำกัดของ Claude พวกเขาอาจยังคงพึ่งพา ChatGPT หรือโมเดลท้องถิ่นเพียงเพราะปัญหาการเข้าถึง

- **ผู้ใช้ที่ต้องการการจัดรูปแบบผลลัพธ์ที่เข้มงวด:** ดังที่ได้กล่าวไว้ Claude บางครั้งใช้เสรีภาพในการตอบกลับ ผู้ใช้ที่ต้องการผลลัพธ์ที่มีโครงสร้างสูง (เช่น JSON สำหรับแอปพลิเคชัน หรือคำตอบที่เป็นไปตามรูปแบบที่แม่นยำ) อาจพบว่า Claude ไม่น่าเชื่อถือสำหรับสิ่งนั้นเท่ากับ ChatGPT ผู้ใช้เหล่านี้ – มักเป็นนักพัฒนาที่รวม AI เข้ากับระบบ – เป็นกลุ่มที่สามารถให้บริการได้ดีขึ้นหาก Claude อนุญาตให้มี “โหมดเข้มงวด” หรือปรับปรุงการปฏิบัติตามคำแนะนำ พวกเขาอาจหลีกเลี่ยง Claude สำหรับงานดังกล่าว โดยยึดติดกับโมเดลที่รู้จักกันดีว่าปฏิบัติตามรูปแบบอย่างเคร่งครัดมากขึ้น

- **ผู้ใช้ Q&A ทั่วไป (เทียบกับผู้ใช้ที่มีความคิดสร้างสรรค์):** Claude มักได้รับการยกย่องในงานสร้างสรรค์ – มันผลิตร้อยแก้วที่ลื่นไหลเหมือนมนุษย์และเรียงความที่รอบคอบ อย่างไรก็ตาม ผู้ใช้บางคนใน Reddit ตั้งข้อสังเกตว่าสำหรับการถามตอบอย่างตรงไปตรงมาหรือคำถามตามข้อเท็จจริง Claude บางครั้งให้คำตอบที่ยืดยาวซึ่งความกระชับจะทำได้ ผู้ใช้ที่เปรียบเทียบ ChatGPT และ Claude กล่าวว่า ChatGPT มักจะกระชับและเป็นหัวข้อย่อย ในขณะที่ Claude ให้คำบรรยายมากกว่าโดยค่าเริ่มต้น ผู้ใช้ที่ต้องการเพียงคำตอบตามข้อเท็จจริงอย่างรวดเร็ว (เช่น “เมืองหลวงของ X และประชากรของเมืองคืออะไร?”) อาจรู้สึกว่า Claude ค่อนข้างอ้อมค้อม ผู้ใช้เหล่านี้ได้รับการตอบสนองที่ดีกว่าด้วยสิ่งที่คล้ายกับการค้นหาที่แม่นยำหรือโมเดลที่กระชับ Claude สามารถทำได้หากถูกถาม แต่สไตล์ของมันอาจไม่ตรงกับความคาดหวังของการถามตอบที่กระชับ หมายความว่ากลุ่มนี้อาจเปลี่ยนไปใช้เครื่องมืออื่น (เช่น Bing Chat หรือ Google)

- **ผู้ใช้ที่มีความปลอดภัยเป็นสำคัญ:** ในทางกลับกัน ผู้ใช้บางคนที่ *ต้องการ* การปฏิบัติตามความปลอดภัยอย่างระมัดระวังมาก (เช่น นักการศึกษาที่ใช้ AI กับนักเรียน หรือผู้ใช้ระดับองค์กรที่ต้องการความเสี่ยงเป็นศูนย์ของผลลัพธ์ที่ไม่ดี) อาจพิจารณาว่าการจัดแนวของ Claude เป็นข้อดี แต่เนื่องจาก ChatGPT ก็มีการจัดแนวค่อนข้างดีเช่นกันและมีฟีเจอร์ระดับองค์กรมากกว่า ผู้ใช้เหล่านั้นอาจไม่เลือก Claude โดยเฉพาะ เป็นกลุ่มเล็ก ๆ แต่สามารถโต้แย้งได้ว่า Claude ยังไม่ได้จับกลุ่มนี้อย่างชัดเจน พวกเขาอาจไม่ได้รับการตอบสนองในแง่ที่ว่าพวกเขาไม่มีวิธีง่าย ๆ ในการ *เพิ่ม* มาตรการป้องกันของ Claude หรือดู “ห่วงโซ่ความคิด” (ซึ่ง Anthropic มีภายในผ่านแนวทาง AI ตามรัฐธรรมนูญ แต่ผู้ใช้ปลายทางไม่โต้ตอบโดยตรงกับสิ่งนั้นนอกจากสังเกตเห็นโทนที่สุภาพโดยทั่วไปของ Claude)

- **ผู้ที่ไม่พูดภาษาอังกฤษ (คุณภาพของผลลัพธ์):** Claude ได้รับการฝึกฝนในภาษาอังกฤษเป็นหลัก (เช่นเดียวกับ LLM ขนาดใหญ่ส่วนใหญ่) ผู้ใช้บางคนได้ทดสอบในภาษาอื่น ๆ Claude สามารถตอบกลับได้หลายภาษา แต่คุณภาพอาจแตกต่างกันไป หากผู้ใช้ต้องการคำตอบที่ละเอียดอ่อนมากในภาษาฝรั่งเศสหรือภาษาฮินดี เป็นไปได้ว่าความสามารถของ Claude อาจไม่ได้รับการปรับแต่งอย่างละเอียดในที่นั้นเท่ากับ ChatGPT (GPT-4 ได้แสดงให้เห็นถึงประสิทธิภาพหลายภาษาที่แข็งแกร่ง มักจะสูงกว่าโมเดลอื่น ๆ ในเกณฑ์มาตรฐานบางอย่าง) ผู้ใช้ที่สนทนาในภาษาที่ไม่ใช่ภาษาอังกฤษเป็นหลักอาจพบว่าความคล่องแคล่วหรือความแม่นยำของ Claude อ่อนแอกว่าเล็กน้อย กลุ่มนี้ไม่ได้รับการตอบสนองเพียงเพราะ Anthropic ยังไม่ได้เน้นการฝึกอบรมหลายภาษาเป็นลำดับความสำคัญอย่างเปิดเผย

### ความแตกต่างในการรับรู้ตามประเภทผู้ใช้

- **นักพัฒนา/ผู้ใช้ทางเทคนิค:** นักพัฒนาใน Reddit ได้ยกย่อง Claude มากขึ้นเรื่อย ๆ โดยเฉพาะอย่างยิ่ง Claude 2 / Claude 3.5 สำหรับงานการเขียนโค้ด การเปลี่ยนแปลงการรับรู้ในปลายปี 2024 นั้นเห็นได้ชัด: นักพัฒนาหลายคนเริ่มชอบ Claude มากกว่า ChatGPT สำหรับความช่วยเหลือด้านการเขียนโปรแกรม พวกเขาอ้างถึง *“ยอดเยี่ยมในการเขียนโค้ด”* และความสามารถในการจัดการฐานโค้ดขนาดใหญ่ในครั้งเดียว ตัวอย่างเช่น ผู้ใช้คนหนึ่งเขียนว่า *“Claude Sonnet 3.5 ดีกว่าที่จะทำงานกับโค้ด (วิเคราะห์ สร้าง) [มากกว่า ChatGPT]”* นักพัฒนาชื่นชมที่ Claude สามารถใช้โค้ดโปรเจ็กต์หรือบันทึกจำนวนมากและสร้างการวิเคราะห์หรือการปรับปรุงที่สอดคล้องกันได้ ต้องขอบคุณบริบทขนาดใหญ่ของมัน อย่างไรก็ตาม พวกเขายังสังเกตเห็นความแปลกประหลาดของมัน – เช่น บางครั้งการใส่คำพูดที่ฟุ่มเฟือยมากขึ้นหรือไม่ปฏิบัติตามข้อกำหนดอย่างเคร่งครัด โดยรวมแล้ว นักพัฒนาหลายคนเก็บทั้ง ChatGPT และ Claude ไว้ในมือ: หนึ่งสำหรับตรรกะทีละขั้นตอนที่เข้มงวด (ChatGPT) และหนึ่งสำหรับบริบทกว้างและความเข้าใจที่เห็นอกเห็นใจ (Claude) เป็นเรื่องที่บอกได้ว่าผู้แสดงความคิดเห็นกล่าวว่า *“ถ้าฉันต้องเลือกหนึ่ง ฉันจะเลือก Claude”* หลังจากเปรียบเทียบทั้งสองทุกวัน สิ่งนี้บ่งชี้ถึงการรับรู้ในเชิงบวกมากในหมู่ผู้ใช้ขั้นสูง โดยเฉพาะอย่างยิ่งสำหรับกรณีการใช้งานเช่นการระดมสมอง การตรวจสอบโค้ด หรือข้อเสนอแนะด้านสถาปัตยกรรม ข้อร้องเรียนทั่วไปเพียงอย่างเดียวจากนักพัฒนาคือการเจอขีดจำกัดการใช้งานของ Claude เมื่อพวกเขาพยายามผลักดันมันอย่างหนัก (เช่น ป้อนคำถาม 50K โทเค็นเพื่อวิเคราะห์ที่เก็บทั้งหมด) โดยสรุป นักพัฒนามองว่า Claude เป็นเครื่องมือที่ทรงพลังมาก – ในบางกรณีดีกว่า ChatGPT – ถูกจำกัดเพียงการเข้าถึงและความคาดเดาไม่ได้ในบางครั้งในการจัดรูปแบบ

- **ผู้ใช้ทั่วไป/ผู้ใช้ที่ไม่ใช่เทคนิค:** ผู้ใช้ทั่วไปที่ได้ลอง Claude มักแสดงความคิดเห็นว่า *เป็นมิตรและมีวาทศิลป์* Claude มีแนวโน้มที่จะเป็นการสนทนา สุภาพ และมีรายละเอียด ผู้ใช้ใหม่ที่เปรียบเทียบกับ ChatGPT สังเกตว่า *“Claude มีความเห็นอกเห็นใจมากกว่า และทำตามโทนการสนทนา... ChatGPT มักจะใช้หัวข้อย่อยบ่อยเกินไป”* ความอบอุ่นเหมือนมนุษย์นี้ทำให้ Claude น่าสนใจสำหรับผู้ที่ใช้มันเพื่อการเขียนเชิงสร้างสรรค์ คำแนะนำ หรือเพียงแค่พูดคุยเพื่อข้อมูล บางคนถึงกับทำให้ Claude มี “บุคลิก” ที่เห็นอกเห็นใจ ผู้ใช้ทั่วไปยังชอบที่เวอร์ชันฟรีของ Claude อนุญาตให้เข้าถึงเทียบเท่ากับระดับ GPT-4 โดยไม่ต้องสมัครสมาชิก (อย่างน้อยก็จนถึงขีดจำกัดอัตรา) ในทางกลับกัน ผู้ใช้ทั่วไปเจอการปฏิเสธของ Claude ในหัวข้อบางอย่างและอาจไม่เข้าใจว่าทำไม (เนื่องจาก Claude จะพูดอย่างขอโทษแต่หนักแน่น) หากผู้ใช้ทั่วไปถามบางอย่างที่อยู่ในขอบเขตและได้รับการปฏิเสธจาก Claude พวกเขาอาจมองว่ามันมีความสามารถน้อยกว่าหรือถูกจำกัดเกินไป โดยไม่รู้ว่ามันเป็นจุดยืนของนโยบาย อีกแง่มุมหนึ่งคือ Claude ขาดการรับรู้ชื่อ – ผู้ใช้ทั่วไปหลายคนอาจไม่รู้ด้วยซ้ำว่าจะลองใช้มันหรือไม่เว้นแต่พวกเขาจะเชื่อมต่อกับชุมชน AI ผู้ที่ลองใช้มักจะแสดงความคิดเห็นว่ามันรู้สึก *“เหมือนคุยกับมนุษย์”* ในทางที่ดี พวกเขามักจะพอใจกับความสามารถของ Claude ในการจัดการคำถามปลายเปิดหรือคำถามส่วนตัว ดังนั้นการรับรู้ของผู้ใช้ทั่วไปจึงเป็นไปในเชิงบวกอย่างมากเกี่ยวกับ *คุณภาพและโทนของผลลัพธ์* ของ Claude โดยมีความสับสนหรือความหงุดหงิดบางประการเกี่ยวกับความพร้อมใช้งาน (ต้องใช้ในแอปเฉพาะหรือภูมิภาค) และบางครั้ง “ทำไม่ได้” ช่วงเวลา

- **ผู้ใช้ธุรกิจ/ผู้ใช้มืออาชีพ:** การรับรู้ของธุรกิจเกี่ยวกับ Claude นั้นยากที่จะวัดจาก Reddit สาธารณะ (เนื่องจากผู้ใช้ระดับองค์กรโพสต์รายละเอียดน้อยกว่า) แต่มีแนวโน้มบางอย่างเกิดขึ้น ประการแรก Anthropic ได้วางตำแหน่ง Claude ให้มีความ *มุ่งเน้นด้านความเป็นส่วนตัว* มากขึ้นและเต็มใจที่จะลงนามในข้อตกลงระดับองค์กร – สิ่งนี้ดึงดูดบริษัทที่กังวลเกี่ยวกับข้อมูลกับ OpenAI จริง ๆ แล้ว การสนทนาใน Reddit บางรายการกล่าวถึง Claude ในบริบทของเครื่องมือเช่น Slack หรือ Notion ซึ่งมันถูกรวมเป็นผู้ช่วย ผู้เชี่ยวชาญที่ใช้การผสานรวมเหล่านั้นอาจไม่รู้ด้วยซ้ำว่า Claude เป็นเครื่องยนต์ แต่เมื่อพวกเขาทำ พวกเขาจะเปรียบเทียบในแง่ดีในแง่ของสไตล์การเขียนและความสามารถในการย่อยเอกสารขององค์กรขนาดใหญ่ ตัวอย่างเช่น ทีมอาจป้อนรายงานรายไตรมาสที่ยาวให้กับ Claude และได้รับสรุปที่เหมาะสม – สิ่งที่บริบทที่เล็กกว่าของ ChatGPT จะลำบาก อย่างไรก็ตาม ผู้ใช้ธุรกิจยังสังเกตเห็นการขาดฟีเจอร์ของอีโคซิสเต็มบางอย่าง ตัวอย่างเช่น OpenAI เสนอการควบคุมข้อความระบบ การเรียกฟังก์ชัน ฯลฯ ใน API ของพวกเขา ซึ่ง Anthropic มีการสนับสนุนที่จำกัดมากกว่า นักพัฒนาที่ทำงานเกี่ยวกับโซลูชันทางธุรกิจกล่าวว่า *Claude สามารถควบคุมได้มากกว่าในการสนทนา ในขณะที่ ChatGPT มักจะเข้มงวดกว่า... [แต่] ChatGPT สามารถเข้าถึงเว็บได้ซึ่งอาจมีประโยชน์มาก* ความหมายคือสำหรับงานวิจัยหรือการค้นหาข้อมูลที่ผู้ใช้ธุรกิจอาจต้องการ (เช่น ข่าวกรองการแข่งขัน) ChatGPT สามารถดึงข้อมูลได้โดยตรง ในขณะที่ Claude จะต้องมีขั้นตอนแยกต่างหาก โดยรวมแล้ว ผู้ใช้ธุรกิจดู Claude เป็น AI ที่มีความสามารถมาก – ในบางกรณี *ดีกว่า* สำหรับงานวิเคราะห์ภายใน – แต่บางทีอาจยังไม่สมบูรณ์เท่าสำหรับการรวมเข้าด้วยกัน ค่าใช้จ่ายเป็นอีกปัจจัยหนึ่ง: การกำหนดราคาและเงื่อนไขของ API ของ Claude ไม่เป็นสาธารณะเท่ากับของ OpenAI และสตาร์ทอัพบางรายใน Reddit ได้กล่าวถึงความไม่แน่นอนเกี่ยวกับการกำหนดราคาหรือความเสถียรของ Claude โดยสรุป ผู้เชี่ยวชาญเคารพความสามารถของ Claude (โดยเฉพาะความน่าเชื่อถือในการปฏิบัติตามคำแนะนำระดับสูงและสรุปข้อมูลขนาดใหญ่) แต่พวกเขาจับตาดูว่ามันพัฒนาอย่างไรในแง่ของการรวม การสนับสนุน และความพร้อมใช้งานทั่วโลกก่อนที่จะมุ่งมั่นอย่างเต็มที่กับมันมากกว่า ChatGPT ที่เป็นที่ยอมรับมากกว่า

---

## Google Gemini (Bard)

### ปัญหาและข้อจำกัดทั่วไป

- **คำตอบที่ไม่ถูกต้องหรือ “โง่”:** มีความคิดเห็นใน Reddit จำนวนมากเมื่อ Google เปิดตัวการอัปเกรด Bard ที่ขับเคลื่อนด้วย Gemini ซึ่งส่วนใหญ่เป็นเชิงลบ ผู้ใช้บ่นว่า Gemini **ทำงานได้ต่ำกว่ามาตรฐานในการถามตอบพื้นฐาน** เมื่อเทียบกับ ChatGPT การประเมินที่ตรงไปตรงมาชื่อ “100% Honest Take on Google Gemini” ระบุว่า: *“มันเป็นแชทบอท LLM ที่เสียหายและไม่ถูกต้อง”* ผู้ใช้ที่หงุดหงิดอีกคนถามว่า: *“Gemini ยังแย่อยู่ได้อย่างไร? จำนวนครั้งที่ฉันถาม Gemini บางอย่างและมันให้คำตอบที่ไม่ถูกต้องหรือคำตอบที่ไม่สมบูรณ์นั้นน่าหัวเราะ”* พวกเขาเปรียบเทียบแบบเคียงข้างกันกับ ChatGPT-4 และพบว่า ChatGPT ให้ *“คำตอบที่สมบูรณ์แบบ ถูกต้อง มีประสิทธิภาพในครั้งเดียว”* ในขณะที่ Gemini พูดเพ้อเจ้อและต้องการคำถามหลายคำถามเพื่อให้ได้คำตอบที่พอใจครึ่งหนึ่ง โดยสรุป ผู้ใช้ในช่วงแรก ๆ รู้สึกว่า Gemini มัก **หลงประเด็นหรือพลาดประเด็น** ของคำถาม ต้องใช้ความพยายามในการถามคำถามมากเกินไปเพื่อดึงข้อมูลที่ถูกต้อง ความไม่สอดคล้องกันในคุณภาพนี้เป็นความผิดหวังครั้งใหญ่เมื่อพิจารณาจากความคาดหวังเกี่ยวกับ Gemini

- **ความยาวและความฟุ่มเฟือยเกินไป:** ผู้ใช้หลายคนสังเกตว่า Gemini (ในรูปแบบของ Bard ใหม่) มีแนวโน้มที่จะสร้างคำตอบที่ยืดยาวซึ่งไม่ตรงประเด็น ตามที่คนหนึ่งอธิบายว่า *“มันพูดเพ้อเจ้อ... 3 ย่อหน้าของขยะ AI... แม้กระทั่งตอนนั้น มัน [เพียง] กล่าวถึงคำตอบในย่อหน้าของขยะ”* นี่เป็นความแตกต่างอย่างชัดเจนกับ ChatGPT ซึ่งมักจะให้คำตอบที่กระชับกว่าหรือเป็นหัวข้อย่อยเมื่อเหมาะสม ความยาวกลายเป็นปัญหาเมื่อผู้ใช้ต้องคัดกรองข้อความจำนวนมากเพื่อหาข้อเท็จจริงง่าย ๆ บางคนคาดเดาว่า Google อาจปรับแต่งให้เป็นการสนทนาหรือ “ช่วยเหลือ” แต่เกินไปใน *การอธิบายมากเกินไปโดยไม่มีสาระสำคัญ*

- **การรวมเข้ากับบริการของ Google ที่ไม่ดี:** หนึ่งในจุดขายของผู้ช่วย AI ของ Google ควรจะเป็นการรวมเข้ากับอีโคซิสเต็มของ Google (Gmail, Docs, Drive ฯลฯ) อย่างไรก็ตาม ประสบการณ์ของผู้ใช้ในช่วงแรก ๆ นั้นน่าผิดหวังมากในด้านนี้ ผู้ใช้คนหนึ่งระบายว่า: *“อย่าให้ฉันเริ่มเกี่ยวกับความสามารถในการรวมเข้ากับผลิตภัณฑ์ของ Google เองที่เกือบจะไม่มีอยู่จริงซึ่งควรจะเป็น ‘ฟีเจอร์’ (ซึ่งมันดูเหมือนจะไม่รู้ว่ามี)”* ตัวอย่างเช่น ผู้คนจะลองขอให้ Gemini (ผ่าน Bard) สรุป Google Doc หรือร่างอีเมลตามข้อมูลบางอย่าง – ฟีเจอร์ที่ Google โฆษณา – และบอทจะตอบว่ามัน **ไม่สามารถเข้าถึงข้อมูลนั้นได้** ผู้ใช้คนหนึ่งใน r/GooglePixel เขียนว่า: *“ทุกครั้งที่ฉันพยายามใช้ Gemini กับ Google Docs หรือ Drive ของฉัน มันบอกว่ามันไม่สามารถทำอะไรกับมันได้ จุดประสงค์ของการมีฟีเจอร์การรวมเหล่านี้คืออะไร?”* สิ่งนี้แสดงให้เห็นถึงช่องว่างที่สำคัญระหว่างความสามารถที่สัญญาไว้และประสิทธิภาพจริง ทำให้ผู้ใช้รู้สึกว่าผู้ช่วย AI “ไม่ช่วยเหลือ” มากนักในอีโคซิสเต็มของ Google เอง

- **การปฏิเสธและความสับสนในความสามารถ:** ผู้ใช้ยังเจอการปฏิเสธหรือความขัดแย้งที่แปลกประหลาดจาก Gemini ผู้ใช้ Redditor คนเดียวกันสังเกตว่า Gemini *“ปฏิเสธที่จะทำสิ่งต่าง ๆ โดยไม่มีเหตุผล ลืมว่ามันสามารถทำสิ่งอื่น ๆ ได้... วันก่อนมันบอกฉันว่ามันไม่มีการเข้าถึงอินเทอร์เน็ต/ข้อมูลสด อะไรนะ”* สิ่งนี้บ่งชี้ว่า Gemini บางครั้ง **ปฏิเสธงานที่มันควรจะทำได้** (เช่น การดึงข้อมูลสด ซึ่ง Bard เชื่อมต่ออยู่) หรือให้คำแถลงที่ไม่ถูกต้องเกี่ยวกับความสามารถของตัวเอง ประสบการณ์ดังกล่าวทำให้เกิดความประทับใจของ AI ที่ไม่เพียงแค่ฉลาดน้อยกว่า แต่ยัง **ไม่น่าเชื่อถือหรือไม่ตระหนักรู้ในตัวเอง** อีกด้วย ความคิดเห็นที่มีสีสันของผู้ใช้อีกราย: *“Gemini เป็นขยะอย่างแท้จริง คุณเคยมีช่วงเวลาที่คุณแค่อยากจะยกมือขึ้นและพูดว่า ‘พวกเขาคิดอะไรอยู่?’”* สรุปคือ ปัญหาการรวมผลิตภัณฑ์และความสม่ำเสมอของ Gemini ทำให้มันรู้สึก *ยังไม่เสร็จสมบูรณ์* สำหรับผู้ใช้ในช่วงแรก ๆ หลายคน

- **ความสามารถในการเขียนโค้ดที่ไม่น่าประทับใจ:** แม้จะไม่ได้มีการพูดถึงอย่างกว้างขวางเท่ากับการถามตอบทั่วไป ผู้ใช้หลายคนได้ทดสอบ Gemini (Bard) ในงานการเขียนโค้ดและพบว่ามันด้อยกว่า ในฟอรัม AI ความสามารถในการเขียนโค้ดของ Gemini มักถูกจัดอันดับต่ำกว่า GPT-4 และแม้แต่ต่ำกว่า Claude ตัวอย่างเช่น ผู้ใช้คนหนึ่งระบุอย่างตรงไปตรงมาว่า *“Claude 3.5 Sonnet ดีกว่าอย่างชัดเจนสำหรับการเขียนโค้ดมากกว่า ChatGPT 4o... Gemini เป็นขยะอย่างแท้จริง [ในบริบทนั้น]”* ข้อสรุปคือ Gemini สามารถเขียนโค้ดง่าย ๆ หรืออธิบายอัลกอริธึมพื้นฐานได้ แต่บ่อยครั้งที่มันสะดุดในปัญหาที่ซับซ้อนกว่าหรือสร้างโค้ดที่มีข้อผิดพลาด การขาดชุดเครื่องมือสำหรับนักพัฒนาที่กว้างขวาง (เช่น มันไม่มีสิ่งที่เทียบเท่ากับ Code Interpreter หรือการเรียกฟังก์ชันที่แข็งแกร่ง) ยังหมายความว่ามันไม่ใช่ตัวเลือกแรกสำหรับโปรแกรมเมอร์ ดังนั้นในขณะที่ผู้ใช้ทั่วไปอาจไม่สนใจเรื่องโค้ดมากนัก แต่นี่เป็นข้อจำกัดสำหรับกลุ่มนั้น

- **ข้อจำกัดของอุปกรณ์เคลื่อนที่:** Gemini เปิดตัวเป็นส่วนหนึ่งของ Google’s Assistant บนโทรศัพท์ Pixel (ภายใต้แบรนด์ “Assistant with Bard”) ผู้ใช้ Pixel บางคนสังเกตว่าการใช้มันเป็นตัวแทนของผู้ช่วยเสียงมีปัญหา บางครั้งมันไม่รับคำสั่งเสียงอย่างถูกต้องหรือใช้เวลาตอบสนองนานเกินไปเมื่อเทียบกับ Google Assistant เก่า นอกจากนี้ยังมีความคิดเห็นเกี่ยวกับความจำเป็นในการเลือกเข้าร่วมและสูญเสียฟีเจอร์บางอย่างของ Assistant แบบคลาสสิก สิ่งนี้สร้างการรับรู้ว่า *การรวม Gemini บนอุปกรณ์ยังไม่พร้อมเต็มที่* ทำให้ผู้ใช้พลังงานของอีโคซิสเต็มของ Google รู้สึกว่าพวกเขาต้องเลือกระหว่างผู้ช่วยที่ฉลาดและผู้ช่วยที่ใช้งานได้

### ฟีเจอร์หรือการปรับปรุงที่ร้องขอบ่อย

- **ปรับปรุงความแม่นยำและการให้เหตุผลอย่างมาก:** การปรับปรุงอันดับหนึ่งที่ผู้ใช้ต้องการสำหรับ Gemini คือเพียงแค่ **ให้ฉลาดขึ้นและน่าเชื่อถือมากขึ้น** ข้อเสนอแนะใน Reddit ทำให้ชัดเจนว่า Google จำเป็นต้องปิดช่องว่างในคุณภาพของคำตอบ ผู้ใช้คาดหวังว่า Gemini จะใช้การเข้าถึงข้อมูลจำนวนมากของ Google เพื่อให้ *คำตอบที่เป็นข้อเท็จจริงและตรงไปตรงมา* ไม่ใช่คำตอบที่ยืดยาวหรือไม่ถูกต้อง ดังนั้นคำขอ (มักจะมีการพูดประชดประชัน) จึงสรุปได้ว่า: *ทำให้มันดีเท่าหรือดีกว่า GPT-4 ในความรู้ทั่วไปและการให้เหตุผล* ซึ่งรวมถึงการจัดการคำถามติดตามผลและคำถามที่ซับซ้อนได้ดีขึ้น โดยพื้นฐานแล้ว “แก้ไขสมอง” ของ Gemini – ใช้ประโยชน์จากข้อได้เปรียบในการฝึกอบรมหลายรูปแบบที่อ้างว่าเพื่อให้มันหยุดพลาดรายละเอียดที่ชัดเจน Google น่าจะได้ยินเรื่องนี้อย่างชัดเจน: โพสต์หลายรายการเปรียบเทียบคำตอบเฉพาะที่ ChatGPT ทำได้ดีและ Gemini ล้มเหลว ซึ่งทำหน้าที่เป็นรายงานข้อบกพร่องที่ไม่เป็นทางการสำหรับการปรับปรุง

- **การรวมเข้ากับบริบทและการรับรู้ที่ดีขึ้น:** ผู้ใช้ต้องการให้ Gemini ทำตามสัญญาของผู้ช่วยอีโคซิสเต็มของ Google อย่างราบรื่น ซึ่งหมายความว่ามันควร **เชื่อมต่อกับ Gmail, Calendar, Docs, Drive ฯลฯ ได้อย่างถูกต้อง** หากผู้ใช้ถามว่า “สรุปเอกสารที่ฉันเปิด” หรือ “ร่างคำตอบสำหรับอีเมลล่าสุดจากเจ้านายของฉัน” AI ควรทำ – และทำอย่างปลอดภัย ตอนนี้คำขอคือให้ Google *เปิดใช้งานฟีเจอร์เหล่านั้นและทำให้ Gemini รู้จักเมื่อทำงานดังกล่าวเป็นไปได้* มันถูกโฆษณาว่า Bard สามารถเชื่อมต่อกับเนื้อหาของผู้ใช้ (ด้วยการอนุญาต) ดังนั้นผู้ใช้จึงเรียกร้องให้ Google “เปิด” หรือแก้ไขการรวมนี้ นี่เป็นฟีเจอร์สำคัญสำหรับผู้ใช้ธุรกิจโดยเฉพาะ นอกจากนี้ ในด้านการท่องเว็บ: Bard (Gemini) สามารถค้นหาเว็บได้ แต่ผู้ใช้บางคนต้องการให้มันอ้างอิงแหล่งข้อมูลอย่างชัดเจนหรือรวมข่าวด่วนได้ทันเวลา ดังนั้นการปรับปรุงลักษณะที่ *เชื่อมต่อ* ของ Gemini เป็นคำขอบ่อย

- **การควบคุมความกระชับ:** เนื่องจากมีการร้องเรียนเกี่ยวกับความยาว ผู้ใช้บางคนแนะนำฟีเจอร์ในการสลับรูปแบบการตอบสนอง ตัวอย่างเช่น *“โหมดสั้น”* ที่ Gemini ให้คำตอบสั้น ๆ โดยค่าเริ่มต้น เว้นแต่จะขอให้ขยายความ ในทางกลับกัน อาจมี “โหมดละเอียด” สำหรับผู้ที่ต้องการคำตอบที่ละเอียดมาก ChatGPT อนุญาตให้บางส่วนโดยคำถามของผู้ใช้ (“ให้มันสั้น”) กับ Gemini ผู้ใช้รู้สึกว่าถึงแม้พวกเขาจะไม่ขอรายละเอียด มันก็อธิบายมากเกินไป ดังนั้นการตั้งค่าในตัวหรือเพียงแค่การปรับแต่งที่ดีขึ้นเพื่อสร้างคำตอบที่กระชับเมื่อเหมาะสมจะเป็นการปรับปรุงที่น่ายินดี โดยพื้นฐานแล้ว ปรับการควบคุมความยาว

- **ความเท่าเทียมกับ ChatGPT (การเขียนโค้ด ปลั๊กอิน ฯลฯ):** ผู้ใช้พลังงานใน Reddit เปรียบเทียบฟีเจอร์อย่างชัดเจน พวกเขาขอให้ Google’s Gemini/Bard เสนอสิ่งต่าง ๆ เช่น *แซนด์บ็อกซ์การดำเนินการโค้ด* (คล้ายกับ ChatGPT’s Code Interpreter) ความสามารถในการอัปโหลดภาพ/PDF เพื่อการวิเคราะห์ (เนื่องจาก Gemini เป็นหลายรูปแบบ ผู้ใช้ต้องการป้อนภาพที่กำหนดเองจริง ๆ ไม่ใช่แค่ให้มันอธิบายภาพที่ให้ไว้) ฟีเจอร์ที่กล่าวถึงบ่อยอีกอย่างคือ **หน่วยความจำภายในการสนทนาที่ดีขึ้น** – ในขณะที่ Bard มีหน่วยความจำบางส่วนของการโต้ตอบที่ผ่านมา ผู้ใช้ต้องการให้มันดีเท่ากับ ChatGPT ในการอ้างอิงบริบทก่อนหน้า หรือแม้แต่มีการจัดเก็บการสนทนาอย่างถาวรเช่นประวัติการแชทของ ChatGPT ที่คุณสามารถเลื่อนดูและกลับไปดูได้ โดยพื้นฐานแล้ว Google ถูกขอให้ตามทันฟีเจอร์คุณภาพชีวิตทั้งหมดที่ผู้ใช้ ChatGPT Plus มี: ประวัติการแชท อีโคซิสเต็มของปลั๊กอิน (หรืออย่างน้อยการรวมบุคคลที่สามที่แข็งแกร่ง) ความช่วยเหลือด้านการเขียนโค้ด ฯลฯ

- **การปรับปรุงแอปมือถือและเสียง:** ผู้ใช้ทั่วไปจำนวนมากร้องขอ **แอปมือถือเฉพาะสำหรับ Bard/Gemini** (คล้ายกับแอปมือถือ ChatGPT) การพึ่งพาอินเทอร์เฟซเว็บหรือเฉพาะ Assistant ของ Pixel เป็นการจำกัด แอปอย่างเป็นทางการใน iOS/Android ที่มีอินพุตเสียง การตอบสนองด้วยเสียง (สำหรับความรู้สึกของผู้ช่วยจริง) และการรวมที่แน่นหนาสามารถปรับปรุงประสบการณ์ของผู้ใช้ได้อย่างมาก พร้อมกับนั้น เจ้าของ Pixel ต้องการให้ Assistant with Bard เร็วขึ้นและใช้งานได้มากขึ้น – โดยพื้นฐานแล้วพวกเขาต้องการสิ่งที่ดีที่สุดของ Google Assistant เก่า (การกระทำที่รวดเร็วและแม่นยำ) รวมกับความฉลาดของ Gemini ตัวอย่างเช่น สิ่งต่าง ๆ เช่น การอนุญาตให้ใช้คำสั่งเสียง “Hey Google” ต่อไปและไม่ใช่แค่การตอบสนองที่พูดคุย Google สามารถปรับปรุงโหมดเสียงของ Gemini เพื่อแทนที่ผู้ช่วยรุ่นเก่าอย่างแท้จริงโดยไม่มีการถดถอยของฟีเจอร์

- **ความโปร่งใสและการควบคุม:** ผู้ใช้บางคนได้ขอข้อมูลเชิงลึกเพิ่มเติมเกี่ยวกับแหล่งที่มาของ Bard หรือวิธีปรับแต่งสไตล์ของมัน ตัวอย่างเช่น การแสดงว่า Bard กำลังดึงข้อมูลจากผลการค้นหา Google ใด (เพื่อยืนยันความถูกต้อง) – สิ่งที่ Bing Chat ทำโดยการอ้างอิงลิงก์ นอกจากนี้ เนื่องจาก Bard บางครั้งผลิตข้อมูลที่ผิด ผู้ใช้ต้องการความสามารถในการทำเครื่องหมายหรือแก้ไข และในอุดมคติ Bard ควรเรียนรู้จากข้อเสนอแนะนั้นเมื่อเวลาผ่านไป การมีกลไกข้อเสนอแนะที่ง่าย (“ไม่ชอบ – นี่ไม่ถูกต้องเพราะ...”) ที่นำไปสู่การปรับปรุงโมเดลอย่างรวดเร็วจะสร้างความมั่นใจว่า Google กำลังรับฟัง โดยพื้นฐานแล้ว ฟีเจอร์ที่จะทำให้ AI เป็นผู้ช่วยที่ทำงานร่วมกันมากขึ้นแทนที่จะเป็นกล่องดำ

### ความต้องการหรือกลุ่มผู้ใช้ที่ยังไม่ได้รับการตอบสนอง

- **ผู้ใช้ที่ต้องการผู้ช่วยส่วนตัวที่เชื่อถือได้:** เป็นเรื่องน่าขันที่กลุ่มที่ Google *มุ่งเป้า* – ผู้ที่ต้องการผู้ช่วยส่วนตัวที่ทรงพลัง – รู้สึกว่าไม่ได้รับการตอบสนองมากที่สุดจาก Gemini ในรูปแบบปัจจุบัน ผู้ใช้ในช่วงแรก ๆ ที่เปิดใช้งาน Assistant ใหม่ที่ใช้ Bard คาดหวังการอัปเกรด แต่หลายคนรู้สึกว่ามันเป็นการลดระดับในแง่ปฏิบัติ ตัวอย่างเช่น หากมีคนต้องการผู้ช่วยเสียงเพื่อ *ตอบคำถามเรื่องไม่สำคัญ ตั้งการเตือน ควบคุมอุปกรณ์ และรวมข้อมูลจากบัญชีของพวกเขาอย่างแม่นยำ* Gemini มีปัญหา สิ่งนี้ทำให้กลุ่มมืออาชีพที่ยุ่งหรือผู้ที่ชื่นชอบแกดเจ็ต (ที่พึ่งพาผู้ช่วยเพื่อเพิ่มประสิทธิภาพ) รู้สึกว่าความต้องการของพวกเขาไม่ได้รับการตอบสนอง ผู้ใช้คนหนึ่งแสดงความคิดเห็นว่าพวกเขาจะพิจารณาจ่ายเงินสำหรับ “Assistant with Bard” ของ Pixel *“หาก [มัน] เหนือกว่า Google Assistant”* ซึ่งบ่งบอกว่ามันยังไม่ถึง ดังนั้นกลุ่มนั้นยังคงรอผู้ช่วย AI ที่เชื่อถือได้และมีประโยชน์อย่างแท้จริง – พวกเขาจะกระโดดเข้าหามันหาก Gemini ปรับปรุง

- **ผู้ที่ไม่พูดภาษาอังกฤษเป็นภาษาแม่ / การแปลภาษา:** ผลิตภัณฑ์ของ Google มักมีการแปลภาษาที่ยอดเยี่ยม แต่ไม่ชัดเจนว่า Bard/Gemini แข็งแกร่งเท่าเทียมกันในทุกภาษาตั้งแต่เปิดตัวหรือไม่ ผู้ใช้ต่างประเทศบางรายรายงานว่าคำตอบของ Bard ในภาษาพื้นเมืองของพวกเขามีความคล่องแคล่วหรือน่าใช้ประโยชน์น้อยกว่า ผลักดันให้พวกเขากลับไปใช้คู่แข่งในท้องถิ่น หากข้อมูลการฝึกอบรมหรือการเพิ่มประสิทธิภาพของ Gemini ให้ความสำคัญกับภาษาอังกฤษ ผู้ใช้ที่ไม่ใช่ภาษาอังกฤษจะไม่ได้รับการตอบสนอง พวกเขาอาจชอบ ChatGPT หรือโมเดลท้องถิ่นที่ได้ปรับประสิทธิภาพหลายภาษาอย่างชัดเจน นี่เป็นพื้นที่ที่ Google สามารถทำได้ดีตามปกติ (เนื่องจากเทคโนโลยีการแปลของมัน) แต่ข้อเสนอแนะของผู้ใช้เกี่ยวกับเรื่องนี้มีน้อย – น่าจะบ่งบอกว่า Gemini ยังไม่ได้ทำให้ชุมชนเหล่านั้นประทับใจ

- **ลูกค้าองค์กร (จนถึงตอนนี้):** องค์กรขนาดใหญ่ยังไม่ได้ใช้ Bard/Gemini อย่างกว้างขวางตามการพูดคุยสาธารณะ มักเป็นเพราะช่องว่างด้านความไว้วางใจและความสามารถ องค์กรต้องการความสม่ำเสมอ การอ้างอิง และการรวมเข้ากับเวิร์กโฟลว์ของพวกเขา (Office 365 รวมเข้ากับเทคโนโลยีของ OpenAI อย่างลึกซึ้งผ่าน MS Copilot ตัวอย่างเช่น) เทียบเท่าของ Google (Duet AI with Gemini) ยังคงพัฒนาอยู่ จนกว่า Gemini/Bard จะพิสูจน์ได้ว่ามันสามารถร่างอีเมล สร้างสไลด์ หรือวิเคราะห์ข้อมูลใน Google Sheets ได้ในระดับที่เทียบเท่าหรือสูงกว่า GPT-4 ผู้ใช้ระดับองค์กรจะรู้สึกว่าโซลูชันของ Google ไม่ตอบสนองความต้องการของพวกเขาอย่างเต็มที่ โพสต์บางรายการใน r/Bard จากมืออาชีพมีลักษณะว่า “ฉันลองใช้ Bard สำหรับงานที่ทำงานแล้ว มันไม่ดีเท่า ChatGPT ดังนั้นเราจะรอดู” นั่นบ่งชี้ว่าผู้ใช้ระดับองค์กรเป็นกลุ่มที่ยังไม่ได้รับการตอบสนองในขณะนี้ – พวกเขาต้องการ AI ที่เข้ากับ Google Workspace และเพิ่มประสิทธิภาพจริง ๆ โดยไม่ต้องตรวจสอบผลลัพธ์อย่างต่อเนื่อง

- **ผู้ใช้ในอีโคซิสเต็มของ Google ที่ต้องการโซลูชันครบวงจร:** มีผู้ใช้กลุ่มหนึ่งที่ใช้ Google สำหรับทุกอย่าง (การค้นหา อีเมล เอกสาร) และ *จะ* ใช้ AI ของ Google อย่างมีความสุขสำหรับความต้องการแชทบอททั้งหมดของพวกเขา – หากมันดีเท่ากัน ตอนนี้ผู้ใช้เหล่านั้น