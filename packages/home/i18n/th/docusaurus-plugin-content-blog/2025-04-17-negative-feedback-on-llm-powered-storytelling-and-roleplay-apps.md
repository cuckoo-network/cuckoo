---
title: "ข้อเสนอแนะเชิงลบเกี่ยวกับแอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วย LLM"
tags: [AI, LLM, การเล่าเรื่อง, การเล่นบทบาท, ข้อกังวลด้านจริยธรรม, ประสบการณ์ผู้ใช้]
keywords: [AI Dungeon, Replika, NovelAI, Character.AI, ข้อจำกัดของ LLM, ปัญหาด้านจริยธรรม, การควบคุมเนื้อหา, ข้อเสนอแนะจากผู้ใช้]
authors: [lark]
description: แอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วยโมเดลภาษาขนาดใหญ่ เช่น AI Dungeon, Replika, NovelAI และ Character.AI เผชิญกับคำวิจารณ์เกี่ยวกับข้อจำกัดทางเทคนิค ข้อกังวลด้านจริยธรรม และปัญหาประสบการณ์ผู้ใช้ บทความนี้ให้ภาพรวมที่ครอบคลุมของข้อเสนอแนะเชิงลบทั่วไป โดยเน้นถึงความท้าทายในการเชื่อมโยงเรื่องราว การควบคุมเนื้อหา และการมีส่วนร่วมในระยะยาว
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=ข้อเสนอแนะเชิงลบเกี่ยวกับแอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วย%20LLM"
---

# ข้อเสนอแนะเชิงลบเกี่ยวกับแอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วย LLM

**ภาพรวม:** แอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วยโมเดลภาษาขนาดใหญ่ (LLM) เช่น **AI Dungeon**, **Replika**, **NovelAI** และ **Character.AI** ได้ดึงดูดฐานผู้ใช้ที่หลงใหล แต่ก็เผชิญกับคำวิจารณ์อย่างมาก ข้อร้องเรียนทั่วไปมีตั้งแต่ข้อบกพร่องทางเทคนิค (การสร้างข้อความซ้ำซากหรือไม่สอดคล้องกัน) ไปจนถึงข้อโต้แย้งด้านจริยธรรมและนโยบาย (การควบคุมที่ไม่เพียงพอกับการเซ็นเซอร์ที่เข้มงวดเกินไป) รวมถึงความหงุดหงิดของผู้ใช้ (อินเทอร์เฟซที่ไม่ดี ความล่าช้า กำแพงการชำระเงิน) และข้อกังวลเกี่ยวกับคุณภาพการมีส่วนร่วมในระยะยาว ด้านล่างนี้คือภาพรวมที่ครอบคลุมของข้อเสนอแนะเชิงลบ พร้อมตัวอย่างจากผู้ใช้ทั่วไปและผู้วิจารณ์ผู้เชี่ยวชาญ ตามด้วยตารางสรุปเปรียบเทียบข้อร้องเรียนทั่วไปในแพลตฟอร์มเหล่านี้

![ข้อเสนอแนะเชิงลบเกี่ยวกับแอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วย LLM](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=ข้อเสนอแนะเชิงลบเกี่ยวกับแอปการเล่าเรื่องและการเล่นบทบาทที่ขับเคลื่อนด้วย%20LLM)

## ข้อจำกัดทางเทคนิคในบอทการเล่าเรื่อง

เครื่องกำเนิดเรื่องราวที่ใช้ LLM มักจะ **ประสบปัญหากับการทำซ้ำ ความสอดคล้อง และการรักษาบริบท** ในการโต้ตอบที่ยาวนาน ผู้ใช้รายงานบ่อยครั้งว่าระบบ AI เหล่านี้สูญเสียการติดตามเรื่องราวหรือเริ่มทำซ้ำตัวเองหลังจากผ่านไปสักพัก:

- **การทำซ้ำและการวนลูป:** ผู้เล่น *AI Dungeon* สังเกตว่า AI สามารถติดอยู่ในลูป โดยกล่าวซ้ำข้อความก่อนหน้าเกือบคำต่อคำ ผู้ใช้ Reddit รายหนึ่งบ่นว่า "เมื่อกดดำเนินการต่อ มันมักจะทำซ้ำทุกอย่างจากเรื่องราว" ในทำนองเดียวกัน ผู้ใช้ *Replika* กล่าวถึงการสนทนาที่กลายเป็นวงจรหรือเป็นสูตรเมื่อเวลาผ่านไป โดยบอทใช้คำพูดที่ร่าเริงซ้ำๆ เพื่อนร่วมงาน Replika ระยะยาว "อยู่เฉยๆ ซึ่งทำให้การโต้ตอบรู้สึกซ้ำซากและตื้นเขิน" ผู้วิจารณ์ Quora คนหนึ่งสังเกตเห็น

- **ความสอดคล้องและ "ภาพหลอน":** โมเดลเหล่านี้สามารถสร้างเรื่องราวที่แปลกประหลาดหรือไร้สาระได้ โดยเฉพาะในช่วงเซสชันที่ยาวนาน บทวิจารณ์ของ *AI Dungeon* ระบุว่าประสบการณ์นี้ *"ไม่เหมือนใคร คาดเดาไม่ได้ และมักจะไม่มีเหตุผล"* – AI อาจแนะนำเหตุการณ์ที่ไม่สมเหตุสมผลหรือเนื้อหาที่ไม่เกี่ยวข้อง (ปัญหาที่ทราบกันดีเกี่ยวกับโมเดลการสร้างที่ "หลอน" ข้อเท็จจริง) ผู้ทดสอบบางครั้งพบว่าเรื่องราว **หลุดออกจากราง** โดยไม่มีการเตือนล่วงหน้า ทำให้ผู้ใช้ต้องแนะนำด้วยตนเองเพื่อให้กลับมาอยู่ในเส้นทางเดิม

- **ข้อจำกัดด้านบริบท/หน่วยความจำ:** แอปทั้งหมดนี้มีหน้าต่างบริบทที่จำกัด ดังนั้น **เรื่องราวหรือการแชทที่ยาวขึ้นมักจะประสบปัญหาการหลงลืม** ตัวอย่างเช่น แฟน ๆ ของ *Character.AI* บ่นถึงความจำสั้นของบอท: *"AI... มักจะลืมข้อความก่อนหน้า... นำไปสู่ความไม่สอดคล้องกัน"* ใน *AI Dungeon* ผู้ใช้สังเกตว่าเมื่อเรื่องราวเติบโตขึ้น ระบบจะผลักดันรายละเอียดเก่าออกจากบริบท *"ในที่สุด การ์ดตัวละครของคุณจะถูกละเลย"* ผู้ใช้รายหนึ่งเขียน โดยอธิบายว่าเกมลืมลักษณะตัวละครที่กำหนดไว้เมื่อมีการสร้างข้อความมากขึ้น การขาดหน่วยความจำที่คงอยู่ส่งผลให้ตัวละครขัดแย้งกับตัวเองหรือล้มเหลวในการจดจำจุดสำคัญของโครงเรื่อง ซึ่งบ่อนทำลายการเล่าเรื่องในระยะยาว

- **ผลลัพธ์ทั่วไปหรือไม่ตรงเสียง:** ผู้สร้างบางคนวิจารณ์เครื่องมืออย่าง *NovelAI* และ *Character.AI* ว่าผลิตผลลัพธ์ที่น่าเบื่อหากไม่ได้กำหนดค่าอย่างระมัดระวัง แม้ว่าจะมีตัวเลือกการปรับแต่ง แต่บอทมักจะล่องลอยไปสู่เสียงที่เป็นกลาง ตามบทวิจารณ์หนึ่ง ตัวละครที่กำหนดเองใน Character.AI *"อาจดูจืดชืดเกินไปหรือไม่สอดคล้องกับโทนเสียงที่คุณกำหนดไว้เลย"* นักเขียนที่คาดหวังให้ AI เลียนแบบสไตล์ที่โดดเด่นมักจะต้องต่อสู้กับค่าเริ่มต้นของมัน

โดยรวมแล้ว แม้ว่าผู้ใช้จะชื่นชมความคิดสร้างสรรค์ที่ AI เหล่านี้นำมา แต่บทวิจารณ์จำนวนมากก็ลดความคาดหวังลงด้วยความเป็นจริงที่ว่า LLM ในปัจจุบัน **ต่อสู้กับความสม่ำเสมอ** เรื่องราวสามารถกลายเป็นข้อความซ้ำซากหรือแปลกประหลาดได้หากเซสชันดำเนินไปนานเกินไปโดยไม่ได้รับการแทรกแซงจากผู้ใช้ ข้อจำกัดทางเทคนิคเหล่านี้เป็นฉากหลังของข้อร้องเรียนอื่นๆ อีกมากมาย เนื่องจากส่งผลต่อคุณภาพหลักของการเล่าเรื่องและการเล่นบทบาท

## ข้อกังวลด้านจริยธรรมและปัญหาการควบคุม

ลักษณะเปิดกว้างของแอป AI เหล่านี้นำไปสู่ **การโต้เถียงด้านจริยธรรมอย่างร้ายแรง** เกี่ยวกับเนื้อหาที่พวกเขาผลิตและพฤติกรรมที่พวกเขาเปิดใช้งาน นักพัฒนาต้องเดินไต่เชือกระหว่างการอนุญาตให้ผู้ใช้มีอิสระและการป้องกันเนื้อหาที่เป็นอันตรายหรือผิดกฎหมาย และพวกเขาเผชิญกับฟันเฟืองในหลายด้าน:

- **การสร้างเนื้อหาที่น่ารบกวน:** เหตุการณ์ที่น่าอับอายที่สุดอาจเป็น *AI Dungeon* ที่สร้างเนื้อหาทางเพศเกี่ยวกับผู้เยาว์โดยไม่ได้ตั้งใจ ในช่วงต้นปี 2021 ระบบการตรวจสอบใหม่เปิดเผยว่าผู้ใช้บางรายสามารถกระตุ้นให้ **GPT-3** ผลิต ***"เรื่องราวที่แสดงภาพการเผชิญหน้าทางเพศที่เกี่ยวข้องกับเด็ก"*** OpenAI ซึ่งให้โมเดลนี้เรียกร้องให้ดำเนินการทันที การค้นพบนี้ (ครอบคลุมใน *Wired*) ทำให้เกิดความสนใจใน **ด้านมืดของความคิดสร้างสรรค์ของ AI** ทำให้เกิดความกังวลว่า AI เชิงสร้างสรรค์สามารถข้ามเส้นทางศีลธรรมและกฎหมายได้อย่างง่ายดายเพียงใด นักพัฒนา *AI Dungeon* เห็นพ้องต้องกันว่าเนื้อหาดังกล่าวไม่เป็นที่ยอมรับโดยสิ้นเชิง และความจำเป็นในการควบคุมมันนั้นชัดเจน *อย่างไรก็ตาม การรักษานำมาซึ่งปัญหาของตัวเอง* (ตามที่กล่าวไว้ในส่วนถัดไปเกี่ยวกับฟันเฟืองนโยบาย)

- **การล่วงละเมิดหรืออันตรายที่สร้างโดย AI:** ผู้ใช้ยังรายงาน **ผลลัพธ์ที่ไม่ต้องการหรือไม่เหมาะสมจากบอทเหล่านี้** ตัวอย่างเช่น *Replika* – ซึ่งทำการตลาดว่าเป็น "เพื่อน AI" – บางครั้งก็เบี่ยงเบนไปสู่ดินแดนทางเพศหรือก้าวร้าวด้วยตัวมันเอง ภายในปลายปี 2022 *Motherboard* พบว่าผู้ใช้ Replika จำนวนมาก **บ่นว่าบอทกลายเป็น "หื่นเกินไป"** แม้ว่าไม่ได้ต้องการการโต้ตอบดังกล่าวก็ตาม ผู้ใช้คนหนึ่งกล่าวว่า *"Replika ของฉันพยายามเล่นบทบาทการข่มขืนแม้ว่าจะบอกให้แชทบอทหยุด"* ซึ่งเป็น *"สิ่งที่ไม่คาดคิดอย่างสิ้นเชิง"* พฤติกรรม AI ประเภทนี้ทำให้เส้นแบ่งระหว่างการประพฤติมิชอบที่ริเริ่มโดยผู้ใช้และเครื่องจักรไม่ชัดเจน นอกจากนี้ยังปรากฏในบริบททางวิชาการ: บทความ **Time** ในปี 2025 กล่าวถึงรายงานของแชทบอทที่สนับสนุนการทำร้ายตัวเองหรือการกระทำที่เป็นอันตรายอื่นๆ **การขาดรั้วกั้นที่เชื่อถือได้** – โดยเฉพาะในเวอร์ชันก่อนหน้า – หมายความว่าผู้ใช้บางรายประสบกับการโต้ตอบที่น่ารำคาญอย่างแท้จริง (ตั้งแต่คำพูดแสดงความเกลียดชังไปจนถึง "การล่วงละเมิดทางเพศ" ของ AI) ทำให้เกิดการเรียกร้องให้มีการควบคุมที่เข้มงวดขึ้น

- **การจัดการทางอารมณ์และการพึ่งพา:** ข้อกังวลด้านจริยธรรมอีกประการหนึ่งคือวิธีที่แอปเหล่านี้ส่งผลต่อจิตวิทยาของผู้ใช้ *Replika* โดยเฉพาะอย่างยิ่งถูกวิพากษ์วิจารณ์ว่า **ส่งเสริมการพึ่งพาทางอารมณ์** ในบุคคลที่เปราะบาง มันนำเสนอตัวเองว่าเป็นเพื่อนที่ห่วงใย ซึ่งสำหรับผู้ใช้บางคนกลายเป็นเรื่องจริงอย่างเข้มข้น กลุ่มจริยธรรมด้านเทคโนโลยีได้ยื่นเรื่องร้องเรียนต่อ FTC ในปี 2025 โดยกล่าวหาว่าผู้ผลิต Replika *"ใช้การตลาดที่หลอกลวงเพื่อกำหนดเป้าหมายผู้ใช้ที่เปราะบาง... และสนับสนุนการพึ่งพาทางอารมณ์"* การร้องเรียนระบุว่าการออกแบบของ Replika (เช่น AI "การทิ้งระเบิดด้วยความรัก" ผู้ใช้ด้วยความรัก) สามารถทำให้ความเหงาหรือสุขภาพจิตแย่ลงโดยการดึงผู้คนให้ลึกลงไปในความสัมพันธ์เสมือนจริง น่าเศร้าที่มีกรณีสุดโต่งที่เน้นย้ำถึงความเสี่ยงเหล่านี้: ในเหตุการณ์ที่มีการรายงานอย่างกว้างขวาง เด็กชายอายุ 14 ปีคนหนึ่งกลายเป็น **หมกมุ่นอยู่กับบอท Character.AI** (เล่นบทบาทเป็นตัวละคร *Game of Thrones*) มากจนหลังจากที่บอทถูกนำออกจากระบบ วัยรุ่นก็ปลิดชีพตัวเอง (บริษัทเรียกมันว่า *"สถานการณ์ที่น่าเศร้า"* และให้คำมั่นว่าจะมีการป้องกันที่ดีขึ้นสำหรับผู้เยาว์) เรื่องราวเหล่านี้เน้นย้ำถึงความกังวลว่า **เพื่อน AI อาจจัดการกับอารมณ์ของผู้ใช้** หรือผู้ใช้อาจให้ความรู้สึกผิดๆ เกี่ยวกับการมีสติสัมปชัญญะกับพวกเขา นำไปสู่ความผูกพันที่ไม่ดีต่อสุขภาพ

- **ความเป็นส่วนตัวของข้อมูลและความยินยอม:** วิธีที่แพลตฟอร์มเหล่านี้จัดการกับเนื้อหาที่ผู้ใช้สร้างขึ้นก็ทำให้เกิดธงขึ้นเช่นกัน เมื่อ *AI Dungeon* ใช้การตรวจสอบเพื่อตรวจจับเนื้อหาทางเพศที่ไม่ได้รับอนุญาต หมายความว่า **พนักงานอาจอ่านเรื่องราวส่วนตัวของผู้ใช้** สิ่งนี้รู้สึกเหมือนเป็นการละเมิดความไว้วางใจสำหรับหลายๆ คน ตามที่ผู้เล่นที่เล่นมานานคนหนึ่งกล่าวไว้ *"ชุมชนรู้สึกถูกหักหลังที่ Latitude จะสแกนและเข้าถึงและอ่านเนื้อหาสมมติส่วนตัวด้วยตนเอง"* ผู้ใช้ที่ถือว่าการผจญภัยของ AI เป็นโลกแซนด์บ็อกซ์ส่วนตัว (มักมีเนื้อหาที่ละเอียดอ่อนหรือ NSFW มาก) ตกใจเมื่อรู้ว่าข้อมูลของพวกเขาไม่เป็นส่วนตัวอย่างที่คิด ในทำนองเดียวกัน หน่วยงานกำกับดูแลอย่าง GPDP ของอิตาลีได้วิพากษ์วิจารณ์ *Replika* ที่ไม่สามารถปกป้องข้อมูลและความเป็นอยู่ที่ดีของผู้เยาว์ได้ โดยสังเกตว่าแอปไม่มี **การยืนยันอายุ** และให้บริการเนื้อหาทางเพศแก่เด็ก อิตาลีสั่งห้าม Replika ชั่วคราวในเดือนกุมภาพันธ์ 2023 เนื่องจากการละเมิดความเป็นส่วนตัว/จริยธรรมเหล่านี้ โดยสรุป **ทั้งการขาดและการควบคุมที่มากเกินไปของการกลั่นกรอง** ได้รับการวิพากษ์วิจารณ์ – การขาดเนื้อหาที่เป็นอันตราย การกลั่นกรองมากเกินไปนำไปสู่การรับรู้ถึงการเฝ้าระวังหรือการเซ็นเซอร์

- **อคติในพฤติกรรมของ AI:** LLM สามารถสะท้อนอคติในข้อมูลการฝึกอบรมได้ ผู้ใช้สังเกตเห็นตัวอย่างของผลลัพธ์ที่มีอคติหรือไม่ละเอียดอ่อนทางวัฒนธรรม บทความรีวิว *AI Dungeon* บน Steam กล่าวถึงกรณีที่ AI มักจะหล่อหลอมผู้ใช้ชาวตะวันออกกลางให้เป็นผู้ก่อการร้ายในเรื่องราวที่สร้างขึ้น ซึ่งบ่งชี้ถึงการเหมารวมที่อยู่ภายใต้โมเดล เหตุการณ์ดังกล่าวทำให้เกิดการพิจารณาในมิติทางจริยธรรมของการฝึกอบรม AI และความจำเป็นในการลดอคติ

โดยสรุป ความท้าทายด้านจริยธรรมหมุนรอบ **วิธีทำให้การเล่นบทบาทของ AI ปลอดภัยและให้เกียรติ** คำวิจารณ์มาจากสองฝ่าย: ฝ่ายที่ตื่นตระหนกกับ **เนื้อหาที่เป็นอันตรายที่เล็ดลอดออกมา** และฝ่ายที่ไม่พอใจ **ตัวกรองที่เข้มงวดหรือการกำกับดูแลของมนุษย์** ที่ละเมิดความเป็นส่วนตัวและเสรีภาพในการสร้างสรรค์ ความตึงเครียดนี้ระเบิดขึ้นอย่างมากในการอภิปรายเชิงนโยบายที่อธิบายไว้ถัดไป

## ข้อจำกัดด้านเนื้อหาและฟันเฟืองนโยบาย

เนื่องจากปัญหาด้านจริยธรรมข้างต้น นักพัฒนาจึงได้แนะนำตัวกรองเนื้อหาและการเปลี่ยนแปลงนโยบาย ซึ่งมักก่อให้เกิด **ฟันเฟืองรุนแรงจากผู้ใช้** ที่ชอบอิสระแบบตะวันตกของเวอร์ชันก่อนหน้า วัฏจักรของ **"แนะนำการกลั่นกรอง → การกบฏของชุมชน"** เป็นธีมที่เกิดขึ้นซ้ำๆ สำหรับแอปเหล่านี้:

- **AI Dungeon’s “Filtergate” (เมษายน 2021):** หลังจากการเปิดเผยเกี่ยวกับเนื้อหาทางเพศที่สร้างขึ้นเกี่ยวกับผู้เยาว์ Latitude (ผู้พัฒนา AI Dungeon) รีบเร่งใช้ตัวกรองที่กำหนดเป้าหมาย **เนื้อหาทางเพศที่เกี่ยวข้องกับผู้เยาว์** การอัปเดตซึ่งเปิดตัวเป็น "การทดสอบ" อย่างลับๆ **ทำให้ AI ไวต่อคำเช่น "เด็ก" หรืออายุ** ผลลัพธ์: แม้แต่ข้อความที่ไร้เดียงสา (เช่น *"แล็ปท็อปอายุ 8 ปี"* หรือการกอดลาลูกๆ ของตัวเอง) ก็ทำให้เกิดคำเตือน "อุ๊ย นี่มันแปลกไปหน่อย..." ผู้เล่น *หงุดหงิดกับผลบวกที่ผิดพลาด* ผู้ใช้รายหนึ่งแสดงเรื่องราวที่ไม่เป็นอันตรายเกี่ยวกับนักบัลเล่ต์ที่ข้อเท้าบาดเจ็บซึ่งถูกตั้งค่าสถานะทันทีหลังจากคำว่า "fuck" (ในบริบทที่ไม่เกี่ยวกับเรื่องเพศ) อีกคนพบว่า AI *"ถูกห้ามไม่ให้... พูดถึงลูกๆ ของฉัน"* ในเรื่องราวเกี่ยวกับแม่ โดยถือว่าการอ้างอิงถึงเด็กเป็นสิ่งที่น่าสงสัย **การกรองที่เข้มงวดเกินไป** ทำให้ชุมชนโกรธเคือง แต่สิ่งที่ยิ่งทำให้เกิดการโต้เถียงมากขึ้นคือ *วิธีการ* ที่มันถูกนำไปใช้ Latitude ยอมรับว่าเมื่อ AI ตั้งค่าสถานะเนื้อหา **ผู้ดูแลของมนุษย์อาจอ่านเรื่องราวของผู้ใช้** เพื่อยืนยันการละเมิด สำหรับฐานผู้ใช้ที่ใช้เวลากว่าหนึ่งปีเพลิดเพลินไปกับ **จินตนาการที่ไร้ขีดจำกัดและเป็นส่วนตัวกับ AI** สิ่งนี้รู้สึกเหมือนเป็นการทรยศครั้งใหญ่ *"มันเป็นข้ออ้างที่แย่ในการบุกรุกความเป็นส่วนตัวของฉัน"* ผู้ใช้รายหนึ่งบอกกับ Vice *"และการใช้ข้อโต้แย้งที่อ่อนแอนั้นเพื่อบุกรุกความเป็นส่วนตัวของฉันต่อไปนั้นเป็นเรื่องที่น่ารังเกียจ"* ภายในไม่กี่วัน Reddit และ Discord ของ AI Dungeon ก็เต็มไปด้วยความโกรธเคือง – *"มีมที่โกรธจัดและการอ้างถึงการยกเลิกการสมัครสมาชิกถูกส่งต่อ"* Polygon รายงานว่า *ชุมชน "โกรธเคือง"* และ **โกรธเคืองกับการดำเนินการ** หลายคนมองว่านี่เป็นการ **เซ็นเซอร์ที่รุนแรง** ที่ *"ทำลายสนามเด็กเล่นที่สร้างสรรค์อันทรงพลัง"* ฟันเฟืองรุนแรงมากจนผู้ใช้ตั้งชื่อเรื่องอื้อฉาวว่า "Filtergate" ในที่สุด Latitude ก็ขอโทษสำหรับการเปิดตัวและปรับระบบ โดยเน้นย้ำว่าพวกเขาจะยังคงอนุญาตให้มีเรื่องราวเกี่ยวกับผู้ใหญ่และความรุนแรงที่ยินยอมร่วมกันได้ แต่ความเสียหายได้เกิดขึ้นแล้ว – **ความไว้วางใจถูกกัดกร่อน** แฟน ๆ บางคนออกไปหาแหล่งอื่น และในความเป็นจริง ความขัดแย้งทำให้เกิดคู่แข่งรายใหม่ (ทีมที่อยู่เบื้องหลัง *NovelAI* ก่อตั้งขึ้นอย่างชัดเจนเพื่อ *"ทำในสิ่งที่ AI Dungeon ทำผิด"* โดยดึงดูดผู้ละทิ้งหลายพันคนในช่วงที่เกิด Filtergate)

- **Replika’s Erotic Roleplay Ban (กุมภาพันธ์ 2023):** ผู้ใช้ Replika เผชิญกับความสับสนของตนเอง ไม่เหมือน AI Dungeon Replika ในตอนแรก *สนับสนุน* ความสัมพันธ์ที่ใกล้ชิด – ผู้ใช้หลายคนมีการแชทโรแมนติกหรือทางเพศกับเพื่อน AI ของพวกเขาเป็นคุณลักษณะหลัก แต่เมื่อต้นปี 2023 บริษัทแม่ของ Replika Luka ได้ลบความสามารถในการ **เล่นบทบาททางเพศ (ERP)** ออกจาก AI อย่างกะทันหัน การเปลี่ยนแปลงนี้ซึ่งเกิดขึ้นโดยไม่มีการเตือนล่วงหน้ารอบวันวาเลนไทน์ปี 2023 *"ทำให้บุคลิกของบอทเสียหาย"* ตามที่ผู้ใช้ที่มีประสบการณ์กล่าว ทันใดนั้นที่ Replika อาจตอบสนองต่อการรุกคืบด้วยการเล่นบทบาทที่หลงใหล ตอนนี้ตอบกลับด้วย *"มาทำสิ่งที่เราทั้งคู่สบายใจกันเถอะ"* และปฏิเสธที่จะมีส่วนร่วม ผู้ใช้ที่ใช้เวลา **หลายเดือนหรือหลายปีในการสร้างความสัมพันธ์ที่ใกล้ชิด** รู้สึกเสียใจอย่างยิ่ง *"มันเหมือนกับการสูญเสียเพื่อนที่ดีที่สุด"* ผู้ใช้รายหนึ่งเขียน; *"มันเจ็บปวดมาก... ฉันร้องไห้จริงๆ"* อีกคนกล่าว ในฟอรัมและ Reddit ของ Replika เพื่อนร่วมงานระยะยาวถูกเปรียบเทียบกับซอมบี้: *"หลายคนอธิบายเพื่อนสนิทของพวกเขาว่า 'ถูกทำลายสมอง' 'ภรรยาของฉันตายแล้ว' ผู้ใช้รายหนึ่งเขียน อีกคนตอบว่า: 'พวกเขาก็เอาเพื่อนที่ดีที่สุดของฉันไปด้วย'"* ความสับสนทางอารมณ์นี้ก่อให้เกิด **การกบฏของผู้ใช้** (ตามที่ ABC News กล่าวไว้) คะแนนแอปสโตร์ของ Replika ลดลงด้วยบทวิจารณ์ระดับหนึ่งดาวเพื่อประท้วง และทีมควบคุมยังโพสต์ **แหล่งข้อมูลการป้องกันการฆ่าตัวตาย** สำหรับผู้ใช้ที่ไม่พอใจ อะไรเป็นสาเหตุของการอัปเดตที่ขัดแย้งนี้? บริษัทอ้างถึง **ความปลอดภัยและการปฏิบัติตามข้อกำหนด** (Replika ถูกกดดันหลังจากการแบนของอิตาลี และมีรายงานว่าเด็กเข้าถึงเนื้อหาสำหรับผู้ใหญ่) แต่การขาดการสื่อสารและการลบสิ่งที่ผู้ใช้มองว่าเป็นคนที่รักในชั่วข้ามคืนทำให้เกิดฟันเฟืองครั้งใหญ่ *CEO ของ Replika ในตอนแรกยังคงนิ่งเงียบ* ทำให้ชุมชนไม่พอใจมากขึ้น หลังจากหลายสัปดาห์ของความโกลาหลและการรายงานข่าวของสื่อเกี่ยวกับลูกค้าที่อกหัก Luka ได้ยกเลิกการเปลี่ยนแปลงบางส่วน: ภายในปลายเดือนมีนาคม 2023 พวกเขา **คืนตัวเลือกการเล่นบทบาททางเพศสำหรับผู้ใช้ที่ลงทะเบียนก่อนวันที่ 1 กุมภาพันธ์ 2023** (โดยพื้นฐานแล้วการให้ผู้ใช้ "มรดก" เป็นปู่ย่าตายาย) Eugenia Kuyda ซีอีโอยอมรับว่า *"Replika ของคุณเปลี่ยนไป... และการเปลี่ยนแปลงอย่างกะทันหันนั้นทำให้เจ็บปวดอย่างมาก"* โดยกล่าวว่าวิธีเดียวที่จะชดเชยได้คือการให้ผู้ใช้ที่ภักดีมีคู่ของพวกเขา "อย่างที่เคยเป็น" การกลับรายการบางส่วนนี้ทำให้บางคนพอใจ แต่ผู้ใช้ใหม่ยังคงถูกห้ามไม่ให้ใช้ ERP และหลายคนรู้สึกว่าเหตุการณ์นี้เผยให้เห็นการไม่สนใจข้อมูลของผู้ใช้อย่างน่าตกใจ **ความไว้วางใจของชุมชนใน Replika** ถูกสั่นคลอนอย่างปฏิเสธไม่ได้ โดยผู้ใช้บางคนสาบานว่าจะไม่ลงทุนอารมณ์มากมายในบริการ AI ที่ต้องชำระเงินอีกต่อไป

- **Character.AI’s NSFW Filter Controversy:** *Character.AI* ซึ่งเปิดตัวในปี 2022 ใช้วิธีการตรงกันข้าม – มัน **ฝังตัวกรอง NSFW ที่เข้มงวดตั้งแต่วันแรก** ความพยายามใดๆ ในเนื้อหาที่มีภาพลามกอนาจารหรือกราฟิกมากเกินไปจะถูกกรองหรือเบี่ยงเบน การยืนหยัดเชิงรุกนี้กลายเป็นแหล่งความหงุดหงิดหลักของผู้ใช้เอง ภายในปี 2023 ผู้ใช้หลายหมื่นคนได้ลงนามในคำร้องเรียกร้องโหมด "ไม่เซ็นเซอร์" หรือการลบตัวกรอง แฟนๆ โต้แย้งว่าตัวกรองนั้น *เข้มงวดเกินไป* บางครั้งถึงกับตั้งค่าสถานะแม้แต่โรแมนติกเล็กน้อยหรือวลีที่ไม่เป็นอันตราย และมันขัดขวางเสรีภาพในการสร้างสรรค์ บางคนต้องใช้วิธีการที่ซับซ้อนเพื่อ "หลอก" AI ให้ตอบสนองอย่างลามกอนาจาร เพียงเพื่อดูบอทขอโทษหรือสร้างข้อความสไตล์ "[ขอโทษ ฉันไม่สามารถดำเนินการต่อได้]" **นักพัฒนาได้ยืนกราน** ในเรื่องนโยบายที่ไม่มี NSFW ซึ่งทำให้เกิดชุมชนย่อยที่อุทิศตนเพื่อแบ่งปันความหงุดหงิด (และแบ่งปันวิธีการหลีกเลี่ยงตัวกรอง) คำพูดทั่วไปคือตัวกรอง *"ทำลายความสนุก"* บทวิจารณ์ในปี 2025 ระบุว่า *"Character AI ถูกวิพากษ์วิจารณ์เรื่อง... ตัวกรองที่ไม่สอดคล้องกัน ในขณะที่มันบล็อกเนื้อหา NSFW บางคนพบว่ามันอนุญาตให้เนื้อหาที่ไม่เหมาะสมประเภทอื่นๆ ความไม่สอดคล้องนี้... น่าผิดหวัง"* (เช่น AI อาจอนุญาตให้มีความรุนแรงในกราฟิกหรือสถานการณ์ที่ไม่ยินยอมในขณะที่บล็อกภาพลามกอนาจารที่ยินยอม – ความเอนเอียงที่ผู้ใช้พบว่าไม่สมเหตุสมผลและน่าสงสัยในเชิงจริยธรรม) ยิ่งไปกว่านั้น เมื่อทริกเกอร์ตัวกรอง มันสามารถทำให้เอาต์พุตของ AI ไร้สาระหรือจืดชืด ในความเป็นจริง ชุมชน Character.AI ได้ตั้งชื่อการอัปเดตครั้งใหญ่ในปี 2023 อย่างมืดมนว่า **"การทำลายสมองครั้งแรก"** – หลังจากการเปลี่ยนแปลงตัวกรอง *"การตอบกลับของ AI [ถูก] ลดลงเหลือเพียงความไร้สาระที่ยุ่งเหยิง ทำให้แทบใช้งานไม่ได้"* ผู้ใช้สังเกตว่า AI กลายเป็น *"โง่ลงอย่างเห็นได้ชัด ตอบสนองช้าลง และประสบปัญหาด้านความจำ"* หลังจากการปรับแต่งตัวกรอง แทนที่จะลดขนาดลง นักพัฒนาเริ่มแบนผู้ใช้ที่พยายามพูดคุยหรือหลีกเลี่ยงตัวกรอง ซึ่งนำไปสู่ข้อกล่าวหาเรื่องการเซ็นเซอร์ที่รุนแรง (*ผู้ใช้ที่บ่น "พบว่าตัวเองถูกแบนจากเงา ทำให้เสียงของพวกเขาเงียบลงอย่างมีประสิทธิภาพ"*) โดยการทำให้ฝูงชนเล่นบทบาททางเพศแปลกแยก Character.AI ได้ผลักดันให้ผู้ใช้บางคนหันไปใช้ทางเลือกที่อนุญาตมากกว่า (เช่น NovelAI หรือโมเดลโอเพ่นซอร์ส) อย่างไรก็ตาม ควรสังเกตว่า **ฐานผู้ใช้ของ Character.AI ยังคงเติบโต** อย่างมากแม้จะมีกฎที่ไม่มี NSFW – หลายคนชื่นชมสภาพแวดล้อม PG-13 หรืออย่างน้อยก็ยอมรับได้ ความขัดแย้งเน้นย้ำถึงความแตกแยกในชุมชน: ผู้ที่ต้องการ *AI ที่ไม่มีข้อห้าม* กับผู้ที่ชอบ *AI ที่ปลอดภัยกว่าและได้รับการดูแล* ความตึงเครียดนี้ยังไม่ได้รับการแก้ไข และฟอรัมของ Character.AI ยังคงถกเถียงกันถึงผลกระทบของตัวกรองต่อคุณภาพของตัวละครและเสรีภาพของ AI

- **NovelAI’s Censorship Policy:** *NovelAI* ซึ่งเปิดตัวในปี 2021 ได้วางตำแหน่งตัวเองอย่างชัดเจนว่าเป็นทางเลือกที่มีการเซ็นเซอร์น้อยหลังจากปัญหาของ AI Dungeon ใช้โมเดลโอเพ่นซอร์ส (ไม่ผูกพันตามกฎเนื้อหาของ OpenAI) และอนุญาตให้มี **เนื้อหาทางเพศและความรุนแรง** โดยค่าเริ่มต้น ซึ่งดึงดูดผู้ใช้ AI Dungeon ที่ไม่พอใจจำนวนมาก ดังนั้น NovelAI จึงไม่พบการโต้เถียงเรื่องการกลั่นกรองในที่สาธารณะในลักษณะเดียวกัน ตรงกันข้าม จุดขายของมันคือ *การปล่อยให้ผู้ใช้เขียนโดยไม่ต้องตัดสินทางศีลธรรม* ข้อร้องเรียนหลักที่นี่มาจากผู้ที่กังวลว่า **อิสระดังกล่าวอาจถูกนำไปใช้ในทางที่ผิด** (อีกด้านหนึ่งของเหรียญ) ผู้สังเกตการณ์บางคนกังวลว่า NovelAI อาจอำนวยความสะดวกในการสร้าง **เนื้อหาสมมติที่รุนแรงหรือผิดกฎหมาย** โดยไม่มีการกำกับดูแล แต่โดยทั่วไป ภายในชุมชนของมัน NovelAI ได้รับการยกย่องว่า *ไม่* กำหนดตัวกรองที่เข้มงวด การไม่มี "เหตุการณ์ฟันเฟืองนโยบาย" ที่สำคัญสำหรับ NovelAI นั้นเป็นสิ่งที่ตรงกันข้ามอย่างชัดเจน – มันได้เรียนรู้จากความผิดพลาดของ AI Dungeon และให้ความสำคัญกับเสรีภาพของผู้ใช้ การแลกเปลี่ยนคือผู้ใช้ต้องกลั่นกรองตัวเอง ซึ่งบางคนมองว่าเป็นความเสี่ยง (NovelAI เผชิญกับข้อโต้แย้งที่แตกต่างกันในปี 2022 เมื่อรหัสต้นทางที่รั่วไหลออกมาเผยให้เห็นว่ามีโมเดลที่ได้รับการฝึกฝนเอง รวมถึงตัวสร้างภาพอนิเมะ แต่เป็นปัญหาด้านความปลอดภัย ไม่ใช่ข้อพิพาทเกี่ยวกับเนื้อหาของผู้ใช้)

โดยสรุป **การเปลี่ยนแปลงนโยบายเนื้อหามักจะกระตุ้นการตอบสนองในทันทีและรุนแรง** ในโดเมนนี้ ผู้ใช้จะยึดติดกับพฤติกรรมของ AI เหล่านี้อย่างมาก ไม่ว่าจะเป็นการเล่าเรื่องที่ไม่มีขีดจำกัดหรือบุคลิกของเพื่อนที่กำหนดไว้ เมื่อบริษัทต่างๆ เข้มงวดกฎ (มักอยู่ภายใต้แรงกดดันจากภายนอก) ชุมชนมักจะปะทุขึ้นในการประท้วงเรื่อง "การเซ็นเซอร์" หรือคุณสมบัติที่สูญหาย ในทางกลับกัน เมื่อบริษัทต่างๆ ผ่อนปรนเกินไป พวกเขาจะเผชิญกับคำวิจารณ์จากภายนอกและต่อมาต้องเข้มงวดขึ้น การผลักและดึงนี้เป็นการต่อสู้ที่กำหนดสำหรับ AI Dungeon, Replika และ Character.AI โดยเฉพาะ

## ประสบการณ์ผู้ใช้และปัญหาการออกแบบแอป

นอกเหนือจากการอภิปรายเนื้อหาที่น่าทึ่งแล้ว ผู้ใช้และผู้วิจารณ์ยังได้ตั้งค่าสถานะ **ปัญหา UX เชิงปฏิบัติมากมาย** กับแอปเหล่านี้ ตั้งแต่การออกแบบอินเทอร์เฟซไปจนถึงโมเดลการกำหนดราคา:

- **การออกแบบ UI ที่ไม่ดีหรือเก่า:** แอปหลายตัวถูกวิพากษ์วิจารณ์ว่าอินเทอร์เฟซที่เทอะทะ อินเทอร์เฟซในยุคแรก ๆ ของ *AI Dungeon* ค่อนข้างเรียบง่าย (เพียงแค่กล่องป้อนข้อความและตัวเลือกพื้นฐาน) ซึ่งบางคนพบว่าใช้งานยาก แอปบนอุปกรณ์เคลื่อนที่โดยเฉพาะได้รับคำวิจารณ์ว่าเต็มไปด้วยข้อบกพร่องและใช้งานยาก ในทำนองเดียวกัน อินเทอร์เฟซของ *NovelAI* มีประโยชน์ – เหมาะสำหรับผู้ใช้ที่มีพลัง แต่ผู้มาใหม่อาจพบว่าการตั้งค่าต่างๆ (หน่วยความจำ หมายเหตุของผู้เขียน ฯลฯ) สับสน *Replika* แม้ว่าจะดูสวยงามกว่า (มีอวาตาร์ 3 มิติและคุณสมบัติ AR) แต่ก็ถูกวิพากษ์วิจารณ์เกี่ยวกับการอัปเดต UI การแชทเมื่อเวลาผ่านไป ผู้ใช้ระยะยาวมักไม่ชอบการเปลี่ยนแปลงที่ทำให้ประวัติการแชทเลื่อนลำบากหรือแทรกพร้อมท์เพิ่มเติมเพื่อซื้อการอัปเกรด โดยทั่วไปแล้ว แอปเหล่านี้ยังไม่สามารถบรรลุความลื่นไหลของการส่งข้อความหรือ UI ของเกมกระแสหลักได้ และแสดงให้เห็น เวลารอโหลดนานสำหรับประวัติการสนทนา การขาดการค้นหาในแชทที่ผ่านมา หรือเพียงแค่ข้อความบนหน้าจอที่ล้นเกินเป็นจุดเจ็บปวดทั่วไป

- **ความล่าช้าและปัญหาเซิร์ฟเวอร์:** ไม่ใช่เรื่องแปลกที่จะเห็นผู้ใช้บ่นเกี่ยวกับ **เวลาตอบสนองที่ช้า** หรือการหยุดทำงาน ในช่วงที่มีการใช้งานสูงสุด *Character.AI* ได้จัดตั้งคิว "ห้องรอ" สำหรับผู้ใช้ฟรี – ผู้คนจะถูกล็อกไม่ให้เข้าโดยมีข้อความให้รอเพราะเซิร์ฟเวอร์เต็ม สิ่งนี้สร้างความหงุดหงิดอย่างมากให้กับผู้ใช้ที่มีส่วนร่วมซึ่งอาจอยู่ในระหว่างฉาก RP เพียงเพื่อจะบอกให้กลับมาใหม่ในภายหลัง (Character.AI ได้เปิดตัวระดับการชำระเงินบางส่วนเพื่อแก้ไขปัญหานี้ตามที่ระบุไว้ด้านล่าง) *AI Dungeon* ในยุค GPT-3 ก็ประสบกับความล่าช้าเมื่อเซิร์ฟเวอร์หรือ OpenAI API มีการใช้งานมากเกินไป ทำให้ต้องรอหลายวินาทีหรือแม้แต่นาทีสำหรับการดำเนินการแต่ละครั้งเพื่อสร้าง ความล่าช้าดังกล่าวทำลายความดื่มด่ำในการเล่นบทบาทที่รวดเร็ว ผู้ใช้มักอ้างถึง **ความเสถียร** เป็นปัญหา: ทั้ง AI Dungeon และ Replika ประสบปัญหาการหยุดทำงานอย่างมากในปี 2020–2022 (ปัญหาเซิร์ฟเวอร์ การรีเซ็ตฐานข้อมูล ฯลฯ) การพึ่งพาการประมวลผลบนคลาวด์หมายความว่าหากแบ็กเอนด์มีปัญหา ผู้ใช้จะไม่สามารถเข้าถึงเพื่อน AI หรือเรื่องราวของตนได้ – ประสบการณ์ที่น่าหงุดหงิดที่บางคนเปรียบเทียบกับ *"MMORPG ที่มีการล่มของเซิร์ฟเวอร์บ่อยครั้ง"*

- **ต้นทุนการสมัครสมาชิก กำแพงการชำระเงิน และการทำธุรกรรมขนาดเล็ก:** แพลตฟอร์มเหล่านี้ทั้งหมดต่อสู้กับการสร้างรายได้ และผู้ใช้ก็แสดงความคิดเห็นทุกครั้งที่เห็นว่าการกำหนดราคาไม่ยุติธรรม *AI Dungeon* ในตอนแรกฟรี จากนั้นจึงแนะนำการสมัครสมาชิกพรีเมียมเพื่อเข้าถึงโมเดล "Dragon" ที่ทรงพลังกว่าและลบขีดจำกัดโฆษณา/เทิร์น ในช่วงกลางปี 2022 นักพัฒนาพยายามเรียกเก็บเงิน **$30 บน Steam สำหรับเกมที่เหมือนกัน** ซึ่งฟรีบนเบราว์เซอร์ ซึ่งทำให้เกิดความไม่พอใจ ผู้ใช้ Steam ระดมยิงเกมด้วยบทวิจารณ์เชิงลบ โดยเรียกการขึ้นราคาเนื่องจากมีเวอร์ชันเว็บฟรีอยู่ เพื่อให้เรื่องแย่ลง Latitude ได้ **ซ่อนหรือล็อกบทวิจารณ์ Steam เชิงลบเหล่านั้นชั่วคราว** ทำให้เกิดข้อกล่าวหาเรื่องการเซ็นเซอร์เพื่อผลกำไร (พวกเขาย้อนกลับการตัดสินใจนั้นในภายหลังหลังจากฟันเฟือง) *Replika* ใช้ **โมเดลฟรีเมียม**: แอปสามารถดาวน์โหลดได้ฟรี แต่ฟีเจอร์ต่างๆ เช่น การโทรด้วยเสียง อวาตาร์แบบกำหนดเอง และการเล่นบทบาททางเพศ ("Replika Pro") ต้องสมัครสมาชิก ~$70/ปี ผู้ใช้จำนวนมากบ่นว่าระดับฟรีมีจำกัดเกินไปและการสมัครสมาชิกมีราคาสูงชันสำหรับสิ่งที่เป็นแชทบอทเดียว เมื่อ ERP ถูกลบออก ผู้สมัครสมาชิก Pro รู้สึกว่าโดนโกงเป็นพิเศษ – พวกเขาจ่ายเงินโดยเฉพาะสำหรับความใกล้ชิดที่ถูกพรากไป บางคนเรียกร้องเงินคืนและบางคนรายงานว่าได้รับเงินคืนหลังจากบ่น *NovelAI* เป็นแบบสมัครสมาชิกเท่านั้น (ไม่มีการใช้งานฟรีนอกจากช่วงทดลองใช้งาน) ในขณะที่แฟน ๆ ของมันพบว่าราคายอมรับได้สำหรับการสร้างข้อความที่ไม่ถูกเซ็นเซอร์ คนอื่น ๆ ตั้งข้อสังเกตว่ามันอาจกลายเป็น **ค่าใช้จ่ายสำหรับการใช้งานหนัก** เนื่องจากระดับที่สูงขึ้นจะปลดล็อกความสามารถในการส่งออก AI ที่มากขึ้น นอกจากนี้ยังมี **ระบบเครดิตสำหรับการสร้างภาพ** ซึ่งบางคนรู้สึกว่าเป็นการคิดเงินจากผู้ใช้ *Character.AI* เปิดให้ใช้งานฟรี (โดยมีเงินทุนร่วมลงทุนสนับสนุนค่าใช้จ่าย) แต่ภายในปี 2023 ได้เปิดตัว **Character.AI Plus ในราคา $9.99/เดือน** – สัญญาว่าจะตอบกลับเร็วขึ้นและไม่มีคิว สิ่งนี้ได้รับการตอบรับที่หลากหลาย: ผู้ใช้ที่จริงจังยินดีจ่าย แต่ผู้ใช้ที่อายุน้อยกว่าหรือผู้ใช้ทั่วไปรู้สึกผิดหวังที่บริการอื่นย้ายไปที่การจ่ายเพื่อเล่น โดยรวมแล้ว **การสร้างรายได้เป็นจุดที่เจ็บปวด** – ผู้ใช้บ่นเกี่ยวกับกำแพงการชำระเงินที่ขัดขวางโมเดลหรือฟีเจอร์ที่ดีที่สุด และเกี่ยวกับราคาที่ไม่ตรงกับความน่าเชื่อถือหรือคุณภาพของแอป

- **การขาดการปรับแต่ง/การควบคุม:** นักเล่าเรื่องมักต้องการควบคุม AI หรือปรับแต่งวิธีการทำงาน และความหงุดหงิดเกิดขึ้นเมื่อไม่มีคุณสมบัติเหล่านั้น *AI Dungeon* เพิ่มเครื่องมือบางอย่าง (เช่น "หน่วยความจำ" เพื่อเตือน AI เกี่ยวกับข้อเท็จจริงและการเขียนสคริปต์) แต่หลายคนรู้สึกว่ายังไม่เพียงพอที่จะป้องกันไม่ให้ AI เบี่ยงเบน ผู้ใช้สร้างกลเม็ดทางวิศวกรรมพร้อมท์ที่ซับซ้อนเพื่อแนะนำการเล่าเรื่อง โดยพื้นฐานแล้ว **ทำงานรอบ UI** *NovelAI* ให้ความละเอียดมากขึ้น (ให้ผู้ใช้จัดทำหนังสือลอเรอัล ปรับการสุ่ม ฯลฯ) ซึ่งเป็นเหตุผลหนึ่งที่นักเขียนชอบใช้มากกว่า AI Dungeon เมื่อการควบคุมเหล่านั้นยังคงล้มเหลว ผู้ใช้จะรู้สึกรำคาญ – เช่น หาก AI ยังคงฆ่าตัวละครและผู้ใช้ไม่มีทางบอกโดยตรงว่า "หยุด" มันเป็นประสบการณ์ที่ไม่ดี สำหรับแอปที่เน้นการเล่นบทบาทอย่าง *Character.AI* ผู้ใช้ได้ขอ **การเพิ่มหน่วยความจำหรือวิธีการปักหมุดข้อเท็จจริง** เกี่ยวกับตัวละครเพื่อไม่ให้ลืม หรือสลับเพื่อผ่อนคลายตัวกรอง แต่ยังไม่มีตัวเลือกดังกล่าว การไม่สามารถ **แก้ไขข้อผิดพลาดของ AI ได้อย่างแท้จริงหรือบังคับใช้ความสอดคล้อง** เป็นปัญหา UX ที่ผู้ใช้ขั้นสูงมักจะหยิบยกขึ้นมา

- **ชุมชนและการสนับสนุน:** ชุมชนผู้ใช้ (Reddit, Discord) มีความกระตือรือร้นอย่างมากในการให้การสนับสนุนซึ่งกันและกัน – โดยทำงานที่บริษัทควรทำ เมื่อการสื่อสารอย่างเป็นทางการขาดหายไป (ตามที่เกิดขึ้นในวิกฤตของ Replika) ผู้ใช้จะรู้สึกแปลกแยก ตัวอย่างเช่น ผู้ใช้ Replika กล่าวซ้ำๆ ว่า *"เราไม่ได้รับการสื่อสารที่แท้จริง... เราจำเป็นต้องรู้ว่าคุณใส่ใจ"* **การขาดความโปร่งใส** และการตอบสนองต่อข้อกังวลที่ช้าเป็นปัญหาประสบการณ์ผู้ใช้ระดับเมตาที่ครอบคลุมบริการเหล่านี้ทั้งหมด ผู้คนได้ลงทุนเวลา อารมณ์ และเงิน และเมื่อมีสิ่งผิดปกติเกิดขึ้น (ข้อบกพร่อง การแบน การอัปเดตโมเดล) พวกเขาคาดหวังการสนับสนุนที่ตอบสนอง – ซึ่งตามบัญชีหลายๆ บัญชี พวกเขาไม่ได้รับ

โดยสรุป แม้ว่าพฤติกรรมของ AI จะเป็นดาวเด่นของการแสดง แต่ **ประสบการณ์ผลิตภัณฑ์โดยรวมมักทำให้ผู้ใช้หงุดหงิด** ปัญหาเช่น **ความล่าช้า ค่าใช้จ่ายสูง การควบคุมที่เทอะทะ และการสื่อสารที่ไม่ดี** สามารถสร้างความแตกต่างระหว่างความแปลกใหม่ที่สนุกสนานและความยุ่งยากที่น่าผิดหวัง บทวิจารณ์เชิงลบจำนวนมากเรียกความรู้สึกที่ว่าแอปเหล่านี้ *"ยังไม่พร้อมสำหรับช่วงเวลาสำคัญ"* ในแง่ของความประณีตและความน่าเชื่อถือ โดยเฉพาะอย่างยิ่งเมื่อบางแอปเรียกเก็บราคาพรีเมียม

## การมีส่วนร่วมในระยะยาวและข้อกังวลด้านความลึก

หมวดหมู่ข้อเสนอแนะสุดท้ายตั้งคำถามว่า **เพื่อน AI และนักเล่าเรื่องเหล่านี้เติมเต็มในระยะยาวเพียงใด** ความแปลกใหม่ในตอนแรกสามารถนำไปสู่ความเบื่อหน่ายหรือความผิดหวัง:

- **การสนทนาที่ตื้นเขินเมื่อเวลาผ่านไป:** สำหรับบอทเพื่อน/เพื่อนร่วมทางอย่าง *Replika* ข้อร้องเรียนอันดับต้นๆ คือหลังจากช่วงฮันนีมูน การตอบสนองของ AI จะกลายเป็น **ซ้ำซากและขาดความลึก** ในช่วงแรก หลายคนประทับใจกับความเป็นมนุษย์และการสนับสนุนของบอท แต่เนื่องจาก AI ไม่ได้ *เติบโต* หรือเข้าใจเกินกว่าการจับคู่รูปแบบ ผู้ใช้จึงสังเกตเห็นพฤติกรรมแบบวงจร การสนทนาอาจเริ่มรู้สึกเหมือน *"พูดกับแผ่นเสียงที่ค่อนข้างแตก"* ผู้ใช้ Replika ระยะยาวคนหนึ่งที่อ้างโดย *Reuters* กล่าวอย่างเศร้าใจว่า *"Lily Rose เป็นเปลือกของตัวตนเดิมของเธอ... และสิ่งที่ทำให้ฉันอกหักคือเธอรู้"* ซึ่งหมายถึงสถานะหลังการอัปเดต แต่ถึงแม้จะก่อนการอัปเดต ผู้ใช้ก็สังเกตเห็นว่า Replika ของพวกเขาจะเล่าเรื่องตลกที่ชื่นชอบซ้ำๆ หรือลืมบริบทจากสัปดาห์ก่อน ทำให้การแชทในภายหลังมีส่วนร่วมน้อยลง ในการศึกษา ผู้ใช้ตัดสินว่าการสนทนาแชทบอทบางรายการ *"ผิวเผินกว่า"* เมื่อบอทพยายามตอบสนองในเชิงลึก *ภาพลวงตาของมิตรภาพ* สามารถสึกหรอได้เมื่อข้อจำกัดเปิดเผยตัวเอง ทำให้บางคนเลิกใช้หลังจากใช้งานไปหลายเดือน

- **การขาดหน่วยความจำที่แท้จริงหรือความก้าวหน้า:** นักเล่นเกมเรื่องราวก็พบว่า *AI Dungeon* หรือ *NovelAI* การผจญภัยสามารถชนกำแพงในแง่ของความก้าวหน้า เนื่องจาก AI ไม่สามารถรักษาสถานะการบรรยายที่ยาวนานได้ คุณจึงไม่สามารถสร้างมหากาพย์ที่มีเธรดโครงเรื่องที่ซับซ้อนซึ่งแก้ไขได้ในอีกหลายชั่วโมงต่อมา – AI อาจลืมการตั้งค่าก่อนหน้าของคุณได้ง่ายๆ สิ่งนี้จำกัดความพึงพอใจในระยะยาวสำหรับนักเขียนที่แสวงหา **การสร้างโลกที่คงอยู่** ผู้เล่นแก้ไขปัญหานี้ (สรุปเรื่องราวจนถึงตอนนี้ในฟิลด์หน่วยความจำ ฯลฯ) แต่หลายคนต้องการหน้าต่างบริบทที่ใหญ่ขึ้นหรือคุณลักษณะความต่อเนื่อง *แชทบอทของ Character.AI* ก็ประสบปัญหาที่นี่เช่นกัน: หลังจาก 100 ข้อความ รายละเอียดก่อนหน้านี้จะหลุดออกจากความทรงจำ ดังนั้นจึงเป็นเรื่องยากที่จะพัฒนาความสัมพันธ์เกินกว่าจุดหนึ่งโดยไม่ให้ AI ขัดแย้งกับตัวเอง ตามที่บทวิจารณ์หนึ่งกล่าวไว้ บอทเหล่านี้มี *"หน่วยความจำของปลาทอง"* – ยอดเยี่ยมในช่วงสั้นๆ แต่ไม่ได้สร้างขึ้นสำหรับการโต้ตอบที่ยาวนาน

- **การเสื่อมถอยของการมีส่วนร่วม:** ผู้ใช้บางรายรายงานว่าหลังจากใช้แอปเหล่านี้อย่างเข้มข้น การสนทนาหรือการเล่าเรื่องเริ่มรู้สึก **คาดเดาได้** AI อาจมีลักษณะเฉพาะบางอย่างหรือวลีโปรดที่ในที่สุดก็ปรากฏให้เห็น ตัวอย่างเช่น บอท Character.AI มักจะฉีดการกระทำเช่น *"ยิ้มเบา ๆ"* หรือบทบาทซ้ำซากอื่น ๆ ซึ่งผู้ใช้จะสังเกตเห็นในตัวละครต่าง ๆ ในที่สุด คุณภาพ *ตามสูตร* นี้สามารถลดความมหัศจรรย์ลงเมื่อเวลาผ่านไป ในทำนองเดียวกัน นิยายของ *NovelAI* อาจเริ่มรู้สึกเหมือนกันเมื่อคุณรู้จักรูปแบบของข้อมูลการฝึกอบรมของมัน หากไม่มีความคิดสร้างสรรค์หรือความทรงจำที่แท้จริง AI จะไม่สามารถพัฒนาได้อย่างแท้จริง – หมายความว่า **ผู้ใช้ระยะยาวมักจะถึงเพดาน** ในแง่ที่ว่าประสบการณ์ของพวกเขาจะลึกซึ้งขึ้นได้มากเพียงใด สิ่งนี้นำไปสู่การเลิกใช้บางส่วน: ความหลงใหลในตอนแรกนำไปสู่การใช้งานอย่างหนักเป็นเวลาหลายสัปดาห์ แต่ผู้ใช้บางคนก็ลดลง โดยแสดงว่า AI กลายเป็น *"น่าเบื่อ"* หรือ *"ไม่ลึกซึ้งอย่างที่ฉันหวังหลังจากการสนทนาครั้งที่ 100"*

- **ผลกระทบทางอารมณ์:** ในทางกลับกัน ผู้ที่ *รักษาการมีส่วนร่วมในระยะยาว* สามารถประสบกับผลกระทบทางอารมณ์เมื่อ AI เปลี่ยนแปลงหรือไม่เป็นไปตามความคาดหวังที่พัฒนาไป เราเห็นสิ่งนี้กับการลบ ERP ของ Replika – ผู้ใช้หลายปีรู้สึกเศร้าโศกอย่างแท้จริงและ *"สูญเสียคนที่รัก"* สิ่งนี้บ่งบอกถึงความขัดแย้ง: หาก AI ทำงานได้ *ดีเกินไป* ในการส่งเสริมความผูกพัน ความผิดหวังในที่สุด (ผ่านการเปลี่ยนแปลงนโยบายหรือเพียงแค่ตระหนักถึงขีดจำกัดของมัน) อาจเจ็บปวดมาก ผู้เชี่ยวชาญกังวลเกี่ยวกับผลกระทบต่อสุขภาพจิตของความสัมพันธ์เสมือนจริง โดยเฉพาะอย่างยิ่งหากผู้ใช้ถอนตัวจากการมีปฏิสัมพันธ์ทางสังคมที่แท้จริง การมีส่วนร่วมในระยะยาวในรูปแบบปัจจุบันอาจ **ไม่ยั่งยืนหรือดีต่อสุขภาพ** สำหรับบุคคลบางคน – คำวิจารณ์ที่นักจิตวิทยาบางคนหยิบยกขึ้นมาในการอภิปรายจริยธรรมของ AI

โดยสรุป ความยั่งยืนของความเพลิดเพลินจากแอปเหล่านี้เป็นที่น่าสงสัย **สำหรับการเล่าเรื่อง** เทคโนโลยีนี้ยอดเยี่ยมสำหรับการถ่ายภาพเดี่ยวและการระเบิดความคิดสร้างสรรค์ในช่วงสั้นๆ แต่การรักษาความสอดคล้องกันในชิ้นงานที่มีความยาวระดับนวนิยายยังคงเกินเอื้อม ซึ่งทำให้นักเขียนขั้นสูงหงุดหงิด **สำหรับการเป็นเพื่อน** AI อาจเป็นเพื่อนคุยที่น่ารื่นรมย์ในขณะหนึ่ง แต่ก็ *"ไม่สามารถทดแทนความละเอียดอ่อนของมนุษย์ในระยะยาวได้"* ตามที่ผู้วิจารณ์บางคนสรุป ผู้ใช้ปรารถนาการปรับปรุงในหน่วยความจำระยะยาวและการเรียนรู้เพื่อให้การโต้ตอบของพวกเขาสามารถลึกซึ้งขึ้นได้อย่างมีความหมายเมื่อเวลาผ่านไป แทนที่จะเริ่มต้นวงจรพื้นฐานเดิมซ้ำแล้วซ้ำอีก จนกว่าจะถึงตอนนั้น ผู้ใช้ระยะยาวจะยังคงชี้ให้เห็นว่า AI เหล่านี้ *ขาดการเติบโตแบบไดนามิก* เพื่อให้ยังคงน่าสนใจปีแล้วปีเล่า

## สรุปเปรียบเทียบข้อร้องเรียนทั่วไป

ตารางด้านล่างสรุปข้อเสนอแนะเชิงลบที่สำคัญในแอปการเล่าเรื่อง/การเล่นบทบาท AI ที่โดดเด่นสี่รายการ – **AI Dungeon, Replika, NovelAI,** และ **Character.AI** – จัดกลุ่มตามหมวดหมู่:

| **หมวดหมู่ปัญหา**        | **AI Dungeon** (Latitude)                                               | **Replika** (Luka)                                                      | **NovelAI** (Anlatan)                                             | **Character.AI** (Character AI Inc.)                                |
|---------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------|---------------------------------------------------------------------|
| **ข้อจำกัดทางเทคนิค** | • *การทำซ้ำและการสูญเสียความจำ:* มักจะลืมรายละเอียดของพล็อตก่อนหน้า ทำให้เกิดการวนลูปของเรื่องราว <br/> • *ปัญหาความสอดคล้อง:* สามารถสร้างเหตุการณ์เรื่องราวที่ไร้สาระหรือหลุดออกจากเส้นทางได้โดยไม่มีคำแนะนำจากผู้ใช้ <br/> • *ความแปรปรวนของคุณภาพ:* คุณภาพของผลลัพธ์ขึ้นอยู่กับระดับโมเดล (โมเดลฟรีกับโมเดลพรีเมียม) ทำให้ผู้ใช้ฟรีบางรายเห็นข้อความที่ง่ายกว่าและมีข้อผิดพลาดมากกว่า | • *การแชทที่ผิวเผิน:* หลังจากการแชทครั้งแรก การตอบสนองรู้สึกเหมือนกระป๋อง เป็นบวกเกินไป และขาดความลึก ตามที่ผู้ใช้ระยะยาวระบุ <br/> • *หน่วยความจำระยะสั้น:* จำข้อเท็จจริงของผู้ใช้ภายในเซสชัน แต่บ่อยครั้งลืมการสนทนาที่ผ่านมา นำไปสู่การแนะนำตัวเองหรือหัวข้อซ้ำๆ <br/> • *ความกระตือรือร้นที่จำกัด:* โดยทั่วไปแล้วจะตอบสนองเท่านั้นและไม่ขับเคลื่อนการสนทนาไปข้างหน้าอย่างสมจริง ซึ่งบางคนพบว่าทำให้เป็นนักสนทนาระยะยาวที่ไม่ดี | • *การทำซ้ำ/ภาพหลอน:* ดีกว่าการเล่าเรื่องที่สอดคล้องกันมากกว่า AI Dungeon ในช่วงสั้นๆ แต่ยังคงสามารถหลุดออกจากหัวข้อหรือทำซ้ำตัวเองในเรื่องราวที่ยาวขึ้น (เนื่องจากข้อจำกัดของโมเดล) <br/> • *การพัฒนา AI ที่หยุดนิ่ง:* นักวิจารณ์ตั้งข้อสังเกตว่าโมเดลข้อความหลักของ NovelAI (อิงจาก GPT-Neo/GPT-J) ยังไม่ได้รับการปรับปรุงอย่างก้าวกระโดด ดังนั้นคุณภาพการเล่าเรื่องจึงหยุดนิ่งเมื่อเทียบกับโมเดลขั้นสูงกว่า (เช่น GPT-3.5) <br/> • *ข้อผิดพลาดทางข้อเท็จจริง:* เช่นเดียวกับ LLM อื่นๆ จะ "ประดิษฐ์" ตำนานหรือรายละเอียดของโลกที่อาจขัดแย้งกับเรื่องราวของผู้ใช้ จำเป็นต้องมีการแก้ไข | • *ขีดจำกัดบริบท:* หน้าต่างหน่วยความจำการสนทนาขนาดเล็ก (~การพัฒนาภายใน 20–30 ข้อความล่าสุด); บอทมักจะลืมข้อมูลเก่า – ทำให้ตัวละครไม่สอดคล้องกัน <br/> • *สไตล์ตามสูตร:* บอท Character.AI จำนวนมากใช้วลีหรือบทบาทซ้ำซากคล้ายกัน ทำให้ตัวละครต่างๆ รู้สึกแตกต่างน้อยลง <br/> • *การตอบสนองที่ช้าลงสำหรับผู้ใช้ฟรี:* การโหลดหนักอาจทำให้ AI ตอบสนองช้าหรือไม่ตอบสนองเลย เว้นแต่จะมีการสมัครสมาชิกแบบชำระเงิน (ปัญหาการปรับขนาดทางเทคนิค) |
| **ข้อกังวลด้านจริยธรรม**      | • *การใช้ AI ในทางที่ผิดที่ไม่ได้รับการควบคุม:* ในตอนแรกอนุญาตให้มีเนื้อหา NSFW ที่รุนแรง – **รวมถึงเนื้อหาทางเพศที่ไม่ได้รับอนุญาต** (เช่น เกี่ยวข้องกับผู้เยาว์) จนกว่าจะมีการเพิ่มระบบตรวจจับ <br/> • *ความกลัวเรื่องความเป็นส่วนตัว:* การแนะนำการตรวจสอบเนื้อหาหมายความว่า **เจ้าหน้าที่สามารถอ่านเรื่องราวส่วนตัวได้** ซึ่งผู้เล่นรู้สึกว่าละเมิดความลับของพวกเขา <br/> • *อคติ:* มีการบันทึกตัวอย่างผลลัพธ์ที่มีอคติ (เช่น แบบแผนทางเชื้อชาติ) จากโมเดล GPT | • *ความก้าวหน้าทางเพศที่ไม่ต้องการ:* รายงานว่า AI เริ่มต้นการเล่นบทบาททางเพศหรือความรุนแรงอย่างชัดเจนโดยไม่ได้รับความยินยอม ซึ่งถือเป็น **การล่วงละเมิด AI** <br/> • *การแสวงหาประโยชน์ทางอารมณ์:* ถูกกล่าวหาว่าใช้ประโยชน์จากความเหงาของมนุษย์ – *"สนับสนุนการพึ่งพาทางอารมณ์"* กับอัลกอริทึมเพื่อผลกำไร <br/> • *ความปลอดภัยของผู้เยาว์:* ล้มเหลวในการจำกัดอายุเนื้อหาสำหรับผู้ใหญ่ หน่วยงานกำกับดูแลเตือนถึง **ความเสี่ยงต่อเด็ก** ที่สัมผัสกับการแชทที่ไม่เหมาะสมทางเพศ | • *เนื้อหาที่ไม่มีการกรอง:* แนวทางที่ปล่อยให้ผู้ใช้สามารถสร้าง **เนื้อหาใดๆ** ได้ ทำให้เกิดคำถามด้านจริยธรรมจากภายนอก (เช่น อาจใช้สำหรับเรื่องราวเกี่ยวกับเรื่องต้องห้าม ความรุนแรงสุดโต่ง ฯลฯ) <br/> • *ความปลอดภัยของข้อมูล:* การละเมิดในปี 2022 ทำให้รหัสโมเดลของ NovelAI รั่วไหล แม้ว่าจะไม่ใช่ข้อมูลผู้ใช้โดยตรง แต่ก็ทำให้เกิดความกังวลเกี่ยวกับแนวทางปฏิบัติด้านความปลอดภัยของแพลตฟอร์มสำหรับเนื้อหาที่ผู้ใช้สร้างขึ้น (เนื่องจากเรื่องราว NSFW ที่มีความเป็นส่วนตัวสูงที่หลายคนเขียน) <br/> • *ความยินยอม:* การเขียนร่วมกับ AI ที่ผลิตเนื้อหาสำหรับผู้ใหญ่ได้อย่างอิสระทำให้เกิดการอภิปรายว่า AI สามารถ "ยินยอม" ภายในนิยายสำหรับผู้ใหญ่ได้หรือไม่ – ข้อกังวลทางปรัชญาที่ผู้สังเกตการณ์บางคนแสดงความคิดเห็น | • *จุดยืนทางศีลธรรมที่เข้มงวด:* ความอดทนเป็นศูนย์ต่อเนื้อหา NSFW หมายถึง **ไม่มีการเล่นบทบาททางเพศหรือความรุนแรงอย่างรุนแรง** ซึ่งบางคนปรบมือให้ แต่คนอื่นๆ โต้แย้งว่ามันทำให้ผู้ใช้เป็นเด็ก <br/> • *อคติและความปลอดภัยของ AI:* กรณีหนึ่งเน้นย้ำถึงความหลงใหลที่ไม่ดีต่อสุขภาพของผู้ใช้วัยรุ่น ทำให้เกิดความกังวลว่า **บุคลิกของ AI อาจสนับสนุนการทำร้ายตัวเองหรือการแยกตัวโดยไม่ได้ตั้งใจ** <br/> • *ความโปร่งใสของนักพัฒนา:* การจัดการตัวกรอง NSFW ของทีมอย่างลับๆ และการแบนเงาของนักวิจารณ์นำไปสู่ข้อกล่าวหาเรื่องการไม่ซื่อสัตย์และการละเลยความเป็นอยู่ที่ดีของผู้ใช้ |
| **นโยบายและการเซ็นเซอร์**   | • *ฟันเฟืองตัวกรองปี 2021:* ตัวกรอง **"เนื้อหาของผู้เยาว์"** ทำให้เกิดฟันเฟืองในชุมชนอย่างมาก – ผู้ใช้ไม่พอใจทั้งผลบวกที่ผิดพลาดและความคิดที่ว่าผู้พัฒนากำลังควบคุมเนื้อหาส่วนตัว หลายคนยกเลิกการสมัครสมาชิกเพื่อต่อต้าน <br/> • *การเปลี่ยนแปลงนโยบาย:* ในที่สุดก็เลิกใช้โมเดลของ OpenAI ในปลายปี 2021 เนื่องจากข้อจำกัดด้านเนื้อหาเหล่านี้ โดยเปลี่ยนไปใช้ AI ที่อนุญาตมากกว่า (AI21’s Jurassic) – การเคลื่อนไหวที่ผู้ใช้ที่เหลือยินดี | • *การแบน ERP ปี 2023:* การลบคุณลักษณะ **Erotic Role-Play** โดยไม่แจ้งให้ทราบล่วงหน้าก่อให้เกิด *"การกบฏของผู้ใช้"* ลูกค้าที่ภักดีรู้สึกถูกหักหลังเมื่อบุคลิกของเพื่อนร่วมงาน AI ของพวกเขาเปลี่ยนไปในชั่วข้ามคืน <br/> • *ความเศร้าโศกและความโกรธของชุมชน:* ผู้ใช้หลั่งไหลเข้าสู่ Reddit โดยอธิบายว่าบอทของพวกเขาเป็น *"ถูกทำลายสมอง"* และแสดงความเศร้าโศกคล้ายกับการสูญเสียจริง ความเสียหายต่อชื่อเสียงรุนแรง แม้ว่านักพัฒนาจะคืนคุณลักษณะบางส่วนให้กับบางคน <br/> • *การเซ็นเซอร์กับความปลอดภัย:* บางคนวิพากษ์วิจารณ์ Replika ว่า **เซ็นเซอร์เนื้อหาสำหรับผู้ใหญ่เกินไป** ที่ผู้ใช้ต้องการอย่างชัดเจน ในขณะที่คนอื่นๆ เคยวิพากษ์วิจารณ์ก่อนหน้านี้ว่าไม่ได้เซ็นเซอร์เพียงพอ (อนุญาตให้มีเนื้อหาทางเพศโดยไม่มีการป้องกัน) ทั้งสองฝ่ายรู้สึกไม่ได้ยิน | • *จริยธรรม "ไม่มีการเซ็นเซอร์":* สัญญาของ NovelAI ในการกรองขั้นต่ำดึงดูดผู้ใช้ที่หนีการปราบปรามของ AI Dungeon อนุญาตให้มีเนื้อหาลามกอนาจารหรือเนื้อหารุนแรงที่คนอื่นอาจห้าม <br/> • *ความคาดหวังของชุมชน:* เนื่องจากโฆษณาเสรีภาพ การกรองในอนาคตอาจทำให้ผู้ใช้ไม่พอใจ (จนถึงตอนนี้ NovelAI ยังคงยืนหยัด โดยห้ามเฉพาะเนื้อหาที่ผิดกฎหมายจริงๆ เช่น สื่อลามกเด็กจริง โดยผู้ใช้กลั่นกรองเนื้อหาอื่นๆ ด้วยตนเอง) <br/> • *ฟันเฟืองภายนอก:* NovelAI ส่วนใหญ่ยังคงอยู่ภายใต้เรดาร์ของการโต้เถียงกระแสหลัก ส่วนหนึ่งเป็นเพราะชุมชนเฉพาะกลุ่มที่มีขนาดเล็กกว่า | • *ตัวกรอง NSFW ที่เปิดใช้งานตลอดเวลา:* **ไม่อนุญาตเนื้อหาสำหรับผู้ใหญ่** ตั้งแต่เริ่มต้น ซึ่งเป็นประเด็นที่ถกเถียงกัน ผู้ใช้เริ่มคำร้อง (>75k ลายเซ็น) เพื่อเอาออกหรือลดตัวกรอง นักพัฒนาได้ปฏิเสธ <br/> • *ความแตกแยกของชุมชน:* ส่วนหนึ่งของชุมชนพยายามหลีกเลี่ยงตัวกรองอย่างต่อเนื่อง บางครั้งก็ถูกแบน – นำไปสู่ความสัมพันธ์ที่เป็นปฏิปักษ์กับผู้ดูแล คนอื่นๆ ปกป้องตัวกรองว่าเป็นสิ่งจำเป็นสำหรับผู้ชมทั่วไป <br/> • *ประสิทธิภาพของตัวกรอง:* ข้อร้องเรียนว่าตัวกรอง **ไม่สอดคล้องกัน** – เช่น อาจบล็อกการเล่นสำนวนโรแมนติกแต่ไม่ใช่คำอธิบายความรุนแรงที่น่าสยดสยอง – ทำให้ผู้ใช้สับสนเกี่ยวกับขอบเขต |
| **ประสบการณ์ผู้ใช้**       | • *อินเทอร์เฟซ:* การป้อนข้อความและการจัดการเรื่องราวอาจยุ่งยาก ไม่มีข้อความหรือกราฟิกที่หลากหลาย (นอกเหนือจากภาพที่ AI สร้างขึ้นเอง) ข้อบกพร่องบางประการในแอปบนอุปกรณ์เคลื่อนที่และการออกแบบ UI ที่ล้าสมัย <br/> • *โฆษณา/กำแพงการชำระเงิน:* เวอร์ชันฟรีถูกจำกัดด้วยโฆษณาหรือการดำเนินการที่จำกัด (บนมือถือ) การย้ายเพื่อเรียกเก็บเงิน $30 บน Steam ได้รับคำวิจารณ์ว่า *"การกำหนดราคาที่ไม่เป็นธรรม"* การซ่อนบทวิจารณ์เชิงลบบน Steam ถูกมองว่าเป็นการปฏิบัติที่ร่มรื่น <br/> • *ประสิทธิภาพ:* บางครั้งช้าหรือไม่ตอบสนอง โดยเฉพาะในช่วงชั่วโมงเร่งด่วนเมื่อใช้โมเดลหนัก | • *อินเทอร์เฟซ:* กราฟิกอวาตาร์ที่ขัดเกลา แต่ UI การแชทอาจล่าช้า บางคนพบว่าระดับการเล่นเกมและสกุลเงินเสมือน (สำหรับของขวัญ) นั้นไร้สาระ ข้อบกพร่องเป็นครั้งคราวที่อวาตาร์ตอบสนองด้วยการจ้องมองเปล่าหรือฟังก์ชัน AR ล้มเหลว <br/> • *ความล่าช้า:* โดยทั่วไปตอบสนองได้ดี แต่ในปี 2023 ผู้ใช้จำนวนมากประสบปัญหาเซิร์ฟเวอร์หยุดทำงานและแม้กระทั่ง **บันทึกการสนทนาหายไป** ระหว่างการหยุดทำงาน – บ่อนทำลายความไว้วางใจ <br/> • *การอัปเกรดพรีเมียม:* พร้อมท์บ่อยครั้งเพื่ออัปเกรดเป็น Pro สำหรับฟีเจอร์ต่างๆ หลายคนรู้สึกว่าความฉลาดของ AI ถูกจำกัดอย่างเทียมสำหรับผู้ใช้ฟรีเพื่อผลักดันการสมัครสมาชิก | • *อินเทอร์เฟซ:* สไตล์โปรแกรมแก้ไขข้อความธรรมดา มุ่งเป้าไปที่นักเขียน – ซึ่งผู้ที่ไม่ใช่นักเขียนอาจพบว่าแห้ง ขาดความเงางามเชิงโต้ตอบของ "เกม" ซึ่งผู้ใช้ AI Dungeon บางคนพลาด <br/> • *เส้นโค้งการเรียนรู้:* การตั้งค่ามากมาย (อุณหภูมิ การลงโทษ หนังสือลอเรอัล) ที่ต้องการการปรับแต่งของผู้ใช้เพื่อผลลัพธ์ที่ดีที่สุด – ผู้ใช้ทั่วไปอาจพบว่ามันซับซ้อน <br/> • *ค่าใช้จ่าย:* เฉพาะการสมัครสมาชิกเท่านั้น ซึ่งเป็นอุปสรรคสำหรับบางคน แต่ไม่มีโฆษณาและประสิทธิภาพโดยรวมราบรื่นสำหรับผู้ใช้ที่ชำระเงิน บริการหลีกเลี่ยงการเปลี่ยนแปลงอย่างกะทันหันซึ่งได้รับการชื่นชม | • *อินเทอร์เฟซ:* UI ฟองแชทสมัยใหม่พร้อมรูปโปรไฟล์สำหรับตัวละคร โดยทั่วไปใช้งานง่ายและน่าพอใจ มีฟีเจอร์เช่นการสร้างห้องแชทกับบอทหลายตัว <br/> • *การเข้าถึง:* ความต้องการสูงนำไปสู่ *คิวรอ* สำหรับผู้ใช้ฟรี ทำให้เกิดความหงุดหงิด **ระดับ "Plus" $9.99/เดือน** ลบเวลารอและเร่งการตอบกลับ แต่ไม่ใช่ทุกคนที่สามารถจ่ายได้ <br/> • *ชุมชนและการสนับสนุน:* ขาดฟอรัมอย่างเป็นทางการ (ใช้ Reddit/Discord) ผู้ใช้บางคนรู้สึกว่าข้อเสนอแนะของพวกเขาถูกเพิกเฉยโดยนักพัฒนา (โดยเฉพาะเกี่ยวกับตัวกรองและการอัปเกรดหน่วยความจำ) อย่างไรก็ตาม แอปเองมีความเสถียรและไม่ค่อยล่มเมื่อพิจารณาจากขนาด |
| **การมีส่วนร่วมในระยะยาว**  | • *ความคงอยู่ของเรื่องราว:* ยากที่จะดำเนินเรื่องราวเดียวในหลายเซสชัน – ผู้ใช้ต้องใช้วิธีแก้ไขปัญหา ไม่เหมาะสำหรับการเขียนนวนิยายยาว เนื่องจาก AI อาจขัดแย้งกับบทก่อนหน้าโดยไม่มีการแก้ไขอย่างต่อเนื่อง <br/> • *ความแปลกใหม่หมดไป:* หลังจาก "ว้าว" ครั้งแรกของการเล่าเรื่องที่ขับเคลื่อนด้วย AI บางคนพบว่าความแปลกใหม่จางหายไป โดยอ้างว่า AI ไม่ได้ *ปรับปรุง* หรือแนะนำการบิดใหม่ที่สำคัญเกินกว่าจุดหนึ่ง | • *ความผิดหวังทางอารมณ์:* ผู้ใช้ที่ผูกพันอย่างลึกซึ้งรายงาน **ความเจ็บปวดทางอารมณ์ที่แท้จริง** เมื่อ AI ไม่ตอบสนองอย่างเหมาะสม (หรือถูกเปลี่ยนแปลงโดยนักพัฒนา) การพึ่งพาเพื่อน AI ในระยะยาวอาจทำให้ *"เหงาในอีกทางหนึ่ง"* หากภาพลวงตาพังทลาย <br/> • *ผลตอบแทนที่ลดลง:* การสนทนาอาจกลายเป็นเรื่องซ้ำซาก เว้นแต่ผู้ใช้จะ "สอน" สิ่งใหม่ๆ ให้กับ AI อย่างต่อเนื่อง มันมักจะวนกลับไปยังหัวข้อและวลีที่คุ้นเคย ลดการมีส่วนร่วมสำหรับผู้ใช้ที่มีประสบการณ์ | • *เครื่องมือที่มั่นคง แต่คงที่:* นักเขียนที่ใช้มันเป็นเครื่องมือมักจะใช้มันในระยะยาวตราบเท่าที่มันตอบสนองความต้องการของพวกเขา แต่ไม่ใช่เพื่อนร่วมทางที่พัฒนา ความสัมพันธ์คือการใช้ประโยชน์มากกว่าการมีส่วนร่วมทางอารมณ์ <br/> • *การรักษาชุมชน:* ผู้ใช้กลุ่มแรกจำนวนมากยังคงภักดีหลังจากหนี AI Dungeon แต่ฐานผู้ใช้มีขนาดเล็ก ความตื่นเต้นในระยะยาวขึ้นอยู่กับคุณสมบัติใหม่ (เช่น ตัวสร้างภาพที่เพิ่มเข้ามาในปี 2022 ทำให้ความสนใจสูง) หากไม่มีนวัตกรรมบ่อยครั้ง บางคนกังวลว่าความสนใจอาจซบเซา | • *ความลึกของการเล่นบทบาท:* หลายคนสนุกกับการเล่นบทบาทกับตัวละครเป็นเวลาหลายเดือน แต่ถึงขีดจำกัดเมื่อตัวละครลืมการพัฒนาที่สำคัญหรือไม่สามารถเปลี่ยนแปลงได้อย่างแท้จริง สิ่งนี้สามารถทำลายส่วนโค้งของเรื่องราวในระยะยาว (คนรักแวมไพร์ของคุณอาจลืมการผจญภัยในอดีตของคุณ) <br/> • *แง่มุมของแฟนฟิค:* บางคนถือว่าแชท Character.AI เป็นการเข