---
title: "Reddit Kullanıcı Geri Bildirimleri: Önemli LLM Sohbet Araçları"
tags: [AI, ChatGPT, Claude, Google Gemini, Açık Kaynak LLM'ler]
keywords: [AI sohbet araçları, kullanıcı geri bildirimleri, ChatGPT, Claude, Google Gemini, açık kaynak LLM'ler, Reddit analizi]
authors: [lark]
description: Bu makale, ChatGPT, Claude, Google Gemini ve açık kaynak LLM'ler dahil olmak üzere popüler AI sohbet araçları hakkında Reddit tartışmalarının derinlemesine bir analizini sunar. Kullanıcıların bildirdiği sıkıntı noktalarını, sıkça talep edilen özellikleri ve karşılanmamış ihtiyaçları vurgulayarak her aracın güçlü ve zayıf yönlerine dair içgörüler sunar.
image: "https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=Reddit%20Kullan%C4%B1c%C4%B1%20Geri%20Bildirimleri%3A%20%C3%96nemli%20LLM%20Sohbet%20Ara%C3%A7lar%C4%B1"
---

# Reddit Kullanıcı Geri Bildirimleri: Önemli LLM Sohbet Araçları

**Genel Bakış:** Bu rapor, dört popüler AI sohbet aracı – **OpenAI’nin ChatGPT’si**, **Anthropic’in Claude’u**, **Google’ın Gemini’si (Bard)** ve **açık kaynak LLM'ler** (ör. LLaMA tabanlı modeller) hakkında Reddit tartışmalarını analiz eder. Her biri için kullanıcıların bildirdiği yaygın sıkıntı noktalarını, en sık talep edilen özellikleri, karşılanmamış ihtiyaçları veya hizmet alamayan kullanıcı segmentlerini ve geliştiriciler, sıradan kullanıcılar ve iş kullanıcıları arasındaki algı farklılıklarını özetler. Bu noktaları açıklamak için Reddit başlıklarından alınan özel örnekler ve alıntılar dahildir.

![Reddit Kullanıcı Geri Bildirimleri: Önemli LLM Sohbet Araçları](https://opengraph-image.blockeden.xyz/api/og-cuckoo-network?title=Reddit%20Kullan%C4%B1c%C4%B1%20Geri%20Bildirimleri%3A%20%C3%96nemli%20LLM%20Sohbet%20Ara%C3%A7lar%C4%B1)

## ChatGPT (OpenAI)

### Yaygın Sıkıntı Noktaları ve Sınırlamalar

- **Sınırlı bağlam hafızası:** En büyük şikayetlerden biri, ChatGPT’nin uzun konuşmaları veya büyük belgeleri önceki ayrıntıları unutmadan ele alamamasıdır. Kullanıcılar sık sık bağlam uzunluğu sınırına (birkaç bin token) ulaşır ve bilgileri kesmek veya özetlemek zorunda kalır. Bir kullanıcı, *“bağlam penceresinin boyutunu artırmak en büyük iyileştirme olurdu… En çok karşılaştığım sınır bu”* diye belirtti. Bağlam aşıldığında, ChatGPT başlangıçtaki talimatları veya içeriği unutur ve bu da oturum ortasında kalite düşüşlerine yol açar.

- **GPT-4 için mesaj sınırları:** ChatGPT Plus kullanıcıları, GPT-4 kullanımında 25 mesaj/3 saat sınırından şikayetçidir (2023'te mevcut bir sınır). Bu sınıra ulaşmak, işleri kesintiye uğratarak beklemeye zorlar. Yoğun kullanıcılar, bu sınırlamayı büyük bir sıkıntı noktası olarak görür.

- **Katı içerik filtreleri (“nerfler”):** Birçok Reddit kullanıcısı, ChatGPT’nin aşırı kısıtlayıcı hale geldiğini ve önceki sürümlerde ele alınan talepleri sıklıkla reddettiğini düşünüyor. Çok beğenilen bir gönderi, *“bugünlerde sorduğunuz hemen her şey ‘Üzgünüm, yardımcı olamam’ yanıtını veriyor… Bu nasıl en kullanışlı araçtan Google Asistan’ın eşdeğerine dönüştü?”* diye şikayet etti. Kullanıcılar, ChatGPT’nin kendi metinlerini (örneğin, giriş bilgileri) yeniden biçimlendirmeyi reddetmesi gibi örnekler veriyor. Aboneler, *“kullanıcının ‘kötü’ şeyler yapabileceği gibi belirsiz bir kavram… sonuçları göstermemek için bir gerekçe olmamalı”* diye savunuyor, çünkü modelin çıktısını istiyorlar ve bunu sorumlu bir şekilde kullanacaklar.

- **Halüsinasyonlar ve hatalar:** Gelişmiş yeteneğine rağmen, ChatGPT yanlış veya uydurma bilgileri güvenle üretebilir. Bazı kullanıcılar, modelin “aptallaştırıldığını” düşünerek bunun zamanla daha da kötüleştiğini gözlemledi. Örneğin, finans alanında bir kullanıcı, ChatGPT’nin NPV veya IRR gibi metrikleri doğru hesapladığını, ancak güncellemelerden sonra *“çok fazla yanlış cevap alıyorum… düzeltmeden sonra bile yanlış cevaplar üretiyor. Gerçekten değişikliklerden sonra çok daha aptal hale geldiğine inanıyorum.”* dedi. Bu tür öngörülemeyen yanlışlıklar, gerçeklere dayalı hassasiyet gerektiren görevler için güveni zedeler.

- **Eksik kod çıktıları:** Geliştiriciler, ChatGPT’yi kodlama yardımı için sıkça kullanır, ancak bazen çözümün parçalarını atladığını veya uzun kodları kestiğini bildirirler. Bir kullanıcı, ChatGPT’nin şimdi *“kodu atladığını, yardımcı olmayan kod ürettiğini ve ihtiyacım olan şeyi yapmada başarısız olduğunu… O kadar çok kodu atlıyor ki çözümünü nasıl entegre edeceğimi bile bilmiyorum.”* diye paylaştı. Bu, kullanıcıları geri kalanını çıkarmak için takip eden istemler istemeye veya cevapları manuel olarak birleştirmeye zorlar – bu zahmetli bir süreçtir.

- **Performans ve çalışma süresi endişeleri:** ChatGPT’nin bireysel kullanıcılar için performansının, kurumsal kullanım arttıkça azaldığına dair bir algı vardır. *“Bant genişliğini ve işlem gücünü işletmelere tahsis ettiklerini ve bunu kullanıcılardan aldıklarını düşünüyorum, bu bir aboneliğin maliyeti göz önüne alındığında dayanılmaz!”* diye bir Plus abonesi öfkeyle belirtti. Yoğun zamanlarda yaşanan kesintiler veya yavaşlamalar anekdot olarak kaydedilmiştir ve bu da iş akışlarını bozabilir.

### Sıkça Talep Edilen Özellikler veya İyileştirmeler

- **Daha uzun bağlam penceresi / hafıza:** En çok talep edilen iyileştirme, daha büyük bir bağlam uzunluğudur. Kullanıcılar, çok daha uzun konuşmalar yapmak veya büyük belgeleri sıfırlama olmadan beslemek istiyor. Birçok kişi, ChatGPT’nin bağlamını GPT-4’ün 32K token yeteneğiyle (şu anda API aracılığıyla mevcut) veya daha fazlasıyla eşleştirmeyi öneriyor. Bir kullanıcının dediği gibi, *“GPT bağlamla en iyi şekilde çalışır ve başlangıçtaki bağlamı hatırlamadığında sinirlenirim… PDF’lerin bağlamı hakkında söylentiler doğruysa, bu temelde tüm sorunlarımı çözerdi.”* Belgeleri yükleme veya kişisel verileri bağlama özellikleri için yüksek talep vardır, böylece ChatGPT bir oturum boyunca onları hatırlayabilir ve referans alabilir.

- **Dosya işleme ve entegrasyon:** Kullanıcılar, ChatGPT’ye dosya veya veri beslemenin daha kolay yollarını sıkça talep eder. Tartışmalarda, *“Google Drive’ımı kopyalayıp yapıştırmak ve çalışmasını sağlamak”* veya ChatGPT’nin kişisel dosyalardan doğrudan bağlam almasına izin veren eklentilere sahip olmak istediklerini belirtirler. Bazıları geçici çözümler denemiştir (PDF okuyucu eklentileri veya Google Dokümanlar’ı bağlamak gibi), ancak hatalar ve sınırlamalar hakkında şikayet etmişlerdir. Bir kullanıcı, ideal eklentisini *“Link Reader gibi ama kişisel dosyalar için… sürücümün hangi bölümlerini bir konuşmada kullanacağımı seçmek… bu, GPT-4 ile ilgili tüm sorunlarımı temelde çözerdi.”* olarak tanımladı. Kısacası, dış bilgi için daha iyi yerel destek (eğitim verilerinin ötesinde) popüler bir taleptir.

- **Ücretli kullanıcılar için azaltılmış sınırlamalar:** Birçok Plus kullanıcısı GPT-4 mesaj sınırına ulaştığı için, daha yüksek sınırlar veya sınırsız erişim için daha fazla ödeme seçeneği talep ederler. 25 mesaj sınırı keyfi olarak görülüyor ve yoğun kullanımı engelliyor. İnsanlar, uzun problem çözme oturumlarının kesilmemesi için kullanım tabanlı bir model veya daha yüksek bir sınır tercih ederler.

- **“Sansürsüz” veya özel moderasyon modları:** Kullanıcıların bir bölümü, içerik filtrelerinin sıkılığını değiştirme yeteneğine sahip olmak ister, özellikle ChatGPT’yi kendileri için kullanırken (kamuya açık içerik değil). Bir “araştırma” veya “sansürsüz” modun – uyarılarla ama katı reddetmeler olmadan – daha özgürce keşfetmelerine izin vereceğini düşünüyorlar. Bir kullanıcının belirttiği gibi, ödeme yapan müşteriler bunu bir araç olarak görüyor ve *“[bunun için] para ödüyorum.”* diyorlar. Sınırda olan sorulara bile yanıt alma seçeneği istiyorlar. OpenAI güvenliği dengelemek zorunda olsa da, bu kullanıcılar özel sohbetlerde politikaları gevşetmek için bir bayrak veya ayar öneriyorlar.

- **Geliştirilmiş gerçeklik doğruluğu ve güncellemeler:** Kullanıcılar genellikle daha güncel bilgi ve daha az halüsinasyon talep ederler. ChatGPT’nin bilgi kesme tarihi (önceki sürümlerde Eylül 2021) Reddit’te sıkça dile getirilen bir sınırlamaydı. OpenAI, tarama ve eklentiler tanıttı, bazı kullanıcılar bunları kullanıyor, ancak diğerleri sadece temel modelin daha sık yeni verilerle güncellenmesini talep ediyor. Özellikle matematik ve kodlama gibi alanlarda bariz hataların azaltılması sürekli bir dilek. Bazı geliştiriciler, ChatGPT hata yaptığında geri bildirimde bulunarak modelin iyileştirilmesini umuyorlar.

- **Daha iyi kod çıktıları ve araçlar:** Geliştiricilerin, içeriği atlamayan geliştirilmiş bir kod yorumlayıcı ve IDE’ler veya sürüm kontrolü ile entegrasyon gibi özellik talepleri vardır. (OpenAI’nin Kod Yorumlayıcı eklentisi – şimdi “Gelişmiş Veri Analizi”nin bir parçası – bu yönde bir adımdı ve övgü aldı.) Yine de, kullanıcılar genellikle kod üretiminde daha ince kontrol talep eder: örneğin, uzun olsa bile tam, filtrelenmemiş kod çıktısı seçeneği veya AI’nın hata yaptığı kodu kolayca düzeltme mekanizmaları. Temelde, ChatGPT’nin yanıtı rafine etmek için birden fazla isteme ihtiyaç duymadan güvenilir bir kodlama asistanı gibi davranmasını istiyorlar.

- **Kalıcı kullanıcı profilleri veya hafıza:** Bazılarının bahsettiği bir diğer iyileştirme, ChatGPT’nin kullanıcı hakkında oturumlar arasında bir şeyler hatırlamasına izin vermektir (rıza ile). Örneğin, birinin yazı stilini veya yazılım mühendisi olduğunu her yeni sohbette tekrar belirtmek zorunda kalmadan hatırlamak. Bu, API ince ayarı veya bir “profil” özelliği ile bağlanabilir. Kullanıcılar önemli bağlamı yeni sohbetlere manuel olarak kopyalıyor, bu yüzden kişisel tercihler için yerleşik bir hafıza zaman kazandırır.

### Karşılanmamış İhtiyaçlar veya Kullanıcı Segmentleri

- **Uzun belgeleri olan araştırmacılar ve öğrenciler:** ChatGPT’nin uzun araştırma makalelerini, kitapları veya büyük veri setlerini analiz etmesini isteyen kişiler hizmet alamıyor. Mevcut sınırlar, metni parçalara ayırmaya veya özetlere razı olmaya zorluyor. Bu segment, daha büyük bağlam pencerelerinden veya uzun belgeleri ele alacak özelliklerden büyük ölçüde fayda sağlar (token sınırlarını aşmaya çalışırken hakkında birçok gönderi olduğu gibi).

- **Sınırların ötesinde yaratıcı hikaye anlatımı veya rol yapma arayan kullanıcılar:** ChatGPT genellikle yaratıcı yazı için kullanılırken, bazı hikaye anlatıcıları uzun bir hikayedeki erken olayları unutan model veya yetişkin/korku içeriğini reddeden model tarafından kısıtlandığını hisseder. Hikayelerine devam etmek için alternatif modellere veya hilelere başvururlar. Bu yaratıcı kullanıcılar, daha uzun hafızaya sahip ve kurgusal şiddet veya olgun temalar konusunda biraz daha esnek bir ChatGPT sürümüyle daha iyi hizmet alır (makul ölçüde). Bir kurgu yazarı, AI hikayeyi kaybettiğinde, *“ona tam formatı veya bağlamı hatırlatmam gerekiyor… İki istem önce harikaydı ama şimdi AI’yı yakalamak zorundayım diye sinirleniyorum.”* dedi.

- **Güç kullanıcıları ve alan uzmanları:** Özelleşmiş alanlardaki profesyoneller (**finans**, **mühendislik**, **tıp**) bazen ChatGPT’nin yanıtlarını alanlarında derinlik veya doğruluk açısından yetersiz bulur, özellikle sorular son gelişmeleri içeriyorsa. Bu kullanıcılar daha güvenilir uzman bilgisi ister. Bazıları API veya özel GPT’ler aracılığıyla ince ayar yapmayı denemiştir. İnce ayar yapamayanlar, ChatGPT’nin alanına özgü sürümlerini veya güvenilir veritabanlarını entegre eden eklentileri takdir eder. Varsayılan formunda, ChatGPT, yüksek doğruluk ve alan bilgisi gerektiren kullanıcıları yeterince hizmet edemeyebilir (sıklıkla işini iki kez kontrol etmek zorunda kalırlar).

- **Sansürsüz veya uç durum içeriği arayan kullanıcılar:** Kullanıcıların azınlığı (güvenlik senaryolarını test eden hackerlar, aşırı kurgu yazarları vb.) ChatGPT’nin içerik kısıtlamalarını ihtiyaçları için çok sınırlayıcı bulur. Resmi ürün tarafından şu anda hizmet edilmeyen bu kullanıcılar (belirli içeriği açıkça kaçındığı için) genellikle jailbreak istemleriyle veya istedikleri yanıtları almak için açık kaynak modelleriyle deney yaparlar. Bu, OpenAI için güvenliği sağlamak adına kasıtlı bir boşluk, ancak bu kullanıcılar başka yerlere bakıyor demektir.

- **Gizlilik bilincine sahip bireyler ve işletmeler:** Bazı kullanıcılar (özellikle kurumsal ortamlarda) ChatGPT’ye hassas veri göndermekten gizlilik endişeleri nedeniyle rahatsızlık duyar. OpenAI’nin API verilerini eğitim için kullanmama politikaları vardır, ancak ChatGPT web arayüzü tarihsel olarak böyle garantiler sunmamıştır, bir devre dışı bırakma özelliği eklenene kadar. Gizli veri işleyen şirketler (hukuk, sağlık vb.) genellikle ChatGPT’yi tam olarak kullanamayacaklarını hisseder, ihtiyaçları karşılanmamış kalır, yerel çözümler geliştirmedikçe. Örneğin, bir Reddit kullanıcısı, şirketlerinin gizlilik nedenleriyle yerel bir LLM’ye geçtiğini belirtti. ChatGPT’nin yerinde veya özel örnekleri mevcut olana kadar, bu segment temkinli kalır veya daha küçük uzman satıcıları kullanır.

### Kullanıcı Türüne Göre Algı Farklılıkları

- **Geliştiriciler/Teknik Kullanıcılar:** Geliştiriciler, ChatGPT’nin en büyük savunucularından ve en sert eleştirmenlerinden biridir. Kod açıklama, şablon oluşturma ve hata ayıklamada yardımcı olma yeteneğini severler. Ancak, daha uzun bağlam ve kod doğruluğundaki sınırlamaları keskin bir şekilde hissederler. Bir geliştirici, ChatGPT’nin *“yardımcı olmayan kod ürettiğini”* ve önemli kısımları atlattığını, bu durumun *“beni sinirlendiriyor… Ona ‘tembel olma’ demek istemiyorum – sadece tam sonucu istiyorum”* dedi. Geliştiriciler, model güncellemelerinden sonra kalitedeki ince değişiklikleri bile fark eder ve kodlama yeteneğindeki “nerfler” veya düşüşler hakkında Reddit’te çok sesli olmuşlardır. Ayrıca sınırları zorlarlar (karmaşık istemler oluşturma, araçları zincirleme), bu yüzden genişletilmiş bağlam, daha az mesaj sınırı ve kodlama araçlarıyla daha iyi entegrasyon gibi özellikler isterler. Özetle, geliştiriciler ChatGPT’yi rutin görevleri hızlandırmak için değerlendirir, ancak mantık veya kod hatalarını hızlıca belirtirler – onu hala gözetim gerektiren bir genç asistan olarak görürler.

- **Gündelik/Günlük Kullanıcılar:** Daha gündelik kullanıcılar – genel bilgi, tavsiye veya eğlence isteyenler – genellikle ChatGPT’nin yeteneklerine hayran kalır, ancak kendi şikayetleri vardır. Yaygın bir gündelik kullanıcı hayal kırıklığı, ChatGPT’nin kendilerine masum görünen bir isteği reddetmesidir (muhtemelen bir politika kuralına takılma). Bir başlıkta orijinal poster bunu örnekledi, *“sorun olmaması gereken bir istem yazdığımda ve şimdi reddettiğinde çok sinirleniyorum”* dedi. Gündelik kullanıcılar ayrıca bilgi kesme noktasına (botun çok güncel olayları ele alamadığını bulmak) takılabilir ve bazen ChatGPT’nin açıkça yanlış bir yanıt verdiğini fark ederler. Geliştiricilerin aksine, AI’yı her zaman iki kez kontrol etmeyebilirler, bu da bir hata üzerine harekete geçerlerse hayal kırıklığına yol açabilir. Olumlu tarafta, birçok gündelik kullanıcı ChatGPT Plus’ın daha hızlı yanıtlarını ve GPT-4’ün geliştirilmiş çıktısını ayda 20 dolara değer bulur – “reddetme” sorunu veya diğer sınırlamalar deneyimi bozmazsa. Genel olarak, yardımcı, çok amaçlı bir asistan isterler ve ChatGPT’nin politika açıklamalarıyla yanıt verdiğinde veya basit bir yanıt almak için karmaşık bir isteme ihtiyaç duyduğunda sinirlenebilirler.

- **İş/Profesyonel Kullanıcılar:** İş kullanıcıları genellikle ChatGPT’ye üretkenlik ve güvenilirlik açısından yaklaşır. E-postaların hızlı taslağını çıkarma, belgelerin özetini çıkarma veya fikir üretme gibi şeyleri takdir ederler. Ancak, **veri güvenliği**, tutarlılık ve iş akışlarına entegrasyon konusunda endişelidirler. Reddit’te, profesyoneller ChatGPT’yi Outlook, Google Dokümanlar gibi araçlarda veya dahili sistemlerinde bir API olarak istediklerini tartıştılar. OpenAI’nin kurumsal müşterilere hizmet vermeye yönelmesiyle, ürünün odağının değiştiği hissi var: Ücretsiz veya bireysel kullanıcı deneyiminin biraz bozulduğu (örneğin, daha yavaş veya “daha az akıllı”) hissi var, çünkü şirket daha büyük müşterilere hizmet vermek için ölçeklendikçe. Doğru olup olmadığına bakılmaksızın, bu bir algıyı vurgular: İş kullanıcıları güvenilirlik ve öncelikli hizmet ister, bireysel kullanıcılar ise şimdi ikinci sınıf olduklarından endişe eder. Ayrıca, profesyoneller doğru çıktılara ihtiyaç duyar – gösterişli ama yanlış bir cevap hiç cevap olmamasından daha kötü olabilir. Bu nedenle, bu segment doğruluğa duyarlıdır. Onlar için, daha uzun bağlam (sözleşmeleri okuma, kod tabanlarını analiz etme) ve garanti edilen çalışma süresi gibi özellikler çok önemlidir. Uyum ve gizlilik gereksinimleri karşılandığı sürece, premium hizmet seviyeleri için daha fazla ödeme yapmaya isteklidirler. Bazı işletmeler, BT politikalarını karşılamak için OpenAI’nin API’sini sıkı veri işleme kurallarıyla kullanmayı veya yerinde dağıtımları keşfetmeyi bile düşünürler.

---

## Claude (Anthropic)

### Yaygın Sıkıntı Noktaları ve Sınırlamalar

- **Kullanım sınırları ve erişim kısıtlamaları:** Claude, güçlü bir model (Claude 2) sunması nedeniyle övgü aldı, ancak kullanıcılar hızla kullanım sınırlarıyla karşılaştı (özellikle ücretsiz katmanda). Belirli bir sayıda istemden veya büyük miktarda metinden sonra, Claude durabilir ve *“Üzgünüm, bu konuşmayı şimdilik sonlandırmam gerekiyor. Lütfen daha sonra geri gelin.”* gibi bir şey söyleyebilir. Bu sınırlama, Claude’u genişletilmiş bir kodlama veya yazma ortağı olarak gören kullanıcıları hayal kırıklığına uğratır. Hatta Claude Pro (ücretli) kullanıcıları bile *“sınırsız zaman garantisi yok”* diye belirtti; kotayı aşmak hala “daha sonra geri gelin” mesajını üretir. Ayrıca, Claude uzun süre resmi olarak coğrafi olarak kısıtlanmıştı (başlangıçta sadece ABD/İngiltere’de mevcuttu). Uluslararası kullanıcılar Reddit’te VPN veya üçüncü taraf platformlar kullanmak zorunda kaldı, bu da bir rahatsızlıktı. Bu, birçok ABD dışı kullanıcının erişim genişleyene kadar dışlanmış hissetmesine neden oldu.

- **Çok büyük girdilerle yoldan sapma eğilimi:** Claude’un başlık özelliği, *100k-token bağlam penceresi*, son derece uzun istemlere izin verir. Ancak, bazı kullanıcılar Claude’a on binlerce token doldurduğunuzda, yanıtlarının daha az odaklanmış hale geldiğini fark etti. *“100k süper kullanışlı ama talimatları düzgün takip etmezse ve yoldan saparsa, o kadar da kullanışlı değil,”* diye bir kullanıcı gözlemledi. Bu, büyük bağlamlarla Claude’un sapabileceğini veya gevezelik etmeye başlayabileceğini, göreve devam etmek için dikkatli bir istem gerektirdiğini gösterir. Bu, bağlamı aşırıya itmenin doğasında olan bir sınırlamadır – model çok şey tutar ama bazen hangi ayrıntıların en önemli olduğunu “unutur”, bu da küçük halüsinasyonlara veya konudan sapmalara yol açar.

- **Tutarsız biçimlendirme veya talimatlara itaat:** Yan yana karşılaştırmalarda, bazı kullanıcılar Claude’un belirli direktifleri takip etme konusunda daha az öngörülebilir olduğunu buldu. Örneğin, Claude *“etkileşimlerde daha insansı. Ama sistem mesajlarını daha az sıkı takip ediyor.”* olarak tanımlanır. Bu, ona takip etmesi gereken sabit bir format veya çok katı bir kişilik verirseniz, Claude’un ChatGPT’den daha fazla sapabileceği anlamına gelir. Belirli formatlara (JSON formatları veya belirli stiller gibi) dayanan geliştiriciler, Claude’un ekstra yorum eklemesi veya şablona sıkı sıkıya uymaması durumunda bazen hayal kırıklığına uğrar.

- **İçerik kısıtlamaları ve reddetmeler:** ChatGPT’ninki kadar sık eleştirilmemiş olsa da, Claude’un güvenlik filtreleri de gündeme gelir. Anthropic, Claude’u etik kuralları takip eden anayasal AI (AI’nin kendisi etik kuralları takip eder) vurgusuyla tasarladı. Kullanıcılar genellikle Claude’un geniş bir konu yelpazesini tartışmaya istekli olduğunu bulur, ancak Claude’un ChatGPT’nin izin verebileceği talepleri reddettiği durumlar vardır. Örneğin, bir Reddit kullanıcısı *“ChatGPT’nin daha az ahlaki kısıtlaması var… hangi gaz maskelerinin hangi koşullar için daha iyi olduğunu açıklarken Claude reddedecek”* diye belirtti. Bu, Claude’un belirli “hassas” tavsiyeler konusunda daha katı olabileceğini (belki de potansiyel olarak tehlikeli rehberlik olarak değerlendirdiği) gösterir. Başka bir kullanıcı, “uzaylılar tarafından kaçırıldığını hayal et” gibi eğlenceli bir rol yapma senaryosu denedi, Claude reddetti, oysa Gemini ve ChatGPT katılacaktı. Yani, Claude’un kullanıcıları bazen daha izin verici olmasını beklerken şaşırtan filtreleri vardır.

- **Çok modlu yetenek eksikliği:** ChatGPT’nin aksine (2023’ün sonlarında, GPT-4 Vision ile görüntü anlama kazandı), Claude şu anda yalnızca metin tabanlıdır. Reddit kullanıcıları, Claude’un görüntüleri analiz edemediğini veya kendi başına web’de gezinemediğini belirtir. Bu tam olarak bir “sıkıntı noktası” değil (Anthropic bu özellikleri hiç tanıtmadı), ancak rakiplere göre bir sınırlamadır. Bir AI’nın bir diyagramı veya ekran görüntüsünü yorumlamasını isteyen kullanıcılar Claude’u bunun için kullanamaz, oysa ChatGPT veya Gemini bunu ele alabilir. Benzer şekilde, Claude’un şu anda resmi bir tarama modu olmadığından, güncel bilgilerin alınması bir üçüncü taraf aracı (örneğin, Poe veya arama motoru entegrasyonu) kullanmayı gerektirir.

- **Küçük kararlılık sorunları:** Birkaç kullanıcı, Claude’un bazen tekrarlayıcı olduğunu veya belirli istemler için döngülere takıldığını bildirdi (bu bazı daha küçük modellerde daha yaygın olsa da). Ayrıca, Claude’un önceki sürümleri bazen yanıtları erken sonlandırır veya büyük çıktılarla uzun zaman alırdı, bu küçük rahatsızlıklar olarak görülebilir, ancak Claude 2 hız konusunda iyileşmiştir.

### Sıkça Talep Edilen Özellikler veya İyileştirmeler

- **Daha yüksek veya ayarlanabilir kullanım sınırları:** Reddit’teki Claude meraklıları, Anthropic’ten konuşma sınırlarını artırmasını sıkça talep eder. 100k bağlamını tam anlamıyla kullanmak istiyorlar, yapay bir durma noktasına ulaşmadan. Bazıları, ücretli Claude Pro’nun bile *önemli ölçüde* daha fazla token sağlaması gerektiğini öne sürer. Diğerleri, belki de bir abonelik, ağır kullanıcılar için genişletilmiş erişim sunabilir – örneğin, *“Claude, iki kat kullanım sınırları olan bir 100k bağlam moduna sahip olmalı”* gibi bir “100k genişletilmiş mod” fikrini öne sürdü. Özünde, aboneler için sınırsız (veya yüksek kapasiteli) kullanım sunan bir plan talebi vardır.

- **Uzun bağlam navigasyonunun iyileştirilmesi:** 100k token’a sahip olmak çığır açıcı olsa da, kullanıcılar Claude’un bu bağlamı daha iyi *kullanmasını* istiyor. Bir iyileştirme, Claude’un bilgiyi önceliklendirme şeklini rafine etmek olabilir, böylece görevde kalır. Anthropic, modelin büyük olduğunda bile isteme bağlılığını geliştirebilir. Reddit tartışmaları, kullanıcıya büyük bir bağlamda “sabit” talimatları sabitleme izni vermek gibi teknikleri önerir. Girdinin bölümlerini segmentleme veya özetleme araçları da Claude’un büyük girdileri daha tutarlı bir şekilde ele almasına yardımcı olabilir. Kısacası, kullanıcılar Claude’a bir kitabı besleme olasılığını seviyor – sadece keskin kalmasını istiyorlar.

- **Eklentiler veya web tarama:** Birçok ChatGPT kullanıcısı eklentilere alıştı (örneğin, tarama, kod yürütme vb.) ve Claude’un benzer genişletilebilirliğe sahip olmasını istiyorlar. Yaygın bir istek, Claude’un resmi bir web arama/tarama işlevine sahip olmasıdır, böylece talep üzerine güncel bilgileri alabilir. Şu anda, Claude’un bilgisi çoğunlukla statiktir (2023 başlarına kadar eğitim verileri, bazı güncellemelerle). Claude web’i sorgulayabilseydi, bu sınırlamayı hafifletirdi. Benzer şekilde, Claude’un üçüncü taraf araçları (hesap makineleri veya veritabanı bağlayıcıları gibi) kullanabileceği bir eklenti sistemi, güç kullanıcıları için faydasını genişletebilir. Bu, Claude’un eksik olduğu bir özellik ve Reddit kullanıcıları, ChatGPT’nin eklenti ekosisteminin belirli görevlerde ona bir avantaj sağladığını sıkça belirtir.

- **Çok modlu giriş (görüntüler veya ses):** Bazı kullanıcılar Claude’un görüntü girdilerini destekleyip desteklemeyeceğini veya görüntü oluşturup oluşturmayacağını merak etmiştir. Google’ın Gemini’si ve OpenAI’nin GPT-4’ü çok modlu yeteneklere sahip, bu yüzden rekabetçi kalmak için kullanıcılar Anthropic’in bunu keşfetmesini bekliyor. Sıkça istenen bir özellik: *“Claude’a analiz etmesi için bir PDF veya bir görüntü yükleyebilir miyim?”* Şu anda cevap hayır (görüntüleri başka bir yerde metne dönüştürme gibi geçici çözümler dışında). Sadece görüntüden metne (OCR ve açıklama) izin vermek bile birçok kullanıcıyı tatmin eder. Bu, dilek listesinde, ancak Anthropic 2025 başı itibarıyla benzer bir şey duyurmadı.

- **İnce ayar veya özelleştirme:** İleri düzey kullanıcılar ve işletmeler bazen Claude’u kendi verileri üzerinde ince ayar yapıp yapamayacaklarını veya özel sürümler alıp alamayacaklarını sorar. OpenAI bazı modeller için ince ayar sunar (henüz GPT-4 için değil, ancak GPT-3.5 için). Anthropic, Claude 1.3 için bir ince ayar arayüzü yayınladı, ancak Claude 2 için geniş çapta tanıtılmadı. Reddit kullanıcıları, Claude’u şirket bilgileri veya kişisel yazı stili üzerinde eğitme yeteneğini sorguladı. Bunu yapmanın daha kolay bir yolu (her seferinde istem enjeksiyonları dışında) çok memnuniyetle karşılanır, çünkü bu, Claude’u belirli bir bilgi tabanını veya kişiliği hatırlayan kişiselleştirilmiş bir asistana dönüştürebilir.

- **Daha geniş erişilebilirlik:** ABD dışındaki kullanıcılar sıkça Claude’un resmi olarak kendi ülkelerinde başlatılmasını talep eder. Kanada, Avrupa, Hindistan vb. yerlerden gönderiler, Claude’un web sitesini VPN olmadan ne zaman kullanabileceklerini veya Claude API’nin daha geniş bir şekilde ne zaman açılacağını sorar. Anthropic temkinli davrandı, ancak talep küresel – birçok kişi için bir iyileştirme, basitçe “daha fazlamızın kullanmasına izin verin” olurdu. Şirketin erişimi kademeli olarak genişletmesi, bunu kısmen ele aldı.

### Karşılanmamış İhtiyaçlar veya Kullanıcı Segmentleri

- **Uluslararası kullanıcı tabanı:** Belirtildiği gibi, Claude’un birincil kullanıcı tabanı uzun süre coğrafya ile sınırlıydı. Bu, birçok *potansiyel* kullanıcıyı hizmet alamamış bıraktı. Örneğin, Claude’un 100k bağlamını merak eden Almanya’daki bir geliştiricinin resmi olarak kullanma yolu yoktu. Geçici çözümler var (üçüncü taraf platformlar veya VPN + desteklenen bir ülkede telefon doğrulaması), ancak bu engeller, sıradan uluslararası kullanıcıların etkili bir şekilde kilitlenmesine neden oldu. Karşılaştırıldığında, ChatGPT çoğu ülkede mevcuttur. Dolayısıyla, ABD dışındaki İngilizce konuşanlar ve özellikle İngilizce konuşmayanlar, Claude’un sınırlı yayılımı nedeniyle hizmet alamamıştır. Sadece erişim sorunları nedeniyle ChatGPT veya yerel modellere güvenebilirler.

- **Kesin çıktı formatına ihtiyaç duyan kullanıcılar:** Belirtildiği gibi, Claude bazen yanıtlarda özgürlük tanır. Çok yapılandırılmış çıktılara ihtiyaç duyan kullanıcılar (örneğin, bir uygulama için JSON veya belirli bir formatı takip eden bir cevap) Claude’u bu konuda ChatGPT’den daha az güvenilir bulabilir. Bu kullanıcılar – genellikle AI’yı bir sisteme entegre eden geliştiriciler – Claude’un bu tür görevler için daha sıkı bir mod veya talimatlara bağlılığını geliştirmesini sağlayacak bir şey olsaydı daha iyi hizmet alabilir. Şu anda, bu tür görevler için Claude’dan kaçınabilirler, formatları daha sıkı takip ettiği bilinen modellerle kalabilirler.

- **Gündelik Soru-Cevap kullanıcıları (yaratıcı kullanıcılar karşısında):** Claude genellikle yaratıcı görevler için övülür – akıcı, insansı düzyazı ve düşünceli makaleler üretir. Ancak, bazı kullanıcılar Reddit’te, basit soru-cevap veya gerçek sorgular için Claude’un bazen özlü cevaplar yerine uzun cevaplar verdiğini belirtti. ChatGPT ve Claude’u karşılaştıran kullanıcı, ChatGPT’nin genellikle kısa ve madde işaretli olduğunu, Claude’un ise varsayılan olarak daha anlatımsal olduğunu söyledi. Sadece hızlı bir gerçek cevap isteyen kullanıcılar (örneğin, “X’in başkenti ve nüfusu nedir?”) Claude’un biraz dolaylı olduğunu hissedebilir. Bu kullanıcılar, bir arama veya kısa bir model gibi bir şeyle daha iyi hizmet alır. Claude bunu yapabilir, ancak tarzı kısa bir Soru-Cevap beklentisine uymayabilir, bu da bu segmentin diğer araçlara (Bing Chat veya Google gibi) kaymasına neden olabilir.

- **Güvenlik açısından kritik kullanıcılar:** Tersine, *çok dikkatli* güvenlik uyumu gerektiren kullanıcılar (örneğin, AI’yı öğrencilerle kullanan eğitimciler veya sıfır risk isteyen kurumsal müşteriler) Claude’un hizalamasını bir artı olarak görebilir, ancak ChatGPT de oldukça hizalı olduğu ve daha fazla kurumsal özelliğe sahip olduğu için, bu kullanıcılar özellikle Claude’u seçmeyebilir. Küçük bir segmenttir, ancak Claude’un henüz bunu belirgin bir şekilde yakalayamadığını söyleyebiliriz. Claude’un güvenlik önlemlerini *artırmanın* veya “düşünce zincirini” görmenin kolay bir yolu yok (Anthropic’in anayasal AI yaklaşımıyla içsel olarak sahip olduğu, ancak son kullanıcılar bununla doğrudan etkileşimde bulunmaz, Claude’un genellikle kibar tonunu fark etmeleri dışında).

- **İngilizce olmayan konuşmacılar (çıktı kalitesi):** Claude öncelikle İngilizce eğitildi (çoğu büyük LLM gibi). Bazı kullanıcılar diğer dillerde test etti; birçok dilde yanıt verebilir, ancak kalitesi değişebilir. Örneğin, bir kullanıcı Fransızca veya Hintçe’de çok ince bir cevap isterse, Claude’un yetenekleri ChatGPT’ninki kadar ince ayarlı olmayabilir (GPT-4, belirli ölçütlerde diğer modellere göre daha yüksek çok dilli performans göstermiştir). Öncelikle İngilizce dışındaki dillerde konuşan kullanıcılar, Claude’un akıcılığını veya doğruluğunu biraz daha zayıf bulabilir. Bu segment, Anthropic’in çok dilli eğitimi kamuya açık bir öncelik olarak vurgulamadığı için biraz hizmet alamamıştır.

### Kullanıcı Türüne Göre Algı Farklılıkları

- **Geliştiriciler/Teknik Kullanıcılar:** Reddit’teki geliştiriciler, özellikle Claude 2 / Claude 3.5, kodlama görevleri için giderek daha fazla övgü aldı. 2024’ün sonlarında algı değişimi dikkat çekiciydi: birçok geliştirici, Claude’u ChatGPT’ye tercih etmeye başladı. *“Kodlamada harika”* performansını ve büyük kod tabanlarını bir seferde ele alabilme yeteneğini öne çıkarıyorlar. Örneğin, bir kullanıcı *“Claude Sonnet 3.5, kodla çalışmak (analiz, üretim) [ChatGPT’den] daha iyi.”* diye yazdı. Geliştiriciler, Claude’un büyük bir proje kodunu veya günlükleri alıp tutarlı analizler veya iyileştirmeler üretebilmesini takdir eder, bu da büyük bağlamı sayesinde mümkündür. Ancak, onun tuhaflıklarını da fark ederler – bazen daha fazla konuşma doluluğu eklemek veya bir spesifikasyonu harfiyen takip etmemek gibi. Genel olarak, birçok geliştirici hem ChatGPT’yi hem de Claude’u elinde tutar: biri adım adım mantık için (ChatGPT) ve biri geniş bağlam ve empatik anlayış için (Claude). *“Birini seçmek zorunda kalsaydım Claude’u seçerdim”* diyen bir yorumcu, ikisini günlük olarak karşılaştırdıktan sonra bu olumlu algıyı gösterir. Bu, özellikle beyin fırtınası, kod incelemesi veya mimari öneriler gibi kullanım durumları için ileri düzey kullanıcılar arasında çok olumlu bir algıyı gösterir. Geliştiricilerin tek yaygın şikayeti, Claude’un kullanım sınırlarına ulaşmalarıdır (örneğin, bir 50K-token istemi bir bütün depoyu analiz etmek için beslemek). Özetle, geliştiriciler Claude’u son derece güçlü bir araç olarak görüyor – bazı durumlarda ChatGPT’den üstün – sadece kullanılabilirlik ve biçimlendirmedeki bazı öngörülemezliklerle sınırlı.

- **Gündelik/Non-teknik Kullanıcılar:** Claude’u deneyen gündelik kullanıcılar genellikle onun *dostane ve açık* olduğunu yorumlar. Claude’un tarzı genellikle konuşma, kibar ve ayrıntılıdır. Yeni bir kullanıcı, ChatGPT ile karşılaştırarak *“Claude daha empatik ve konuşma tonunu takip ediyor… ChatGPT çok sık madde işaretlerine geçiyor”* diye gözlemledi. Bu insansı sıcaklık, Claude’u yaratıcı yazı, tavsiye veya sadece bilgi için sohbet eden insanlar için çekici kılar. Bazıları Claude’u “şefkatli” bir “kişiliğe” sahip olarak kişiselleştirir. Gündelik kullanıcılar ayrıca Claude’un ücretsiz sürümünün, bir abonelik olmadan GPT-4 seviyesinde zekaya erişim sağladığını beğenir (en azından oran sınırlarına kadar). Öte yandan, gündelik kullanıcılar Claude’un belirli konulardaki reddetmeleriyle karşılaşır ve nedenini anlamayabilir (Claude bunu özür dileyerek ama kararlı bir şekilde ifade eder). Bir gündelik kullanıcı, sınırda bir şey sorduysa ve Claude’dan bir ret aldıysa, bunu daha az yetenekli veya çok kısıtlı olarak algılayabilir, bunun bir politika duruşu olduğunu fark etmeden. Bir diğer yön, Claude’un isim tanınırlığı eksikliğidir – birçok gündelik kullanıcı, AI topluluklarına bağlı değilse denemeyi bile bilmeyebilir. Deneyenler genellikle *“bir insanla konuşuyormuş gibi”* hissettiklerini yorumlarlar. Açık uçlu veya kişisel soruları ele alma yeteneğiyle Claude’dan genellikle çok memnun kalırlar. Yani, gündelik kullanıcı algısı büyük ölçüde Claude’un *çıktı kalitesi ve tonu* ile ilgilidir, ancak kullanılabilirliği (belirli bir uygulama veya bölgede kullanma zorunluluğu) ve ara sıra “bunu yapamam” anlarıyla ilgili bazı kafa karışıklığı veya hayal kırıklığı vardır.

- **İş/Profesyonel Kullanıcılar:** Claude’un iş algılarını kamuya açık Reddit’ten ölçmek biraz daha zordur (çünkü daha az kurumsal kullanıcı ayrıntılı olarak gönderir), ancak birkaç eğilim ortaya çıkar. İlk olarak, Anthropic Claude’u daha *gizlilik odaklı* ve kurumsal anlaşmalar imzalamaya istekli olarak konumlandırdı – bu, OpenAI ile ilgili veri endişeleri olan şirketlere hitap eder. Gerçekten de, bazı Reddit tartışmaları Claude’u Slack veya Notion gibi araçlar bağlamında, bir asistan olarak entegre edildiği yerlerde bahseder. Bu entegrasyonları kullanan profesyoneller Claude’un motor olduğunu fark etmeyebilir, ancak fark ettiklerinde yazı stilini ve uzun kurumsal belgeleri sindirme yeteneğini olumlu karşılaştırırlar. Örneğin, bir ekip uzun bir üç aylık raporu Claude’a besleyebilir ve makul bir özet alabilir – ChatGPT’nin daha küçük bağlamının zorlanacağı bir şey. Bununla birlikte, iş kullanıcıları belirli ekosistem özelliklerinin eksikliğini de fark eder; örneğin, OpenAI API’lerinde sistem mesajı kontrolü, işlev çağrısı vb. sunar, Anthropic ise daha sınırlı destek sunar. Bir iş çözümü üzerinde çalışan bir geliştirici, *Claude’un konuşmalarda daha yönlendirilebilir olduğunu, ChatGPT’nin ise daha katı olduğunu… [ama] ChatGPT’nin çok yardımcı olabilecek web erişimi var* diye belirtti. İma edilen, bir iş kullanıcısının ihtiyaç duyabileceği araştırma veya veri arama görevleri için (rekabetçi istihbarat gibi), ChatGPT’nin doğrudan bilgi çekebileceği, Claude’un ise ayrı bir adım gerektireceğidir. Genel olarak, iş kullanıcıları Claude’u çok yetkin bir AI olarak görüyor – bazı durumlarda *dahili analitik görevler için daha iyi* – ancak henüz entegrasyon açısından o kadar zengin değil. Maliyet bir diğer faktördür: Claude’un API fiyatlandırması ve koşulları OpenAI’ninki kadar kamuya açık değil ve bazı Reddit’teki girişimler Claude’un fiyatlandırması veya kararlılığı hakkında belirsizlik dile getirdi. Özetle, profesyoneller Claude’un yeteneklerine saygı duyuyor (özellikle yüksek düzeyde talimatları takip etme ve büyük girdileri özetleme konusundaki güvenilirliği), ancak onu daha yerleşik ChatGPT’ye tamamen taahhüt etmeden önce entegrasyon, destek ve küresel kullanılabilirlik açısından nasıl geliştiğini izliyorlar.

---

## Google Gemini (Bard)

### Yaygın Sıkıntı Noktaları ve Sınırlamalar

- **Yanlış veya “aptal” yanıtlar:** Google, Gemini destekli Bard yükseltmesini başlattığında Reddit’te bir geri bildirim seli ortaya çıktı, çoğu olumsuzdu. Kullanıcılar, Gemini’nin **temel Soru-Cevap’ta** ChatGPT’ye kıyasla yetersiz performans gösterdiğinden şikayet etti. “Google Gemini Hakkında %100 Dürüst Görüş” başlıklı bir değerlendirme, *“Kırık, yanlış bir LLM sohbet botu”* olarak belirtti. Başka bir hayal kırıklığına uğramış kullanıcı sordu: *“Gemini hala nasıl bu kadar kötü? Gemini’den bir şey istediğimde ya yanlış cevaplar veriyor ya da eksik cevaplar veriyor, bu çok saçma”*. Yan yana ChatGPT-4 ile karşılaştırdılar ve ChatGPT’nin *“mükemmel, doğru, verimli cevabı tek seferde verdiğini”*, oysa Gemini’nin dolambaçlı olduğunu ve doğru bilgiyi çıkarmak için çok fazla isteme ihtiyaç duyduğunu buldular. Özünde, erken kullanıcılar, Gemini’nin sık sık **halüsinasyon gördüğünü veya soruların özünü kaçırdığını**, doğru bilgiyi çıkarmak için aşırı istem çabası gerektirdiğini hissetti. Bu kalite tutarsızlığı, Gemini etrafındaki heyecan göz önüne alındığında büyük bir hayal kırıklığıydı.

- **Aşırı laf kalabalığı ve dolgu:** Birçok kullanıcı, Gemini’nin (yeni Bard formunda) genellikle uzun ve dolambaçlı yanıtlar ürettiğini, konunun özüne inmediğini belirtti. Bir kişi, *“Gevezelik etti… 3 paragraf AI çöpü… sonunda, cevabı paragraflar dolusu çöpün içinde gömülü olarak ancak bahsetti”* diye tanımladı. Bu, genellikle uygun olduğunda daha özlü yanıtlar veya madde işaretleri sunan ChatGPT ile keskin bir zıtlık oluşturur. Laf kalabalığı, kullanıcıların basit bir gerçek için çok fazla metni elemek zorunda kaldıklarında bir sıkıntı noktası haline gelir. Bazıları, Google’ın onu konuşkan veya “yardımcı” olacak şekilde ayarlamış olabileceğini, ancak *çok fazla* açıklama olmadan aşırıya kaçtığını düşündü.

- **Google’ın kendi hizmetleriyle zayıf entegrasyon:** Google’ın AI asistanının satış noktalarından biri, Google ekosistemiyle (Gmail, Dokümanlar, Drive vb.) entegrasyon olmasıdır. Ancak, erken kullanıcı deneyimleri bu konuda çok hayal kırıklığı yarattı. Bir kullanıcı, *“Google’ın kendi ürünleriyle entegrasyon yapamaması, bu bir ‘özellik’ olarak tanıtıldı (bunu yapabileceğini bilmiyor gibi görünüyor)”* diye öfkelendi. Örneğin, insanlar Gemini’den (Bard aracılığıyla) bir Google Dokümanını özetlemesini veya bazı bilgilerle bir e-posta taslağı oluşturmasını denedi – Google’ın tanıttığı özellikler – ve bot **bu verilere erişemeyeceğini** yanıtladı. r/GooglePixel’de bir kullanıcı yazdı: *“Her seferinde Gemini’yi Google Dokümanlarım veya Drive’ımla kullanmaya çalıştığımda, hiçbir şey yapamayacağını söylüyor. Bu entegrasyon özelliklerine sahip olmanın anlamı nedir?”*. Bu, vaat edilen yeteneklerle gerçek performans arasında önemli bir boşluk olduğunu gösterir, kullanıcıları “AI asistanı”nın Google’ın kendi ekosisteminde pek yardımcı olmadığı hissine kapılır.

- **Reddetmeler ve yetenek karışıklığı:** Kullanıcılar ayrıca Gemini’den tuhaf reddetmeler veya çelişkilerle karşılaştı. Aynı Reddit kullanıcısı, Gemini’nin *“hiçbir neden olmadan bir şeyler yapmayı reddettiğini, diğer şeyleri yapabileceğini unuttuğunu… Geçen gün internet/veri erişimi olmadığını söyledi. Ne.”* dedi. Bu, Gemini’nin **yapabileceği görevleri (Bard’a bağlı olan canlı bilgileri almak gibi) reddettiğini** veya kendi yetenekleri hakkında yanlış beyanlarda bulunduğunu gösterir. Bu tür deneyimler, sadece daha az zeki değil, aynı zamanda **daha az güvenilir veya kendinin farkında** bir AI izlenimi verdi. Başka bir kullanıcının renkli yorumu: *“Gemini mutlak çöp. Ellerini havaya kaldırıp ‘Ne düşünüyorlardı?’ demek istediğiniz anlardan biri.”* bu hayal kırıklığını özetliyor. Özünde, Gemini’nin ürün entegrasyonu ve tutarlılık sorunları, birçok erken benimseyen için *yarım yamalak* hissettirdi.

- **Dikkat çekici olmayan kodlama yetenekleri:** Genel Soru-Cevap kadar geniş çapta tartışılmasa da, birkaç kullanıcı Gemini’yi (Bard) kodlama görevlerinde test etti ve yetersiz buldu. AI forumlarında, Gemini’nin kodlama yetenekleri genellikle GPT-4’ün ve hatta Claude’un altında derecelendirildi. Örneğin, bir kullanıcı açıkça *“Claude 3.5 Sonnet, ChatGPT 4o’dan kodlama için açıkça daha iyi… Gemini bu bağlamda mutlak çöp”* dedi. Konsensüs, Gemini’nin basit kod yazabileceği veya temel algoritmaları açıklayabileceği, ancak daha karmaşık sorunlarda sıkça tökezlediği veya hatalı kod ürettiği yönündeydi. Geniş bir geliştirici araç setinin eksikliği (örneğin, ChatGPT’nin Kod Yorumlayıcısı veya sağlam işlev çağrısı eşdeğeri yok) da onu programcılar için ilk tercih yapmadı. Dolayısıyla, her sıradan kullanıcı kodla ilgilenmese de, bu segment için bir sınırlamadır.

- **Mobil cihaz sınırlamaları:** Gemini, Google’ın Asistanı’nın bir parçası olarak Pixel telefonlarda (Bard ile markalanmış “Asistan ile Bard” olarak) piyasaya sürüldü. Bazı Pixel kullanıcıları, bunu bir sesli asistan yedeği olarak kullanmanın sorunları olduğunu belirtti. Bazen sesli istemleri doğru bir şekilde algılamadı veya eski Google Asistan’a kıyasla yanıt vermesi uzun sürdü. Ayrıca, bazı klasik Asistan özelliklerini kaybetmek için opt-in yapma gerekliliği hakkında yorumlar vardı. Bu, *Gemini’nin cihazlardaki entegrasyonunun tam olarak hazır olmadığı* algısını yarattı, Google ekosisteminin güç kullanıcılarına akıllı bir asistan ile işlevsel bir asistan arasında seçim yapmaları gerektiğini hissettirdi.

### Sıkça Talep Edilen Özellikler veya İyileştirmeler

- **Dramatik olarak geliştirilmiş doğruluk ve akıl yürütme:** Kullanıcıların Gemini için istedikleri bir numaralı iyileştirme, **daha akıllı ve daha güvenilir** olmasıdır. Reddit geri bildirimleri, Google’ın yanıt kalitesindeki boşluğu kapatması gerektiğini açıkça ortaya koyuyor. Kullanıcılar, Gemini’nin Google’ın geniş bilgi erişimini kullanarak *gerçek, doğrudan cevaplar* vermesini, dolambaçlı veya yanlış olanları değil, bekliyor. Dolayısıyla talepler (genellikle alaycı bir şekilde ifade edilenler) şu şekilde özetlenebilir: *genel bilgi ve akıl yürütmede GPT-4 kadar iyi veya daha iyi yapın.* Bu, takip sorularını ve karmaşık istemleri daha iyi ele almayı içerir. Özünde, Gemini’nin “beyinini düzeltin” – bu iddia edilen çok modlu eğitim avantajlarını kullanarak bariz ayrıntıları kaçırmayı bırakmasını sağlayın. Google muhtemelen bunu net bir şekilde duydu: birçok gönderi, ChatGPT’nin mükemmel olduğu ve Gemini’nin başarısız olduğu belirli cevapları karşılaştırır, bu da iyileştirme için gayri resmi hata raporları olarak hizmet eder.

- **Daha iyi entegrasyon ve bağlam farkındalığı:** Kullanıcılar, Gemini’nin sorunsuz bir Google ekosistemi yardımcısı olma vaadini yerine getirmesini istiyor. Bu, **Gmail, Takvim, Dokümanlar, Drive vb. ile düzgün bir şekilde arayüz oluşturması** anlamına gelir. Bir kullanıcı “Açtığım belgeyi özetle” veya “Patronumdan gelen son e-postaya yanıt taslağı oluştur” gibi bir şey sorduğunda, AI bunu yapmalı – ve güvenli bir şekilde yapmalı. Şu anda, talep, Google’ın *bu özellikleri etkinleştirmesi ve Gemini’nin böyle bir görevin mümkün olduğunu gerçekten tanımasını sağlaması* yönündedir. Bard’ın kullanıcı içeriğine bağlanabileceği (izinle) tanıtıldı, bu yüzden kullanıcılar Google’ın bu entegrasyonu “açmasını” veya düzeltmesini talep ediyor. Bu, özellikle iş kullanıcıları için kilit bir özelliktir. Ayrıca, web tarama cephesinde: Bard (Gemini) web’de arama yapabilir, ancak bazı kullanıcılar kaynakları daha net bir şekilde belirtmesini veya son dakika haberlerini daha zamanında dahil etmesini istiyor. Yani Gemini’nin *bağlantılı* doğasını geliştirmek sıkça talep edilen bir şeydir.

- **Özlülük kontrolleri:** Laf kalabalığı şikayetleri göz önüne alındığında, bazı kullanıcılar yanıt stilini değiştirecek bir özellik önerir. Örneğin, varsayılan olarak kısa, özlü bir yanıt veren bir *“kısa mod”*, aksi takdirde ayrıntı istenirse. Tersine, çok ayrıntılı yanıtlar isteyenler için belki bir “detaylı mod”. ChatGPT, kullanıcı istemiyle (“kısa tut”) bunu dolaylı olarak sağlar; Gemini ile, kullanıcılar ayrıntı istemediklerinde bile fazla açıkladığını hissetti. Dolayısıyla, yerleşik bir ayar veya sadece uygun olduğunda özlü yanıtlar üretmek için daha iyi bir ayar, memnuniyetle karşılanacak bir iyileştirme olurdu. Özünde, laf kalabalığı ayarını ayarlayın.

- **ChatGPT ile özellik eşitliği (kodlama, eklentiler vb.):** Reddit’teki güç kullanıcıları özellikleri açıkça karşılaştırır. Google’ın Gemini/Bard’ının bir *kod yürütme alanı* (ChatGPT’nin Kod Yorumlayıcısı’na benzer), analiz için görüntü/PDF yükleme yeteneği (Gemini çok modlu olduğundan, kullanıcılar aslında özel görüntüleri beslemek istiyor, sadece sağlananları tanımlamasını değil) gibi şeyler sunmasını talep ederler. Sıkça bahsedilen bir diğer özellik, **sohbet içi hafıza** – Bard’ın geçmiş etkileşimlerin bazı hafızasına sahip olmasına rağmen, kullanıcılar ChatGPT kadar önceki bağlamı referans almasını veya ChatGPT’nin sohbet geçmişi gibi kalıcı sohbet depolaması olmasını istiyorlar, böylece kaydırıp gözden geçirebilir ve yeniden ziyaret edebilirler. Özünde, Google’dan ChatGPT Plus kullanıcılarının sahip olduğu tüm yaşam kalitesi özelliklerini yakalaması isteniyor: sohbet geçmişi, eklenti ekosistemi (veya en azından güçlü üçüncü taraf entegrasyonları), kodlama yardımı vb.

- **Mobil uygulama ve ses iyileştirmeleri:** Birçok gündelik kullanıcı, Bard/Gemini için **özel bir mobil uygulama** talep etti (ChatGPT mobil uygulamasına benzer). Web arayüzüne veya sadece Pixel Asistan’a güvenmek sınırlayıcıdır. iOS/Android genelinde resmi bir uygulama, sesli giriş, konuşan yanıtlar (gerçek bir asistan hissi için) ve sıkı entegrasyon, kullanıcı deneyimini büyük ölçüde iyileştirebilir. Bununla birlikte, Pixel sahipleri, Bard ile Asistan’ın daha hızlı ve daha işlevsel olmasını istiyor – temelde, eski Google Asistan’ın en iyisini (hızlı, kesin eylemler) Gemini’nin zekasıyla birleştirmek istiyorlar. Örneğin, “Hey Google” akıllı ev sesli komutlarına devam etme ve sadece sohbet yanıtları değil. Google, Gemini’nin ses modunu gerçekten eski asistanı özellik gerilemeleri olmadan değiştirecek şekilde iyileştirebilir.

- **Şeffaflık ve kontrol:** Bazı kullanıcılar Bard’ın kaynaklarına daha fazla içgörü veya stilini ince ayarlama yolu istemiştir. Örneğin, Bard’ın hangi Google sonucundan bilgi çektiğini gösterme (doğruluğu doğrulamak için) – Bing Chat’in bağlantıları belirttiği gibi. Ayrıca, Bard zaman zaman yanlış bilgi ürettiği için, kullanıcılar bunu işaretleyebilmek veya düzeltebilmek istiyor ve ideal olarak Bard’ın zamanla bu geri bildirimden öğrenmesi gerekiyor. Yanlış olduğunu belirten (“beğenmedim – bu yanlış çünkü…”) ve hızlı model iyileştirmesine yol açan kolay bir geri bildirim mekanizmasına sahip olmak, Google’ın dinlediğine dair güven aşılayacaktır. Temelde, AI’yı daha işbirlikçi bir asistan haline getirmek için özellikler, bir kara kutu yerine.

### Karşılanmamış İhtiyaçlar veya Kullanıcı Segmentleri

- **Güvenilir bir kişisel asistan arayan kullanıcılar:** İronik olarak, Google’ın *hedeflediği* grup – güçlü bir kişisel asistan isteyen insanlar – mevcut formunda Gemini tarafından en çok hizmet alamayanlardır. Yeni Bard tabanlı Asistan’ı açan erken benimseyenler bir yükseltme bekledi, ancak çoğu pratik anlamda bir düşüş hissetti. Örneğin, birisi bir sesli asistanın *doğru* bir şekilde trivia yanıtlamasını, hatırlatıcılar ayarlamasını, cihazları kontrol etmesini ve hesaplarından bilgi entegre etmesini istiyorsa, Gemini zorlandı. Bu, yoğun profesyoneller veya üretkenlik için asistanlara güvenen gadget meraklıları segmentini, ihtiyaçlarının karşılanmadığını hissettirdi. Bir kullanıcı, Pixel’in “Bard ile Asistan”ını *“Google Asistan’ı geçerse”* satın almayı düşüneceğini belirtti, bu da henüz geçmediğini ima ediyor. Dolayısıyla, bu segment hala güvenilir, gerçekten yardımcı bir AI asistanı bekliyor – Gemini gelişirse buna atlayacaklar.

- **Ana dili İngilizce olmayan konuşmacılar / yerelleştirme:** Google ürünleri genellikle mükemmel yerelleştirmeye sahiptir, ancak Bard/Gemini’nin lansmanda tüm dillerde eşit derecede güçlü olup olmadığı belirsizdir. Bazı uluslararası kullanıcılar, Bard’ın kendi ana dillerindeki yanıtlarının daha az akıcı veya yararlı olduğunu bildirdi, bu da onları yerel rakiplere geri itti. Gemini’nin eğitim verileri veya optimizasyonu İngilizce’yi tercih ettiyse, İngilizce olmayan kullanıcılar hizmet alamamış olabilir. ChatGPT veya yerel modellerin açıkça optimize edilmiş çok dilli yeteneklere sahip olduğu bu alanda Google geleneksel olarak mükemmel olabilir (çeviri teknolojisi göz önüne alındığında), ancak bu konuda kullanıcı geri bildirimi azdır – muhtemelen Gemini’nin bu toplulukları henüz etkilemediğini gösterir.

- **Kurumsal müşteriler (şu ana kadar):** Büyük kuruluşlar, güven ve yetenek boşlukları nedeniyle Bard/Gemini’yi geniş çapta benimsemedi. Kuruluşlar tutarlılık, alıntılar ve iş akışlarına entegrasyon ister (Office 365, MS Copilot aracılığıyla OpenAI’nin teknolojisiyle derinlemesine entegre edilmiştir). Google’ın eşdeğeri (Duet AI with Gemini) hala gelişiyor. Gemini/Bard, GPT-4 ile eşit veya üzerinde bir düzeyde e-posta taslakları oluşturma, slayt desteleri oluşturma veya Google Sheets’te veri analiz etme yeteneğini kanıtlayana kadar, kurumsal kullanıcılar Google’ın çözümünün ihtiyaçlarını tam olarak karşılamadığını hissedeceklerdir. r/Bard’da profesyonellerden gelen bazı gönderiler, “Bard’ı iş görevleri için denedim, ChatGPT kadar iyi değildi, bu yüzden bekleyip göreceğiz” şeklindedir. Bu, kurumsal kullanıcıların şu anda hizmet alamayan bir segment olduğunu gösteriyor – Google Workspace’e uyum sağlayan ve çıktıları sürekli doğrulama gerektirmeyen bir AI istiyorlar.

- **Google ekosisteminde her şeyin bir arada olduğu çözümleri tercih eden kullanıcılar:** Google’ı her şey için kullanan (arama, e-posta, belgeler) ve *tüm sohbet ihtiyaçları için* bir Google AI kullanmayı sevecek bir kullanıcı segmenti var – eğer bu kadar iyi olsaydı. Şu anda, bu kullanıcılar biraz hizmet alamıyor çünkü belirli şeyler için ChatGPT’yi ve diğerleri için Bard’ı kullanıyorlar. Yanlış yanıt kalitesi nedeniyle ChatGPT’ye güveniyor olabilirler, ancak Bard’ı tarama veya entegrasyon girişimleri için kullanıyor olabilirler. Bu bölünmüş deneyim ideal değildir. Bu tür kullanıcılar gerçekten sadece bir uygulama/asistan içinde kalmak istiyorlar. Gemini gelişirse, etrafında toplanacaklar, ancak o zamana kadar “hepsine hükmedecek bir asistan” kullanım durumları karşılanmıyor.

- **Google Cloud’daki geliştiriciler/veri bilimcileri:** Google, geliştiriciler için Gemini modellerini Vertex AI platformu aracılığıyla yayınladı. Ancak, erken raporlar ve ölçütler, Gemini’nin (özellikle mevcut “Gemini Pro” modeli) GPT-4’ü yenmediğini öne sürdü. AI hizmetleri için Google Cloud’u tercih eden geliştiriciler, bu nedenle model kalitesi tarafından biraz hizmet alamıyor – ya biraz daha düşük bir modeli kabul etmeleri ya da OpenAI’nin API’sini ayrı olarak entegre etmeleri gerekiyor. Bu kurumsal geliştirici segmenti, her şeyi tek bir yığında tutabilmek için güçlü bir Google modeline aç. Gemini’nin performansı bazı alanlarda açıkça üstün olana veya fiyatlandırma cazip bir neden sunana kadar, bu grubun ihtiyaçlarını rekabetçi terimlerle tam olarak karşılamıyor.

### Kullanıcı Türüne Göre Algı Farklılıkları

- **Geliştiriciler/Teknoloji Meraklıları:** Teknoloji meraklıları, Google olduğu için Gemini’ye yüksek beklentilerle yaklaştı. Elleriyle test ettikten sonra algıları hızla bozuldu. Reddit’teki birçok geliştirici, Gemini’yi zorlu sorular veya favori zorlu sorularıyla test etti ve geride kaldığını buldu. Bir programcı açıkça, *“Gemini, Llama 3.0’ın eskiden olduğu gibi mutlak çöp”* diyerek, onu bazı açık modellerin bile altında sıraladığını belirtti. Geliştiriciler, mantık hatalarına ve laf kalabalığına özellikle duyarlıdır. Bu yüzden Gemini, uzun ama yanlış cevaplar verdiğinde, hızla güvenilirliğini kaybetti. Öte yandan, geliştiriciler Google’ın potansiyelini tanır; bazıları *“daha fazla ince ayarla, Gemini daha iyi olacak”* umudunu taşır ve güncellemelerden sonra periyodik olarak yeniden test eder. Şu anda, çoğu geliştirici, **neredeyse tüm ciddi görevlerde GPT-4’ten daha düşük** olarak algılar (kodlama, karmaşık problem çözme). Belirli şeyleri takdir ederler: örneğin, Gemini, bir eklentiye ihtiyaç duymadan gerçek zamanlı bilgiye (Google araması aracılığıyla) erişebilir, bu da güncel sorgular için yararlıdır. Bir geliştirici, Bard’ı “X hakkında en son makaleleri ara ve özetle” gibi bir şey için kullanabilir, burada web verilerini alıntılayabilir. Ancak, kendi kendine mantık yürütme için diğer modellere yönelirler. Özetle, teknoloji meraklıları Gemini’yi umut verici bir çalışma olarak görüyor, ancak *şu anda* bir nesil geride hissediyor. Tam güvenlerini kazanmadı ve genellikle Google’ı iyileştirmeye teşvik etmek için hatalarını vurgulayan yan yana karşılaştırmalar yayınlıyorlar.

- **Gündelik/Günlük Kullanıcılar:** Gündelik kullanıcılar, telefonlarında veya web üzerinden yeni Bard’a erişim kazananlar, karışık duygular yaşadı. Birçok gündelik kullanıcı başlangıçta Bard’a (Gemini) ücretsiz ve bir Google hesabıyla erişimin kolay olması nedeniyle yaklaştı, GPT-4 ise ücretliydi. Bazı gündelik kullanıcılar aslında basit kullanımlar için iyi deneyimler bildirir: örneğin, r/Bard’da bir Reddit kullanıcısı, Gemini’nin onlara yasal belgeleri gözden geçirme, metin yazarlığı ve hatta bir fotoğraftan kıyafet bedenlerini tanımlama gibi şeylerde yardımcı olduğunu belirten olumlu bir inceleme verdi. *“Gemini, sorularımı yanıtlamak için değerli bir kaynak oldu… güncel bilgi… ücretli sürüme o kadar alıştım ki ücretsiz sürümün nasıl performans gösterdiğini hatırlayamıyorum.”* – bu, en azından *bazı* Bard Advanced’e zaman (ve para) yatıran gündelik kullanıcıların günlük yaşamda faydalı bulduğunu gösteriyor. Bu kullanıcılar, pratik, günlük yardım için kullanma eğilimindedir ve modeli sınırlarına kadar zorlamayabilirler. Ancak, birçok diğer gündelik kullanıcı (özellikle ChatGPT’yi de denemiş olanlar) hayal kırıklığına uğradı. Seyahat tavsiyesi, trivia veya bir görevde yardım isteyen sıradan insanlar, Bard’ın yanıtlarını daha az net veya yararlı buldu. Buradaki algı bölünmüş: **marka sadık Google kullanıcıları** vs. **zaten ChatGPT tarafından şımartılmış olanlar**. İlk grup, ChatGPT’yi fazla kullanmadılarsa, bazen Bard/Gemini’yi ihtiyaçları için “oldukça iyi” bulur ve arama ile entegre olduğunu ve ücretsiz olduğunu takdir eder. İkinci grup neredeyse her zaman karşılaştırır ve Gemini’yi yetersiz bulur. *“Bard’ı neden kullanayım ki ChatGPT %90 daha iyi?”* diyebilirler. Yani, gündelik kullanıcı algısı gerçekten önceki referans çerçevesine bağlıdır. AI asistanlarına yeni olanlar, Gemini’yi yardımcı bir yenilik olarak değerlendirebilir; rekabetle deneyimli olanlar ise *“hala bu kadar kötü”* olduğunu ve gelişmesi gerektiğini düşünür.

- **İş/Profesyonel Kullanıcılar:** Birçok profesyonel, Google Workspace entegrasyonu (Duet AI) ile piyasaya sürüldüğünde Bard’ı denedi. Bu grubun algısı temkinli bir şüpheciliktir. Bir yandan, Google’ın veri gizliliği ve entegrasyon (örneğin, AI aracılığıyla Dokümanları düzenleme, Takvim davetlerinden toplantı özetleri çıkarma vb.) vaatlerine güvenirler. Öte yandan, erken testler genellikle Gemini’nin gerçek hatalar yaptığını veya genel çıktılar sağladığını gösterdi, bu da iş kullanımı için güven verici değildir. Örneğin, bir profesyonel Bard’dan bir müşteri raporu taslağı oluşturmasını isteyebilir – Bard yanlış veri eklerse veya zayıf içgörüler sağlarsa, bu daha fazla zahmet olabilir. Bu nedenle, profesyonel kullanıcılar Bard’ı kritik olmayan görevlerde *pilot* olarak kullanma eğilimindedir, ancak önemli çıktılar için hala GPT-4 veya Claude’a güvenirler. Bard’ın “prime time” için hazır olmadığı algısı da var: birçok kişi Bard’ı “henüz hazır değil” olarak gördü ve beklemeye karar verdi. Bazı olumlu algılar, **gerçek zamanlı veri sorguları** gibi alanlarda vardır – örneğin, Reddit’te bir finans analisti, Bard’ın Google araması sayesinde son piyasa bilgilerini çekebileceğini, ChatGPT’nin ise eklentiler etkinleştirilmedikçe yapamayacağını belirtti. Dolayısıyla, güncel verilerin anahtar olduğu alanlarda, birkaç profesyonel bir avantaj gördü. Bir diğer nüans: Google ekosisteminde olan insanlar (örneğin, yalnızca Google Workspace kullanan şirketler) sadece Bard/Gemini’nin çevrelerine uyduğu için biraz daha olumlu bir görüşe sahip. Onun gelişmesini umuyorlar, tamamen farklı bir ekosisteme geçmek yerine. Özetle, iş kullanıcıları Gemini’yi *potansiyel olarak çok faydalı* olarak görüyor (Google’ın veri ve araç entegrasyonu göz önüne alındığında), ancak 2025 başı itibarıyla tam güven kazanmadı. “Henüz orada olmayan yeni yarışmacı” olarak algılanıyor – izlemeye değer, ancak henüz görevler için tercih edilen bir çözüm değil. Google’ın itibarı bu kalabalıktan biraz sabır satın alıyor, ancak sonsuz değil; eğer Gemini belirgin şekilde iyileşmezse, profesyoneller onu geniş çapta benimsemeyebilir, diğer çözümlerle kalabilirler.

---

## Açık Kaynak LLM'ler (ör. LLaMA tabanlı Modeller)

### Yaygın Sıkıntı Noktaları ve Sınırlamalar

- **Donanım ve kurulum gereksinimleri:** Bulut sohbet botlarının aksine, açık kaynak LLM’ler genellikle kullanıcıların bunları yerel donanımda veya bir sunucuda çalıştırmasını gerektirir. Bu hemen bir sıkıntı noktası sunar: birçok model (örneğin, 70 milyar parametreli bir LLaMA modeli) sorunsuz çalışmak için çok fazla VRAM’e sahip güçlü bir GPU gerektirir. Bir Reddit kullanıcısının özlü bir şekilde belirttiği gibi, *“Çoğu tüketici donanımında yerel LLM’ler, herhangi bir karmaşık geliştirme için gereken hassasiyete sahip olmayacak.”* Ortalama bir kişi için sadece 8GB veya 16GB GPU (veya sadece bir CPU) ile yüksek kaliteli bir modeli çalıştırmak yavaş veya tamamen imkansız olabilir. Kullanıcılar, sığacak daha küçük modellere başvurabilir, ancak bunlar genellikle daha düşük kaliteli çıktı verir (“daha aptal” yanıtlar). Kurulumun karmaşıklığı başka bir sorundur – model ağırlıklarını yüklemek, Oobabooga veya LangChain gibi ortamları ayarlamak, tokenizasyon kitaplıklarını yönetmek vb. geliştirici olmayanlar için göz korkutucu olabilir. Teknik olarak yetenekli kullanıcılar bile yeni model sürümlerini, GPU sürücü tuhaflıklarını vb. takip etmenin zahmetli olduğunu belirtir. “Ciddi anlamda, yerel LLM’leri nasıl kullanıyorsunuz?” başlıklı bir başlıkta, birçok modelin *“ya düşük performans gösterdiğini ya da donanımımda sorunsuz çalışmadığını”* paylaşan ve pratik tavsiyeler isteyen insanlar vardı.

- **En son kapalı modellere göre düşük performans:** Açık kaynak modelleri hızlı ilerleme kaydetti, ancak 2025 itibarıyla birçok kullanıcı, hala en iyi özel modellerin (GPT-4, Claude) karmaşık akıl yürütme, kodlama ve gerçek doğruluğunda geride kaldığını belirtiyor. Canlı bir örnek: r/LocalLLaMA’da bir kullanıcı, kendi ana dilinde çıktıları karşılaştırdı ve *“Denediğim diğer tüm modeller başarısız… Yakın bile değiller [GPT-4’e]. ChatGPT 4 yazmada kesinlikle harika”* dedi. Bu duygu yaygın olarak yankılanır: daha küçük açık modeller (ince ayarlı 13B veya 7B gibi) boyutlarına göre etkileyici olabilir, ancak derin anlayış veya çok adımlı mantık gerektiren görevlerde zorlanırlar. Daha büyük açık modeller (65B, 70B) GPT-3.5 seviyesine yaklaşsa bile, GPT-4’ün ele aldığı türden zorlu sorunlarda tökezleyebilirler. Kullanıcılar, özellikle niş bilgi veya istemler eğitim dağıtımından biraz saptığında açık modellerde daha fazla halüsinasyon ve hata gözlemler. Yani, ham yetenek boşluğu bir sıkıntı noktasıdır – yerel modelleri kullanırken beklentileri düşürmek gerekir, bu da ChatGPT’nin güvenilirliğine alışkın olanlar için sinir bozucu olabilir.

- **Sınırlı bağlam uzunluğu:** Çoğu açık kaynak LLM geleneksel olarak daha küçük bağlam pencerelerine sahiptir (2048 token, belki 4k token) ChatGPT veya Claude’un sunduğu şeylere kıyasla. Bazı yeni ince ayarlar ve mimariler bunu genişletiyor (örneğin, LLaMA-2’nin 8K veya 16K token sürümleri var ve MPT-7B gibi araştırmalar 16K bağlamı vardı). Ancak, çok uzun bağlam açık modellerinin pratik kullanımı hala erken aşamalardadır. Bu, yerel model kullanıcılarının benzer hafıza sorunlarıyla karşılaştığı anlamına gelir – model, harici hafıza şemaları (geri alma için vektör veritabanları gibi) uygulamazlarsa konuşmanın veya metnin önceki bölümlerini unutur. Reddit tartışmalarında, kullanıcılar sık sık sınırlar içinde kalmak için geçmişi manuel olarak özetlemek veya kesmek zorunda kaldıklarını belirtir, bu da zahmetlidir. Bu, özellikle özel modellerin bağlam uzunluklarını daha da ileriye taşıdığı bir sınırlamadır (Claude’un 100k’si gibi).

- **Bazı modellerde ince ayarlı talimat izleme eksikliği:** Birçok açık model talimat ayarlıdır (Alpaca, LLaMA-2-Chat vb.), ancak hepsi ChatGPT kadar titizlikle RLHF eğitilmemiştir. Bu, yerel modellerin bazen